<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - lyer's blog</title><link>/posts/</link><description>所有文章 | lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Sun, 23 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/" rel="self" type="application/rss+xml"/><item><title>Go处理error</title><link>/2021/05/23/go%E5%A4%84%E7%90%86error/</link><pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/23/go%E5%A4%84%E7%90%86error/</guid><description><![CDATA[大道至简的error go的错误处理就只有一个errors包和一个error接口，这个接口只包哈一个Error方法，该方法返回一个string，这个包的代码很少，只有两个文件：
 errors.go wrap.go  go的error也就是通过创建一个错误提示的字符串的方式，然后通过返回值来返回这个错误，除非这个函数能保证一定能执行成功，否则每个函数都必须返回一个error
func f() error{ return errors.New(&#34;error&#34;) //返回error接口 } 下面来看下errors/errors.go的源码，不过10行左右
func New(text string) error { return &amp;errorString{text} //返回errorString指针 } //实现了error接口 type errorString struct { s string } //获取错误字符串的方法 func (e *errorString) Error() string { return e.s } ​
自定义error 我们只需要实现error接口也就是重写Error()方法即可自定义错误
type ZeroDivisionError struct { msg string code int } func (e ZeroDivisionError) Error() string { return fmt.Sprintf(&#34;[%d]:%s&#34;, e.code, e.msg) } type NullPointerError struct { msg string } func (e NullPointerError) Error() string { return fmt.]]></description></item><item><title>MySql事务和锁</title><link>/2021/05/23/mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/</link><pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/23/mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/</guid><description>为什么需要有事务 事务的出现就是为了 保障数据一致性，将多条逻辑相关的SQL语句当做一件事情来做，要么都成功要么都失败
最经典的场景就是转账业务: 当A给B转账时，B账户余额增加的同时必须保证A账户余额减少，也就是说必须保证A和B账户的总钱款大小前后一致，两个账户的钱总量不会多也不会少
一个事务中包含一条或则多条逻辑相关的操作(SQL)，这些操作看作是一个整体，不可分割，当做一件事情来做。如果其中一条或多条SQL失败了则代表此次事务(这件事情)就失败了，则之前执行过的SQL必须全部失败，全部执行回滚 (原子性) 不管事务是否成功，数据必须保持一致性，不会出现错误 并发操作下，事务最难控制 事务的执行过程中最需要关注的就是 事务并行和事务隔离 问题，就是说多个事务必须是隔离的，事务A不能影响事务B的执行，这也是事务中最难处理和最难理解的一部分
​
事务四大特性ACID 原子性 Atomicity
事务是数据库的逻辑工作单位，不可分割，事务中包含的各操作要么都做，要么都不做
一致性 Consistency
一致性是指事务将数据库从一种一致性状态变为下一种一致性状态，在事务开始之前和之后，数据库的完整性约束没有被破坏
比如转账的例子，两个账户的钱款总量在转账前后还是一致的，如果B余额增加了但是A余额没有扣除那么就会凭白无故多出一部分钱来，这就引发钱款不一致的状况了
再比如A的余额为0了，此时A还要给别人转账就不合适了，因为余额必须&amp;gt;=0。如果余额出现负数，这也导致了数据不一致状况
还有年龄不能为负数，红绿灯只有三种颜色，人民币最大面值为100等，这些约束都必须要符合真实世界的情况，都必须和真实世界保持一致性
隔离性 Isolation
每个事务都是隔离的，互相不影响，一共有4个隔离级别
不同事务在提交的时候，必须保证最终呈现出来的效果是串行的。比如两个顾客同时买一件衣服，衣服总量只有2件了。此时顾客A买了1件提交了，顾客B买了1件也提交了。那么最终的衣服总量必须减少为0，而不是1。如果在RR隔离级别下，顾客A和B在事务没提交之前看见的衣服总量都为2，因为他们是同时开启事务的，假设A先提交了，但是B看到的余量依旧是2件(RR隔离级别)，当B再买并且提交之后，则必须还剩余0件，而不是剩余1件，必须保障数据的一致性。也就是说虽然他们看起来是并行执行的事务，但是最终的效果一定要是串行的效果。
持久性 Durability
事务一旦提交，它对数据库中的数据的改变就应该是永久性的，必须持久化到磁盘
​
MySql事务的实现 原子性: undo log 实现 (记录了事务修改之前的数据，当事务在执行过程中如果失败了那么当前事务就处于不一致的状态，这样可以回滚到上一个一致性的状态) 持久性: redo log 实现 隔离性: 锁+MVCC 实现 一致性: 通过原子性、持久性、隔离性实现 ​
隔离性和四大隔离级别 1、读未提交 Read Uncommitted
一个事务还没提交时，它做的变更对他事务可见
脏读 不可重复读 幻读 2、读已提交 Read Committed Oracle默认的隔离级别
一个事务只有提交时它做的变化才对其他事务可见，该级别会造成 在事务中两次读取数据不一致的情况，也就是不可重复读
不可重复读 幻读 3、可重复读 Repeatable Read MySql、Innodb默认的隔离级别</description></item><item><title>Go中的slice</title><link>/2021/05/22/go%E4%B8%AD%E7%9A%84slice/</link><pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/22/go%E4%B8%AD%E7%9A%84slice/</guid><description>数组 数组值拷贝
func main(){ a1:=[...]int{1,2,3} a2:=a1 log.Println(a1,a1[0]) log.Println(a2,a2[0]) //也可以通过下标访问 a2[0] = 10 log.Println(a) //a[0]=1 } 数组指针传递
//通过指针访问数组 func main(){ a:=[...]int{1,2,3} a2:=&amp;amp;a log.Println(a,a[0]) log.Println(a2,a2[0]) a2[0] = 10 log.Println(a) //a[0]=10 } ​
len和cap的区别 len 代表底层数组可访问的范围，用索引访问不可越过这个界限
cap 代表底层数组的实际空间长度，不可用索引访问，如果append 元素时没有超过这个cap，则不再创建底层数组，直接在len空间后面扩展。否则开辟新的空间，同时增大cap（这里有一个增大规则），所以如果要频繁的扩容，适当设置大一些的cap能减少开销的，设置大的cap是为了防止多次扩容拷贝造成开销
func main(){ slice1 := []int{1,2,3} //len=3 cap=3 slice2 := make([]int,2) //len=2 cap=2 slice3 := make([]int,2,4) //len=2 cap=4 } func main(){ arr:=make([]int,2,10) // len=2 cap=10 arr[0]=1 arr[1]=2 //arr[2]=3 //报错 // len=6 cap=10 arr = arr[:6] //扩容,不会再申请空间 arr[2]=3 // [1,2,3,0,0,0] //会在len后面添加,如果len&amp;gt;cap则会进行扩容 此处不会扩容 arr = append(arr,888) // len=7 cap=10 //arr=arr[:11] //报错 超过cap的大小，此时必须用过append进行扩容 } func main(){ //下面的切片引用切片 指向同一个底层数组 cap右界限都是和父亲一样的 a1 :=[]int{1,2,3,4,5,6,7,8} // len=8 cap=8 a2 :=a1[:3] //[1,2,3] len=3 cap=8 a3 :=a1[:5] //[1,2,3,4,5] len=5 cap=8 } ​</description></item><item><title>Go并发模式和channel</title><link>/2021/05/22/go%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F%E5%92%8Cchannel/</link><pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/22/go%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F%E5%92%8Cchannel/</guid><description><![CDATA[channel实现互斥锁 传统的sync.Mutex互斥锁
//如果不加锁那么最终结果可能不是10000 func main() { count := 0 wg := sync.WaitGroup{} mu := sync.Mutex{} for i := 0; i &lt; 10000; i++ { wg.Add(1) go func() { mu.Lock() count++ mu.Unlock() wg.Done() }() } wg.Wait() fmt.Println(count) //10000 } channel实现互斥锁
func main() { count := 0 wg := sync.WaitGroup{} //channel的大小表示资源数量 1表示只允许一个goroutine加锁 	lock := make(chan struct{}, 1) for i := 0; i &lt; 10000; i++ { wg.Add(1) go func() { lock &lt;- struct{}{} //加锁 	count++ &lt;-lock //解锁 	wg.]]></description></item><item><title>github上的docker镜像仓库</title><link>/2021/05/21/github%E4%B8%8A%E7%9A%84docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/21/github%E4%B8%8A%E7%9A%84docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</guid><description>github镜像仓库 github上也提供了docker镜像仓库服务，分为两类:
docker.pkg.github.com 仓库关联的镜像仓库，必须对应一个仓库 ghcr.io 仓库无关的镜像仓库，和用户关联 tag格式分别为:
docker.pkg.github.com/OWNER/REPOSITORY/IMAGE_NAME:VERSION ghcr.io/OWNER/IMAGE_NAME:VERSION 登入的密码就是github上创建的TOKEN，注意token必须有读写package的相关权限，我把token记录在了环境变量中，也可以记录在指定的文件里，将echo替换为cat即可
echo $GITHUB_DOCKER_IMAGE_TOKEN | docker login https://docker.pkg.github.com -u biningo --password-stdin echo $GITHUB_DOCKER_IMAGE_TOKEN | docker login https://ghcr.io -u biningo --password-stdin ​
参考 Working with the Docker registry
Working with the Container registry</description></item><item><title>Docker实用小工具</title><link>/2021/05/20/docker%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%B7%A5%E5%85%B7/</link><pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/20/docker%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%B7%A5%E5%85%B7/</guid><description>lazydocker https://github.com/jesseduffield/lazydocker
终端界面管理Docker
portainer https://github.com/portainer/portainer
Web界面可视化管理Docker和Kubernetes集群
harbor https://github.com/goharbor/harbor
企业级docker私有仓库
DockerSlim https://github.com/docker-slim/docker-slim
Docker镜像瘦身，镜像安全等
ctop https://github.com/bcicen/ctop
Docker终端容器监控工具
podman 一个和Docker命令兼容的Linux容器工具，被誉为下一代容器工具
参考 推荐5款好用的开源Docker工具</description></item><item><title>netcat和socat网络小工具</title><link>/2021/05/19/netcat%E5%92%8Csocat%E7%BD%91%E7%BB%9C%E5%B0%8F%E5%B7%A5%E5%85%B7/</link><pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/19/netcat%E5%92%8Csocat%E7%BD%91%E7%BB%9C%E5%B0%8F%E5%B7%A5%E5%85%B7/</guid><description>netcat网络瑞士军刀 netcat是一个网络小工具，可以用来监听端口，数据回发(简单的echo)，TCP端口扫描，探测网络，网络测速等
echo监听端口和连接端口
#server -l表示监听 nc -l 8000 #监听8000端口 #client nc localhost 8000 #连接本地的8000端口 #然后直接输入数据对方就可以收到了 #监听UDP端口 nc -u -l 8080 #请求UDP端口 nc -u localhost 8080 传输文件
#server nc -l 1234 &amp;gt; filename.out #client nc -N localhost 1234 &amp;lt; filename.in #-N表示如果接受到EOF则断开 端口扫描和检测端口
# -z表示只是检测端口 不需要发送数据 # -v表示显示详细信息 # -w表示指定超时时间s nc -zv host.example.com 20-30 #[20,30] nc -zv icepan.cloud 9000 #端口检测 telnet效果一样 nc -zv -w 5 icepan.cloud 1111 #检测端口设置超时时间为5s 结合pv网络测速（pv用于测量任何操作的数度，可以以管道符来测量）
#server nc -l 8080 &amp;lt; /dev/zero #给这个传输无限多个空白字符串 #client nc icepan.</description></item><item><title>Nginx中server_name和HTTP协议中的Host</title><link>/2021/05/19/nginx%E4%B8%ADserver_name%E5%92%8Chttp%E5%8D%8F%E8%AE%AE%E7%9A%84host/</link><pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/19/nginx%E4%B8%ADserver_name%E5%92%8Chttp%E5%8D%8F%E8%AE%AE%E7%9A%84host/</guid><description><![CDATA[HTTP协议中的Host HTTP请求头部有一个Host字段可以指定目标主机的域名或则主机名，但是最终域名不是需要转化为IP:Port吗？IP:Port不就是可以标识唯一应用了吗？ 那为啥HTTP请求头还需要一个Host字段来标识出域名呢？
这里涉及到 虚拟主机 的概念，即一台主机(一个IP) 可以拥有多个域名，每个域名都可以在80同端口下部署HTTP应用，客户端看访问应用则以为应用是一台独立的主机一样，但是实际上多个应用是共享同一台主机，只不过他们对应的域名不一样罢了，所以也叫虚拟主机
如果一个请求发送到服务器上的80端口，那么监听在80端口上的应用服务器会判断HTTP请求报文中的Host是不是自己的，如果是则接收并且响应，不是则丢弃。或则直接部署一个网关(Nginx)，网关捕获所有请求然后检查HTTP请求头的Host字段根据配置的 Host规则 转发到不同的后端服务器上即可
当然也可以将多个应用分别部署到不同的端口上，只是这样比较麻烦并且占用了端口，有时候还违背了一些默认规则，比如HTTP应用的默认端口80，如果我有两个网站那么我就不得不将其他网站的端口给修改了，这样会造成用户访问不方便
​
Nginx中的server_name 我们可以配置server_name规则来让Nginx检查Host字段并且转发到相应的服务器上
server { listen 80; server_name www; location / { default_type text/html; content_by_lua &#39; ngx.say(&#34;&lt;p&gt;www&lt;/p&gt;&#34;) &#39;; } } server { listen 80; server_name www.lyer.com; location / { default_type text/html; content_by_lua &#39; ngx.say(&#34;&lt;p&gt;www.lyer.com&lt;/p&gt;&#34;) &#39;; } } server { listen 80; server_name www.lyer.*; location / { default_type text/html; content_by_lua &#39; ngx.say(&#34;&lt;p&gt;www.lyer.*&lt;/p&gt;&#34;) &#39;; } } server { listen 80; server_name ~\w+.]]></description></item><item><title>C语法总结</title><link>/2021/05/16/c%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</link><pubDate>Sun, 16 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/16/c%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</guid><description><![CDATA[函数指针和回调函数  指针函数 返回指针的函数  char * sayHello(){ char *msg = (char*)malloc(sizeof(13)); msg = &#34;hello,world\n&#34;; return msg; } int main(int argc, char const *argv[]) { char *msg; msg = sayHello(); printf(&#34;%s\n&#34;,msg); }  函数指针 保存函数入口地址的指针，可用于直接设置CPU的PC，直接跳转到目标函数代码指向，目标代码还可以是一段汇编程序，这样也可以实现C和汇编混合编程  void echo(char *msg) { printf(&#34;%s\n&#34;, msg); } int main(int argc, char const *argv[]) { //void:返回值 (*func):函数指针写法 (char *msg):形参  void (*func)(char *msg); //可以直接赋予一个函数的地址 或则void*地址都可  //赋予一段汇编代码地址起始处也可  func = &amp;echo; func(&#34;hello,world&#34;); //直接跳转到地址入口执行 } 下面将四则运算法则传入函数中进行回调]]></description></item><item><title>TTL和MSL</title><link>/2021/05/14/ttl%E5%92%8Cmsl/</link><pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/14/ttl%E5%92%8Cmsl/</guid><description>TTL Time To Live 指定了IP包允许跳转(允许通过的最大网段数量)的路由器数量，最大值为255，推荐值为64
TTL在IP数据包中表示
IP数据包每经过一个路由器其值就会-1，一旦TTL=0路由器就会将该IP数据包丢弃，并向IP包的发送者发送 ICMP time exceeded消息
TTL主要就是为了防止IP数据包在网络上出现无限的循环跳转，一旦出现循环跳转的话就会比较浪费网络资源
​
MSL Maximum Segment Lifetime最大报文段生存时间，此时间应该是略大于TTL跳转的时间的，也就是说一旦IP包只要送到对方的机器上，那么此包就一定不会超过MSL，想象一下如果MSL小于TTL那么IP包送到了但是TCP包超时了那么就会比较浪费资源，并且因为TCP包是包含在IP包上的，里面的时间按逻辑上就应该大于等于TTL的
所以只要经过了MSL时间，那么TCP包就肯定已经被传输线路上的路由器给丢弃了
​
参考 TCP/IP</description></item></channel></rss>