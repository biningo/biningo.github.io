<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - lyer's blog</title><link>/posts/</link><description>所有文章 | lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Sat, 29 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/" rel="self" type="application/rss+xml"/><item><title>Go文件读写和IO操作</title><link>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</guid><description><![CDATA[IO接口 io.Reader 读IO接口
type Reader interface { Read(p []byte) (n int, err error) } io.Writer 写IO接口
type Writer interface { Write(p []byte) (n int, err error) } io.Closer 关闭IO接口
type Closer interface { Close() error } ​
文件读取 方式一: 无缓冲直接读取
func fileDemo1() { file, err := os.Open(&#34;/go-test-learn/io/t1.go&#34;) CheckError(&#34;&#34;, err) defer file.Close() content := []byte{} buf := make([]byte, 100) //每次读取的最大byte数组 	for { n, err := file.Read(buf) //返回真实读取的数据字节大小 (&lt;=len(buf)) 	if err == io.]]></description></item><item><title>一致性Hash</title><link>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</guid><description>分布式缓存 为了提高Redis缓存的读写能力，一般会建一个Redis集群，此时我们就需要通过hash算法将key存储到指定的一台节点中，这样每次取这个key的时候到key对应的节点中去获取即可
假如现在有10台Redis，计算key对应的节点的hash公式如下:
node = hash(key)%10 静态分配策略在集群节点数量固定的时候是没问题的，但是当集群节点数量进行动态扩缩的情况下就会出现 缓存雪崩 问题
比如现在新加了10个节点，那么上面的公式就变成了如下:
node = hash(key)%20 也就是说之前所有的key计算出的节点在集群扩大的时候再次计算时就可能不是同一个节点，那么就无法在对应节点中获取到key的缓存。如果这样的key数量很多的话就会造成缓存雪崩问题，那么后端数据库的压力就会在集群扩容的时候剧增
为了解决这个问题，于是就有了后面的 一致性Hash算法
​
一致性Hash算法 一致性hash算法将节点映射到这个环上，同时也将key映射到一个2^32大小的环上，并且沿着key所在的位置顺时针查找，找到的第一个节点就是这个key要保存的节点
如果加了一个node或则减少了一个node，那么只会影响环上的node顺时针对应的前一个node之间的数据
​
节点倾斜问题 当hash环上的节点数量较少时就可能造成节点倾斜问题，比如所有节点都被映射到了同一边的一个角落，那么就会有大量的key只存在一个node上，而其他node则没有多少key
为了解决节点倾斜问题，引入了 虚拟节点 。 就是在每个实际的节点下虚拟出几个不存在的节点将其映射到hash环上，让hash环上节点分布的比较均匀。如果key保存在虚拟节点上，则实际上是保存在这个虚拟节点对应的实际节点中。通过虚拟节点就解决了数据倾斜问题
​
参考 好刚: 7分钟视频详解一致性hash 算法
一致性hash</description></item><item><title>常见的开源数据库</title><link>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>KV数据库 BoltDB go语言写的kv数据库，现在已经停止维护
https://github.com/boltdb/bolt
但是etcd扩展了BoltDB，重新命名叫 BBolt，作为是etcd的底层kv存储
https://github.com/etcd-io/bbolt
levelDB google开源的，使用c++写的kv数据库
https://github.com/google/leveldb
​
时序数据库 influxDB go语言写的时序数据库，分为商业版和开源版，开源版本不支持分布式
https://github.com/influxdata/influxdb
TDengine 用C写的时序数据库，支持分布式，全部开源
https://github.com/taosdata/TDengine
关于时序数据库参考博客 时序数据库 InfluxDB（一）
时序数据库InfluxDB使用详解</description></item><item><title>TCP半连接和全连接队列</title><link>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</guid><description>什么是半连接和全连接队列 操作系统在listen开启监听时就会建立两个队列
半连接 全连接 半连接队列存放的就是一些还没建立TCP连接，并且还在三次握手过程中的客户端连接
全连接队列存放的就是一些已经完全建立TCP连接但是还没被应用层取走的连接，每次应用层调用accept时就会从全连接队列里取一个连接去处理，但是如果队列中没有连接就会阻塞
​
半连接队列 当服务器端在LISTEN状态时能接受其他客户端的TCP建立连接请求，当服务器收到客户端发来的SYN包时就会回复ACK+SYN，此时服务器就进入了 SYN_RECV的状态，这个时候服务器就会将这个连接存放到半连接队列中，并且等待客户端发来应答的ACK
如果在指定时间内客户端没有发第三次握手，则服务器会进行重试直到超过一定次数则会将此连接从半连接队列里面删除
#SYN+ACK重试次数 默认为5 /proc/sys/net/ipv4/tcp_synack_retries 如果客户端发来了第三次握手ACK，则会将此连接放入全连接队列等待用户应用去队列里面取
如果半连接队列满了的话，则服务器不会继续接受客户端的连接请求，当其他客户端想要建立TCP连接发送SYN时，服务器就会发送RST报文告诉客户端 &amp;ldquo;连接失败&amp;quot;或则是直接丢弃
​
半连接队列大小 半连接队列大小收到下面几个因素影响
用户层 listen 传入的backlog （用户传入的全连接队列大小） 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128 （Linux配置的全连接队列大小） int listen(int sockfd, int backlog); //第二个参数 /proc/sys/net/ipv4/tcp_max_syn_backlog #1024 /proc/sys/net/core/somaxconn #4096 如果我们想要增加半连接队列的大小，我们就需要同时增加上面三个值，而单单的增加其中的几个则可能无法增加半连接队列的大小
​
全连接队列 当服务器收到客户端发来的第三次握手的时候，服务器就会将这个连接从半连接队里里面转移到全连接队里面并等待应用去全连接队列里取连接进行处理，应用一旦取走该连接就不会保存在队列里了
全连接队列只是用来保存已经建立TCP连接但是还没被用户取走待处理的连接
如果全连接队列满了的话服务器会使用下面两种策略，用户可以在一下文件中配置
/proc/sys/net/ipv4/tcp_abort_on_overflow 0 全连接队列满了则server会丢弃ACK，当作没收到
即使收到了客户端发来的第三次握手ACK也会丢弃当做没收到，则此半连接就无法进入全连接队里，同时server端也会在超时的时候继续发送SYN+ACK，当重试超过指定次数之后全连接队列还是满的则会因为将此半连接删除
1 全连接队列满了则会发送RST包告诉客户端废除这个连接请求
一般配置为0可以有效的增加服务器的并发能力，可能全连接队列只是短暂的满了，之后会被快速取走，则配置为0之后，在后面重试的ACK中还是可以建立连接的
​
全连接队列大小 全连接大小由操作系统配置somaxconn和用户应用配置的backlog两个值确定的
min(somaxconn, backlog) int listen(int sockfd, int backlog) //用户决定 /proc/sys/net/core/somaxconn #4096 操作系统参数 我们如果要增加全连接大小，则需要考虑操作系统的配置以及应用程序传入的配置，取他们之间最小的一个，也就是说即使应用程序传入的backlog再大，如果somaxconn很小的话则依然无法增加全连接队列的大小</description></item><item><title>TCP协议中的KeepAlive机制</title><link>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</guid><description>HTTP中的keep-alive 在HTTP的头部中，也有一个字段
connection: keep-alive 此字段告诉服务器HTTP会复用这一条TCP连接，当前的HTTP请求完毕之后不会立即断开连接，还可以被另外的HTTP请求复用这条连接，这样就可以减少建立TCP连接的次数
​
TCP的长连接和短连接 TCP连接并没有分为长短连接，长短连接只是在于你如何使用TCP
如果建立TCP连接短暂通讯结束之后立即释放这条连接则此连接就为短连接，比如我HTTP发一次请求就建立一次TCP连接，HTTP响应回来之后就立即断开TCP连接
短连接的缺点就是需要频繁的建立TCP连接，比较耗时，优点就是可以很快的释放TCP连接队列，以便于空出位置建立其他TCP连接
如果建立TCP连接在使用时候不立即断开，如果一直没有请求的话就将这条连接空闲即可，以便与后面如果还要请求通讯的话就不需要建立TCP连接了，直接复用那条已经建立好的TCP连接即可。比如我HTTP请求建立TCP连接，响应结束之后浏览器不会立即释放与服务器的TCP连接，如果下次还有其他请求的话则可以复用之前建立的TCP连接即可，如果一时半会儿还没有请求的话只需要将TCP连接空闲着即可，等下次有请求了就可以继续用这条连接进行传输
长连接的优点就是可以减少建立TCP连接的消耗，复用连接。缺点就是如果很长一段时间都没有数据可发的话就会占用操作系统的TCP全连接队列，如果TCP全连接队列比较紧张的话那么就无法建立其他的TCP连接了
​
TCP的KeepAlive机制 TCP的KeepAlive机制会在指定的间隔时间发送KeepAlive探活包，如果收到了KeepAlive包的ACK则表明对方还在，如果多次发送KeepAlive包都得不到回复则可以认为对方已经挂了，就可以将这个TCP连接从队列里面删除了
KeepAlice主要有如下几个作用:
保活 解决窗口值为0的情况 在空闲的长连接里我们可以通过KeepAlive机制探测对方是否存活，如果收到ACK则表明对方还存活并且还需要复用这条连接
如果多次发送KeepAlive都收不到则说明对方已经挂了或则对方拒绝回复，这样就表明这条长连接可以断开清除了。如果没有KeepAlive机制如果对方挂了则这个连接还会一直保留在服务区占用着TCP全连接队列
还有一种情况就是在接收方的窗口值为0的情况下，那么发送方就不能继续发送数据了，那么即使接收方的窗口扩大了也没有办法告诉发送方，此时就相当于死锁了双方都不会发送数据
所以KeepAlive探测包还可以用于解决窗口值减少为0而造成死锁的情况。当接收方的窗口为0的时候，发送方可以定时的发送KeepAlive包来探测接收方的窗口是否扩大了
​
Linux中KeepAlive相关配置 #7200 每7200s发送KeepAlive包 /proc/sys/net/ipv4/tcp_keepalive_time #75 如果75s内没有收到KeepAlive的ACK则再次发送 /proc/sys/net/ipv4/tcp_keepalive_intvl #9 如果重试9次都没有响应则把此连接删除掉 /proc/sys/net/ipv4/tcp_keepalive_probes ​
KeepAlive能携带数据吗 注意，KeepAlive包的seq也是没有意义的，seq一般和初始化的seq一致，KeepAlive是不携带数据的</description></item><item><title>Redis事务</title><link>/2021/05/26/redis%E4%BA%8B%E5%8A%A1/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/26/redis%E4%BA%8B%E5%8A%A1/</guid><description>TODO</description></item><item><title>面试常见问题总结</title><link>/2021/05/26/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/26/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</guid><description>MySql MySql索引说说看? InnoDB索引使用什么数据结构?
MyISAM和InnoDB索引的区别?
什么是聚集索引，什么是非聚集索引?
什么时候适合建索引?
Redis Redis网络模型说说看?
Redis有哪几个常用的数据类型和数据结构?
Redis持久化RDB和AOF?
Redis集群有了解吗?
你项目里用到了Redis的哪些数据结构?
Redis键的过期策略了解吗?
参考博客
https://segmentfault.com/a/1190000022670317
网络相关 TCP四次握手过程? 为什么需要四次? 为什么需要TIME_WAIT?
Go语言 new和make的区别
go中的slice机制是怎么样的?
map的并发安全的吗? 为什么?
获取一个map中不存在的key会出现什么情况? 删除一个不存在的key呢?
channel了解吗? 缓冲channel和非缓冲channel的区别
channel你使用过吗? 有什么应用场景
往一个已经close的channel发数据会怎么样? 读数据呢?
go的GMP模型了解吗
GC知道吗？go使用了gc算法说说看
go1.14之后的抢占式调度知道吗
操作系统 线程和进程的区别
操作系统进程调度说说看
其他 设计模式知道吗? 常见的设计模式说说看?</description></item><item><title>Go处理error</title><link>/2021/05/23/go%E5%A4%84%E7%90%86error/</link><pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/23/go%E5%A4%84%E7%90%86error/</guid><description><![CDATA[大道至简的error go的错误处理就只有一个errors包和一个error接口，这个接口只包哈一个Error方法，该方法返回一个string，这个包的代码很少，只有两个文件：
 errors.go wrap.go  go的error也就是通过创建一个错误提示的字符串的方式，然后通过返回值来返回这个错误，除非这个函数能保证一定能执行成功，否则每个函数都必须返回一个error
func f() error{ return errors.New(&#34;error&#34;) //返回error接口 } 下面来看下errors/errors.go的源码，不过10行左右
func New(text string) error { return &amp;errorString{text} //返回errorString指针 } //实现了error接口 type errorString struct { s string } //获取错误字符串的方法 func (e *errorString) Error() string { return e.s } ​
自定义error 我们只需要实现error接口也就是重写Error()方法即可自定义错误
type ZeroDivisionError struct { msg string code int } func (e ZeroDivisionError) Error() string { return fmt.Sprintf(&#34;[%d]:%s&#34;, e.code, e.msg) } type NullPointerError struct { msg string } func (e NullPointerError) Error() string { return fmt.]]></description></item><item><title>MySql事务和锁</title><link>/2021/05/23/mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/</link><pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/23/mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81/</guid><description>为什么需要有事务 事务的出现就是为了 保障数据一致性，将多条逻辑相关的SQL语句当做一件事情来做，要么都成功要么都失败
最经典的场景就是转账业务: 当A给B转账时，B账户余额增加的同时必须保证A账户余额减少，也就是说必须保证A和B账户的总钱款大小前后一致，两个账户的钱总量不会多也不会少
一个事务中包含一条或则多条逻辑相关的操作(SQL)，这些操作看作是一个整体，不可分割，当做一件事情来做。如果其中一条或多条SQL失败了则代表此次事务(这件事情)就失败了，则之前执行过的SQL必须全部失败，全部执行回滚 (原子性) 不管事务是否成功，数据必须保持一致性，不会出现错误 并发操作下，事务最难控制 事务的执行过程中最需要关注的就是 事务并行和事务隔离 问题，就是说多个事务必须是隔离的，事务A不能影响事务B的执行，这也是事务中最难处理和最难理解的一部分
​
事务四大特性ACID 原子性 Atomicity
事务是数据库的逻辑工作单位，不可分割，事务中包含的各操作要么都做，要么都不做
一致性 Consistency
一致性是指事务将数据库从一种一致性状态变为下一种一致性状态，在事务开始之前和之后，数据库的完整性约束没有被破坏
比如转账的例子，两个账户的钱款总量在转账前后还是一致的，如果B余额增加了但是A余额没有扣除那么就会凭白无故多出一部分钱来，这就引发钱款不一致的状况了
再比如A的余额为0了，此时A还要给别人转账就不合适了，因为余额必须&amp;gt;=0。如果余额出现负数，这也导致了数据不一致状况
还有年龄不能为负数，红绿灯只有三种颜色，人民币最大面值为100等，这些约束都必须要符合真实世界的情况，都必须和真实世界保持一致性
隔离性 Isolation
每个事务都是隔离的，互相不影响，一共有4个隔离级别
不同事务在提交的时候，必须保证最终呈现出来的效果是串行的。比如两个顾客同时买一件衣服，衣服总量只有2件了。此时顾客A买了1件提交了，顾客B买了1件也提交了。那么最终的衣服总量必须减少为0，而不是1。如果在RR隔离级别下，顾客A和B在事务没提交之前看见的衣服总量都为2，因为他们是同时开启事务的，假设A先提交了，但是B看到的余量依旧是2件(RR隔离级别)，当B再买并且提交之后，则必须还剩余0件，而不是剩余1件，必须保障数据的一致性。也就是说虽然他们看起来是并行执行的事务，但是最终的效果一定要是串行的效果。
持久性 Durability
事务一旦提交，它对数据库中的数据的改变就应该是永久性的，必须持久化到磁盘
​
MySql事务的实现 原子性: undo log 实现 (记录了事务修改之前的数据，当事务在执行过程中如果失败了那么当前事务就处于不一致的状态，这样可以回滚到上一个一致性的状态) 持久性: redo log 实现 隔离性: 锁+MVCC 实现 一致性: 通过原子性、持久性、隔离性实现 ​
隔离性和四大隔离级别 1、读未提交 Read Uncommitted
一个事务还没提交时，它做的变更对他事务可见
脏读 不可重复读 幻读 2、读已提交 Read Committed Oracle默认的隔离级别
一个事务只有提交时它做的变化才对其他事务可见，该级别会造成 在事务中两次读取数据不一致的情况，也就是不可重复读
不可重复读 幻读 3、可重复读 Repeatable Read MySql、Innodb默认的隔离级别</description></item><item><title>Go中的slice</title><link>/2021/05/22/go%E4%B8%AD%E7%9A%84slice/</link><pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/22/go%E4%B8%AD%E7%9A%84slice/</guid><description>数组 数组值拷贝
func main(){ a1:=[...]int{1,2,3} a2:=a1 log.Println(a1,a1[0]) log.Println(a2,a2[0]) //也可以通过下标访问 a2[0] = 10 log.Println(a) //a[0]=1 } 数组指针传递
//通过指针访问数组 func main(){ a:=[...]int{1,2,3} a2:=&amp;amp;a log.Println(a,a[0]) log.Println(a2,a2[0]) a2[0] = 10 log.Println(a) //a[0]=10 } ​
len和cap的区别 len 代表底层数组可访问的范围，用索引访问不可越过这个界限
cap 代表底层数组的实际空间长度，不可用索引访问，如果append 元素时没有超过这个cap，则不再创建底层数组，直接在len空间后面扩展。否则开辟新的空间，同时增大cap（这里有一个增大规则），所以如果要频繁的扩容，适当设置大一些的cap能减少开销的，设置大的cap是为了防止多次扩容拷贝造成开销
func main(){ slice1 := []int{1,2,3} //len=3 cap=3 slice2 := make([]int,2) //len=2 cap=2 slice3 := make([]int,2,4) //len=2 cap=4 } func main(){ arr:=make([]int,2,10) // len=2 cap=10 arr[0]=1 arr[1]=2 //arr[2]=3 //报错 // len=6 cap=10 arr = arr[:6] //扩容,不会再申请空间 arr[2]=3 // [1,2,3,0,0,0] //会在len后面添加,如果len&amp;gt;cap则会进行扩容 此处不会扩容 arr = append(arr,888) // len=7 cap=10 //arr=arr[:11] //报错 超过cap的大小，此时必须用过append进行扩容 } func main(){ //下面的切片引用切片 指向同一个底层数组 cap右界限都是和父亲一样的 a1 :=[]int{1,2,3,4,5,6,7,8} // len=8 cap=8 a2 :=a1[:3] //[1,2,3] len=3 cap=8 a3 :=a1[:5] //[1,2,3,4,5] len=5 cap=8 } ​</description></item></channel></rss>