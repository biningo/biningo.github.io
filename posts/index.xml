<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - lyer's blog</title><link>/posts/</link><description>所有文章 | lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Wed, 28 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/" rel="self" type="application/rss+xml"/><item><title>为什么数组下标从0开始?</title><link>/2021/04/28/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%95%B0%E7%BB%84%E4%B8%8B%E6%A0%87%E4%BB%8E0%E5%BC%80%E5%A7%8B/</link><pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/28/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%95%B0%E7%BB%84%E4%B8%8B%E6%A0%87%E4%BB%8E0%E5%BC%80%E5%A7%8B/</guid><description>先说答案吧:
历史问题，C语言数组下标使用0，于是之后的语言都使用0 数组的偏移运算规则 历史问题这个不用多说了，下面说一下第二条原因
我们知道数组因为内存都是连续存放的，每个元素的大小都是固定的，所以支持随机访问，我们只需要根据偏移和元素大小来计算出地址即可实现随机任意的访问数组中的元素，所以随机访问效率为 O(1)
数组查找一个元素的效率为O(n)，如果是有序数组查找一个元素使用二分的话那就是O(logn)
a[i]的地址 = a + i * size 我们看到，如果是第一个元素，那么i=0，如果是第二个元素那么i=1 ，这就是为什么数组下标从0开始的原因
但是如果硬要从1开始的话，那么上述的公式就会变成如下:
a[i]的地址 = a + (i-1) * size 这样就会多一次i-1的减法操作，产生不必要的消耗，因为数组可能会进行一个频繁的随机查找</description></item><item><title>链表总结</title><link>/2021/04/28/%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93/</link><pubDate>Wed, 28 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/28/%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93/</guid><description>链表分类 链表主要分为一下几类:
单链表 循环链表 双链表 ​
各个链表比较 开发中最常用的链表就是 循环双链表
循环链表和单链表对比起来，循环链表有如下几个优点:
通过任意一个节点即可以遍历所有的节点 单链表和双链表对比起来，双链表有如下几个优点:
可以轻松获取一个节点的前后节点 双链表的删除和插入节点效率更高更方便 双链表遍历更方便，可以从一个节点开始可以往前往后遍历 ​
链表和数组的比较 随机访问
数组支持随机访问，随机访问的时间复杂度为O(1)，但是链表不支持随机访问，如果要访问指定位置的节点必须遍历前面所有的节点，时间复杂度为O(n)
查找元素
链表和数组查找元素的时间复杂度都是O(n) ，但是对于一个有序的数组可以使用二分查找来加快速度，此时时间复杂度为O(logn)，但是对于链表就没有办法进行二分了
对于元素的插入和删除，链表的时间复杂度为O(1)，而数组则为O(n)，因为数组需要进行元素的移动，链表只需要改变指针即可
总结
如果是需要频繁进行随机访问的时候可以使用数组，如果需要频繁进行增加和删除则可以考虑使用链表</description></item><item><title>Java并发总结</title><link>/2021/04/27/java%E5%B9%B6%E5%8F%91%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/27/java%E5%B9%B6%E5%8F%91%E6%80%BB%E7%BB%93/</guid><description>TODO</description></item><item><title>常用设计模式总结</title><link>/2021/04/27/%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/27/%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</guid><description>单例模式 单例模式有两种实现方式:
饿汉式单例
类一加载就创建单例对象,如果对象比较多比较大并且在运行中始终没有用到那么就白白的消耗内存了
饿汉模式可以通过如下几个方法来实现:
直接赋予属性值 静态代码块 Enum枚举(Java推荐方式) 懒汉式单例
懒汉和饿汉相反，只有当对象用到的时候才创建，但是这种模式需要考虑一个并发问题，如果处理的不恰当的话就会破坏单例而创建出两个对象
实现饿汉的方式主要有下面几个:
静态内部类(Java语法特性，只有用到静态内部类的时候静态内部类才会被加载) 方法级加上同步锁 双重检查，控制锁的粒度更小 上面的单例都会被 反射 给破坏，所以Java推荐以Enum方式创建单例来防止反射破坏单例，Java在编译层面防止用反射创建Enum对象
容器注册式单例
还有一种 容器注册式单例 ，在Spring中会有一个IOC容器，如果没有显示指定对象需要多个，那么Spring都只会创建一个单例对象并且注册进IOC容器，需要的时候直接去这个容器中获取，如果容器中没有则进行创建并且保存到容器中，如果有则直接从容器中取出来返回，这个容器可以简单的看成是一个ConcurrentHashMap
容器注册式单例和对象式单例的区别?
下面列出一些具体的应用:
Runtime类使用的就是饿汉式单例，这是一个JVM运行时类，记录了JVM运行时的一些信息比如JVM可用的堆内存，可用的CPU个数等
Spring中会解析XML配置文件然后通过BeanFactory创建单例的Bean对象同时注册到IOC容器中供程序进行DI注入
我们在使用JDBC连接数据库的时候创建的JDBC连接对象是单例的，因为我们连接对象仅仅只是维护了一些连接数据库的参数，查询的时候会根据这些参数创建TCP连接，所以这样的连接上下文对象也只需要一个即可
​
工厂模式 工厂模式有三种，三种模式都是逐步演变过来的?
简单工厂
所有对象的创建都在一个工厂类里，工厂类职责过于复杂
工厂方法
定义一个工厂接口，每个类都定义一个创建他本身的工厂类，缺点就是工厂类随着类的增加会逐渐增加
抽象工厂
在工厂方法上面做的一个改进，不为每个类都创建工厂类了，而是只为同一类对象只创建一个工厂类，抽象工厂所关注的是如何创建一系列的类
比如美的和海尔各自有自己的工厂类，美的工厂只负责创建美的空调、美的冰箱、美的电磁炉等，而海尔工厂只负责创建海尔冰箱、海尔空调、海尔电磁炉等
依赖注入Dependency Injection其实就是用工厂模式来创建对象的</description></item><item><title>锁</title><link>/2021/04/26/%E9%94%81/</link><pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/26/%E9%94%81/</guid><description>什么是锁 锁其实就是一个变量，保存在内存中，比如一个flag，初始化为false ，当被线程加锁之后就将他设置为true，当一个线程拿锁时会检测这个变量是否上锁，如果没有上锁也就是值不为true则可以拿到锁
但是难度在与置位flag要求是一个原子操作，并且CPU还有一个缓存问题需要解决TODO
​
互斥锁和自旋锁 互斥锁 在加锁失败之后会释放CPU资源让给其他线程，所以互斥锁在加锁失败之后会引发一个线程调度，线程调度是有开销的，这就是为什么互斥锁会产生开销的原因
如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长
自旋锁 线程在加锁失败之后会进入一个 忙等 的一个状态，相当于当前线程并不会放弃CPU而是进入一个空转的状态，一旦锁被释放了就可以立即获得锁，所以自旋锁的消耗在于空转时的消耗，不过CPU提供了空转指令PAUSE能大大降低这种消耗，所以如果被锁住的处理代码很长的话则不适合使用自旋锁
​
参考 面试官：你说说互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景</description></item><item><title>为什么DNS使用UDP?</title><link>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88dns%E4%BD%BF%E7%94%A8udp/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88dns%E4%BD%BF%E7%94%A8udp/</guid><description>DNS协议 在讲解为什么之前我们先来讲解什么是DNS协议，以及DNS协议的一些细节
DNS协议的作用就是建立 域名和IP地址的映射，因为IP地址太长并且没有语义所以需要给IP一个域名，DNS协议的作用就是将域名转化为IP地址，这就是DNS协议的主要功能，当然还有其他功能比如记录CNAME、IP地址负载均衡等
浏览器在请求一个网址之前需要通过DNS协议获取到这个网址的IP地址这样才可以进行网络通讯建立TCP连接，因为网络中都是以IP地址来识别一个主机的
那么浏览器向谁请求DNS协议呢？这就是DNS服务器的功劳
DNS服务器是专门用来记录域名以及IP地址的映射的一个服务器，其他计算机可以通过DNS协议来请求DNS服务器来查询他所需要的信息，这些信息也是通过DNS协议返回回去的，主机只需要依照DNS协议的规范规则进行请求并且解析响应即可获取信息
DNS服务器主要会记录域名的如下几种记录:
类型 解释 A IP地址记录Address 记录域名对应的IP AAAA IPV6的地址记录 NS DNS服务器记录（Name Server），返回记录此服务器的DNS服务器域名 CNAME 规范名称记录（Canonical Name），返回另一个域名，即当前查询的域名是另一个域名的跳转 SRV 用于服务发现和负载均衡 下面来看一个DNS查询icepan.cloud的完整过程:
dig -t A icepan.cloud +trace .是根DNS服务器，查询会先根据缓存在本地的根域名服务器的NS记录和A记录去查询到权威域名服务器对应的A记录和NS记录
下面是13组根域名服务器对应的NS记录
. 7117 IN NS g.root-servers.net. . 7117 IN NS l.root-servers.net. . 7117 IN NS d.root-servers.net. . 7117 IN NS b.root-servers.net. . 7117 IN NS h.</description></item><item><title>为什么TCP会产生粘包问题?</title><link>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E4%BC%9A%E4%BA%A7%E7%94%9F%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E4%BC%9A%E4%BA%A7%E7%94%9F%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/</guid><description>概述 粘包 就是指应用层的多条消息被合并为一个TCP包了，这个其实在发送端和接收端都会产生
还有一种现象叫拆包，指的是应用层数据被拆分为多个TCP包了
​
发送端 正常的情况
每个应用层数据都会被封装为一个TCP包然后发送
两个包粘在一起的情况
如果应用层传递下来的数据太少那么TCP协议会等待更多的数据再发送，这样可以提高传输效率，防止大头儿子的情况
粘包和拆包一起的情况
如果应用层数据太大超过了TCP协议的MSS大小，则会发生拆包
​
接收端 接收端如果来不及处理数据，那么多个到达的TCP包都会加入缓存队列，此时也会发生粘包现象
​
为什么UDP不会产生粘包问题 因为TCP是面相流的，不认为应用层的消息是一条一条的，只是将应用层传递下来的数据看成一个数据流，没头没尾
而UDP则是基于报文的，将应用层的数据看成是一个完整的数据包，所以不会进行拆分和合并，不管应用层传递下来多大多小的数据都只会封装为一个UDP包进行传输，接收端也一样会将接受到的UDP报文完整的交付给应用层
​
参考 TCP粘包拆包及解决方法
什么是TCP粘包？怎么解决这个问题</description></item><item><title>为什么TCP是面相字节流的?</title><link>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E6%98%AF%E9%9D%A2%E7%9B%B8%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E6%98%AF%E9%9D%A2%E7%9B%B8%E5%AD%97%E8%8A%82%E6%B5%81%E7%9A%84/</guid><description>TCP和UDP的区别 其实这个标题可以改为 【TCP和UDP的区别】
我们知道TCP只能进行一对一的传输，而UDP则可以进行一对一、多对多、一对多、多对一传输，主要原因就是TCP会建立虚拟通道建立一个连接来保证数据包的可靠传输，数据包丢了必须进行重传
UDP就不需要保证可靠传输，只要把数据封装为UDP报文填上目标的IP+端口发送出去就行，其它的都交给网络了，不管到没到。
所以一个主机可以发送UDP包给任何的主机而不需要提前建立连接，如果目标主机有监听这个端口那么就可以接收到数据，没有监听则会把这个包丢掉
同理一个主机也可以接受来自任意主机的UDP报文，只需要监听着端口等待数据即可
所以UDP报文其实只是相当于给IP报文加上了个IP+端口而已，继承了IP包、以太网数据帧的特性，不管网络拥塞不拥塞只要应用层有数据就发送，而TCP报文就复杂了，需要记录各个信息，这些信息都是一些维护连接，控制流量的一些信息
TCP是面相字节流的，而UDP是面相报文的
这句话估计已经耳熟能详倒背如流的，那么什么是面向字节流呢？什么是面相报文呢？
​
什么是面相字节流 字节流可以理解为水流，TCP连接会建立一个虚拟通道(其实就是双方维护连接的数据结构，发到哪了收到哪了下面该发那段数据了)，建立通道之后这样就只能一对一的进行可靠传输了，TCP会将应用层的数据看成是一个无结构的字节流数据，简单来说就是没头没尾
如果应用层传递下来的数据太少则TCP可以等一等，积累一些数据再封装为一个TCP包发送，这样就提高传输的效率，因为如果数据大小都比TCP报文头的数据还小这样传输数据的效率是不划算的，这样将就会将应用层传递下来的多个数据合并为一个TCP包进行传输
如果应用层传递下来的数据太多，那么TCP就会拆分为多个TCP报文进行传输，因为TCP报文有一个MSS规定了报文的最大大小 ，这个值和以太网的MTU大小有关，如果一个TCP报文不规定合适的MSS 那么可能会被拆分为多个IP包进行传输，这个就会增加IP包拆分和组装的消耗，所以MSS应该和MTU大小接近不能超过这个值
每次发送的数据包大小都是不一致的，这个和网络状况以及对方的数据接受能力有关，也就是滑动窗口和拥塞控制窗口
​
什么是面相报文 UDP是面相报文的，UDP将应用层数据看作是一个有头有尾的完整的数据包，
也就是说不管应用层传递下来多少数据，多大的数据，UDP都会封装为一个完整的数据包发送出去
接收端也不管接受到了多大多小的UDP数据包都不会进行拆分和组装，而是完整的将UDP报文数据上交给应用层
​
总结 总的来说，TCP是以一次连接的建立和断开为单位进行传输数据的，在连接还没有断开之前一直可以往这个通道里传输数据流，并且不知道这个连接什么时候断开，只有当应用层通知连接可以关闭即开始4次握手断开连接，连接建立代表数据开始传输，连接结束代表数据传输完毕，所以说TCP是面相字节流
UDP则以一次数据包的发送接受为单位，只要应用层传递下来数据，UDP就封装为一个完整的UDP数据包发送出去，此时就可以表示此次的发送已经完成，后面的发送都是独立和无关的都代表着一次UDP连接发送</description></item><item><title>为什么TCP需要3次握手</title><link>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E9%9C%80%E8%A6%813%E6%AC%A1%E6%8F%A1%E6%89%8B/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E9%9C%80%E8%A6%813%E6%AC%A1%E6%8F%A1%E6%89%8B/</guid><description>为什么TCP连接是3次握手 注意上面的初始seq号是随机生成的，对方返回的ack必须是seq+1
一般我们人和人打招呼一来一回两次即可，但是放到网络上就不能这样了，因为网络环境是比较复杂并且不稳定的
TCP进行3次握手主要为了如下几个原因:
防止重复的历史连接 建立双方都承认的稳定的TCP连接 初始化两端的seq序列号 防止重复的历史连接 A向B发送请求连接的SYN包，如果网络拥塞A一直得不到B的ACK，则A会继续发送SYN包请求连接直到超过了重试次数则放弃
如果B同意连接，则会回复A一个ACK并且A也收到了，如果只进行两次连接，那么此时就代表建立了TCP连接，然后他们进过短暂的通讯之后就断开了，此时如果之前A重试的SYN包又到达了，则B是无法判断这个是不是A之前重试的SYN包，以为A还需要继续建立连接，那么B就会回复一个ACK又建立连接，这样就会出现很多不符合预期的连接于是TCP需要三次握手，在B发送ACK的时候还需要等待A的应答ACK，如果A收到了B的ACK并且判断出这是之前重试的SYN包(因为A有足够的上下文来判断，而B没有)，于是A就不会同意建立连接，发送RST包来终止这次请求，告诉B不需要进行重试了
防止建立错误的连接 如果进行两次握手就建立连接，这种连接是不可靠的
A发送SYN包给B，B此时需要回复一个ACK，如果只进行两次握手的话，那么此时B就认为和A建立了连接，但是有下面两种情况会产生错误:
B的ACK丢了 但是如果B回复的ACK丢了，那么A没有收到B的ACK则以为B不想建立连接于是就一直重试直到超过规定次数，但是B却认为已经和A建立连接了，这纯属单相思
A挂了 如果A挂了，那么B发送ACK之后却认为已经和A建立连接，这样也是不合理的
A不同意建立连接而没有回复ACK 比如A判断这个SYN包是之前过期的包，于是不同意建立连接不回复ACK，但是此时B却认为建立了连接，这样也是不合理的
所以B需要收到A的应答之应答之后才可以认为建立了连接
如果B的ACK到达了A并且A也同意建立连接那么A就会回复一个ACK给B，此时A就可以认为已经和B建立连接了，于是就可以发送数据给B或则等待B发数据
如果B一直没收到A的应答则会继续发ACK，此时A则会继续回复ACK直到B收到，如果B收到了A的ACK则可以认为建立了连接
初始化Seq号 A 要告诉 B，我这面发起的包的序号起始是从哪个号开始的，B 同样也要告诉 A，B 发起的包的序号起始是从哪个号开始的，只有三次握手才可以100%确定对方都收到了自己的seq号
seq号通常需要随机产生，如果都从1开始那么会出现问题
比如 A 连上 B 之后，发送了 1、2、3、4 这4个包，但是发送 4 的时候丢了，或者绕路了，于是重新发送
后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送1、2、3但是压根没想发送 4，但是上次绕路的那个 4 又回来了，发给了B，B认为，这就是下一个包，于是发生了错误
另外一个原因就是防止伪造TCP包进行攻击，seq号如果每次都固定，那么黑客能可以很容易伪造TCP包进行攻击，如果seq号是随机的那么黑客就很难直到这个包到底属于哪个范围哪一部分，这样就加大了攻击的难度
​
总结 TCP的握手其实可以一直进行下去，4、5、6、400&amp;hellip;.
但是进行再多的握手其实和3次握手的结果都是一样的，是没必要的
3次握手之后双方都刚好进行了 一收一发，这样就可以确定建立连接了
​
参考 为什么 TCP 建立连接需要三次握手</description></item><item><title>为什么TCP需要4次握手</title><link>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E9%9C%80%E8%A6%814%E6%AC%A1%E6%8F%A1%E6%89%8B/</link><pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/04/25/%E4%B8%BA%E4%BB%80%E4%B9%88tcp%E9%9C%80%E8%A6%814%E6%AC%A1%E6%8F%A1%E6%89%8B/</guid><description>为什么TCP需要4次握手 第一次: A没数据发送了则主动要求断开连接，于是A向B发送了一个FIN包
第二次: B收到A的FIN包则需要回复一个ACK表示收到了A的FIN请求，但是此时B可能还有数据需要发给A(比如之前没有收到A的ACK的数据需要重发等)，这种情况下A可以继续接受B的数据但是不会主动发送数据给B只会回复ACK，所以B发送的ack号永远都是一样的
第三次: B将剩余的数据发送完毕之后就需要发送一个FIN包给A表示”自己的数据发送完毕了，我要断开了“
第四次: 此时A必须回复这个FIN表示收到了B的断开请求，此时就进入 TIME_WAIT 状态等待一段时间才会断开，B如果收到了A的ACK则断开连接，如果没收到则还会继续发送FIN请求，此刻因为A还处于 TIME_WAIT 状态则会继续回复ACK
​
为什么需要 TIME_WAIT 回复B最后一个FIN包 重发ACK包 接受之前还遗留在网络上的数据包 ​
参考 https://www.bilibili.com/video/BV1x441177hF?from=search&amp;amp;seid=3231512348930851320</description></item></channel></rss>