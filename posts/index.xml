<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - lyer's blog</title><link>/posts/</link><description>所有文章 | lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Thu, 03 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/" rel="self" type="application/rss+xml"/><item><title>Linux权限和用户</title><link>/2021/06/03/linux%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/03/linux%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90/</guid><description>用户和用户组 一个用户必须属于某个组，创建新用户的时候如果没有指定用户组则会创建一个同名的默认用户组
用户组和用户的关系是多对多的关系，一个组里可以有多个用户，同理一个用户也可以属于多个用户组，但是每个用户都会有一个默认组，而其他组则是附加组在/etc/passwd文件中记录的用户组就是用户所属的默认组，而在/etc/group中会记录每个用户组里面的其它用户成员列表(用户组的主成员不记录在此)
/etc/passwd记录的是用户相关的一些信息，每个用户占用一行
用户名:口令(都为x):用户ID:用户组ID:用户注释:用户家目录:shell解释器 testuser:x:1001:1001:TmpUser:/home/testuser:/bin/sh /etc/group记录的是用户组相关的信息，每个用户组占一行
组名:口令(都为x):用户组ID:组内用户列表 audio:x:29:pulse,pb #主用户不会记录在这里 /etc/shadow 记录的是用户加密之后的密码信息
/etc/default/useradd 新用户默认设置的配置文件
SHELL=/bin/sh #新用户的默认shell EXPIRE=2020/06/08 #新用户的默认过期时间 不配置则永久 .... ​
用户和用户组相关的Linux命令 我们直接修改配置文件也是可以的，但是Linux也为我们提供了一些命令，本质上都是修改底层的配置文件
新建/删除/修改用户
useradd/userdel/usermod 用户组增删改
groupadd/groupdel/groupmod 修改用户密码
passwd 为用户添加到指定的组中 (直接修改/etc/group命令也可)
#添加用户到指定的用户组中 不加-a则表示替换 #这里需要注意: 用户的默认组是不会被修改掉的 这个操作只能修改附加组 usermod -a -G g1,g2,g3 查看用户信息
id/who/users/whoami/last/lastb ​
sudo命令和sudoers配置 sudo的作用是一个用户借用其它用户的权限来执行相关命令，需要配置/etc/sudoers文件，Linux会判断是否符合sudo文件的配置才会决定是否能够借权
用户名 主机=(用户:用户组) NOPASSWD:命令列表 #pb用户可以在 所有主机登入 执行 所有用户:所有组 的所有命令 并且不需要输入密码 pb ALL=(ALL:ALL) NOPASSWD:ALL #表示admin组内的用户规则 %admin ALL=(ALL:ALL) ALL 下面再来看几个案例
#相当于(root:root) peter ALL=(root) NOPASSWD: ALL lucy ALL=(ALL) chown,chmod,useradd papi ALL=/usr/sbin/*,/sbin/*,!</description></item><item><title>性能指标QPS</title><link>/2021/06/03/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87qps/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/03/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87qps/</guid><description>TPS每秒事务数 Transactions Per Second 每秒处理的事务数目，一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程
比如我请求访问twitter页面，则twitter服务器会返回一个twitter完整的页面给我，这个页面可能还包括一些css、js、各种数据的请求，这一整个页面的访问和全部数据的响应就叫TPS
TPS过程包括: 客户端请求服务端+服务端内部处理+服务端返回客户端
tps=处理事务数/秒 ​
QPS每秒查询率 Queries Per Second 每秒查询率，表示一台服务器每秒能够响应的查询次数，代表的是服务器的机器的性能最大吞吐能力
qps基本类似于 tps，但是不同的是对于一个页面的一次访问，形成一个 TPS，但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求就可计入QPS之中
简单来说QPS就是对每个后端请求的度量，比如一个页面要请求多个接口，那么对每个接口的请求可以归结为QPS，当用户请求页面到页面完整的展示给用户这一个过程可以归结为TPS
也就是说如果一个页面只会访问一个接口一个请求，则TPS=QPS
qps=能处理的请求数/秒 ​
PV页面浏览量 page view 页面浏览量，用户每次对页面的访问都计入PV，比如我对一个页面刷新了5次那么PV就加5
​
UV独立访客数 Unique Visitor 独立访客访问数，可以理解为IP访问次数，比如我对一个页面刷新了100次，但是UV还是只加1，因为IP还是我</description></item><item><title>缓存一致性</title><link>/2021/06/02/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</link><pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/02/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</guid><description>什么是缓存一致性 操作缓存比操作Mysql数据库要快，如果流量大的话可以先将数据保存在缓存中，等空闲的时候再将缓存中的数据持久化到数据库中
还有一些热点数据我们也可以预先从数据库中加载到缓存中，那样在流量大的时候就不需要每次都从数据库里面去读取数据了
因为缓存和数据库是两个不同的地方，最容易出现的问题就是缓存的数据和数据库中的数据不一致问题: 可能从缓存中读取的数据是旧值，又或者我们保存在缓存中的数据还没有持久化到Mysql数据库中
为了保证缓存一致性，减少数据不一致的情况，我们必须合理的使用缓存
​
不更新缓存，而是删除缓存 后端数据库如果改变的话，我们不应该更新缓存而应该删除缓存，直到下一次数据读取的时候再加载数据库中最新的缓存
如果数据改变了，我们如果去更新缓存的话则会出现很多问题
一、线程安全，脏数据问题
下面有两个并发请求A、B同时更新了数据库
A更新数据库 B更新数据库 B更新缓存 A更新缓存 由于网络原因，虽然A是先于B更新数据库，但是此时A却后于B更新缓存，此时的缓存的数据就是A的数据而不是最新的数据B，这样就造成了数据不一致的问题
如果我们在更新数据时直接删除数据，此下次再来读取的时候加载一次数据库即可，那么加载的数据一定是最新的
二、频繁更新缓存造成不必要的浪费
如果在写多读少的场景下，缓存数据会进行频繁更新，但是读数据却很少，则会造成资源浪费，还不如直接将缓存删除，下次读的时候只需要一次cache miss的消耗
同时如果数据需要进过复杂的运算和逻辑处理才能写入缓存，那么频繁的更新缓存也会造成不必要的消耗
​
先操作数据库，再删除缓存 在写数据的时候，我们一般是先写数据库，再删除缓存 这样才能减少数据不一致的问题
先删除缓存，再操作数据库
此方案在并发读写的时候也会造成数据不一致性的问题
假设有线程A、B
线程A请求写操作，于是线程A会删除缓存数据再进行数据库写操作 此时线程B在A写操作的过程中进行读操作，引发一次cache miss 由于B是在A写事务执行过程中来读取的，于是B加载到缓存中的数据还是之前的老数据 此时A写操作完成，这样就造成了缓存和数据库的数据不一致性，如果缓存的数据没有过期时间的话则其他客户端读取到的数据就一直都是脏数据直到下次 发生数据写操作删除缓存 先更新数据库，再删除缓存
这种方案不会引发上面的缓存不一致的问题，一旦数据库的数据更新完毕之后就会立即删除缓存中的数据，则下次再读取时就会引发一次cache miss就能读取到最新的数据
但是也会有很小的概率会发生数据不一致的状态
假设有两个并发线程A、B
A请求读取数据，此时缓存凑巧失效了，A引发cache miss之后读取数据 B请求在A读取数据的同时在写入新值到数据库中，并且写入完成之后删除了缓存 此时A又将读取到的旧值加载到了缓存中，引发数据不一致的问题 上面的情况发生的概率是比较小的
​
参考 缓存一致性问题</description></item><item><title>XSS和CSRF攻击</title><link>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</guid><description><![CDATA[XSS攻击 Cross Site Script 跨站脚本攻击，为了不和CSS混淆，所以缩写为XSS
在网页的输入框中最容易被XSS攻击，比如在一个评论框中，用户输入了以下内容
&lt;script&gt;alert(“hello,XSS”)&lt;/script&gt; 那么网页在渲染这段数据的时候就相当于嵌入了一段js脚本代码，以后所有用户访问此网站都会被执行这段代码
上面注入的只是简单的弹窗代码，但是如果注入的是一些恶意的js脚本，那么每个用户访问都会在后台默默的执行注入的恶意js代码
恶意的js代码可以做啥呢
 窃取用户的Cookie，如果Set-Cookie没有设置HttpOnly的话则可以被js代码读取并且通过网络转发给黑客，那么用户的Cookie数据就泄露了 伪造用户，通过js脚本使用用户的Cookie来请求网站，以此假冒用户登入 (利用浏览器的同源策略可以避免) 劫持流量实现恶意跳转，每当用户访问时js代码执行强行跳转劫持用户到另外的站点  预防XSS
  过滤用户的输入
  将用户的输入内容插入特殊符号进行转义
  ​
CSRF攻击 Cross Site Request Forgery 跨站请求伪造攻击
攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求
利用受害者在被攻击网站已经获取的注册凭证Cookie，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的
下面是一个案例
 小明登入了银行网站A，网站A设置Cookie来作为用户之后请求的Token 小明在登入银行A之后被诱导点击了网站B 网站B向A发送了一个转账请求，浏览器会携带上之前网站A设置的Cookie A收到请求之后就会验证通过，此时小明的钱就被网站B转走了  网站B在受害者不知情的情况下冒充受害者，通过Cookie让网站A执行了网站B定义的操作
由于浏览器有同源策略，因此网站B向网站A发送请求会被浏览器认定为跨域，因此会被浏览器拦截
但是有下面几种情况不会被拦截:
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为浏览器认为这些标签肯定是网站主动引用外部资源所加入的的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
  浏览器为了方便表单的提交，所以 &lt;form&gt; 中填的action 也不会限制同源策略，可以填写任意的URL，一旦用户提交表单那么就会请求URL发生跨域。如果用户在恶意网站里面填写并提交了表单则可能会被CSRF攻击
  如何防止CSRF攻击？
 服务端验证请求，比如验证HTTP请求头的Referer字段 浏览器同源策略，防止跨域请求 加入token，比如我们可以在请求参数后面附加一个token，每次请求都验证一下这个token，因为黑客并不知道这个token，则可以防止CSRF攻击  ​
参考 如何防止XSS攻击？
如何防止CSRF攻击？
安全篇——如何预防CSRF攻击
Cookie 的 SameSite 属性]]></description></item><item><title>同源策略和跨域请求</title><link>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</guid><description><![CDATA[何为同源，何为跨域 首先需要知道什么是 同源和非同源
同源: 域名、协议、端口 完全一致就是同源头
不同源之间相互访问就叫 跨域访问
google.com www.google.com #域名不一致 不同源 google.com:8080 google.com:9090 #端口不一致 不同源 http://google.com https://google.com #协议不一致 不同源 google.com/b.html google.com/c.html #同源 ​
什么是同源策略 浏览器对于非同源请求做出了如下限制，也就是同源策略
  无法读取非同源的 Cookie、LocalStorage IndexDB等内容
  无法读取和修改非同源的DOM
  无法发送非同源的AJAX，如果发送了非同源请求就会被浏览器拦截
  无法发送非同源的请求
  ​
为什么需要同源策略 如果没有同源策略，那么假如小明在A网站登入了，如果小明在没有注销期间访问了B网站，B网站中携带了js脚本向A网站发起了模拟用户的请求，那么此请求会携带上浏览器保存的Cookie，这样B网站的js脚本就可以模拟小明随意操作了，这就是 CSRF跨站脚本伪造攻击
​
跨域请求 在前后端分离的应用中需要规避这个同源策略，因为这是我们主动发起的跨域请求，自认为是安全的，例如前端地址为abc.com:8080,后端API为abc.com:9090 直接访问API会触发同源策略被浏览器拦截，所以需要想办法跨过去
主要有如下几个跨域请求的方法:
  CORS 跨域资源共享
HTTP设置了跨域专用的请求头，后端API服务器abc.com:9090 告诉浏览器特定URL abc.com:8080的ajax请求可以直接使用，不会激活同源策略
  nginx反向代理
前端通过指定路径 abc.com:8080/api 访问后端请求，nginx配置此前缀的URL反向代理到abc.com:8080
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为这些标签肯定是网站主动引用外部资源的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
所以我通过调用js脚本的方式，从服务器上获取JSON数据绕过同源策略]]></description></item><item><title>HTTP缓存</title><link>/2021/05/31/http%E7%BC%93%E5%AD%98/</link><pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/31/http%E7%BC%93%E5%AD%98/</guid><description><![CDATA[浏览器缓存原理 浏览器会把请求的URL作为key，value就是此次请求对应的响应。每次查找缓存的时候就会到内存或则磁盘去查找key对应的响应信息即可
​
Cache-Control 强缓存 Cache-Control 控制浏览器缓存的时间，注意此头部是通用头部，请求和响应都可以有
如果是服务器响应头部的话则是告诉浏览器此信息可以缓存多久，下面的报文表示可以缓存10s
GET /ping HTTP/1.1 Cache-Control: max-age=10 Content-Length: 4 Content-Type: application/json; charset=utf-8 Date: Tue, 01 Jun 2021 13:23:49 GMT 比如我现在一个重定向到此请求，则下次重定向就不需要再次请求/ping了，直接从缓存里面读取，下面是go后端演示程序
func main() { r := gin.Default() r.GET(&#34;/ping&#34;, func(context *gin.Context) { context.Header(&#34;Cache-Control&#34;, &#34;max-age=10&#34;) context.JSON(200, &#34;OK&#34;) }) r.GET(&#34;/a&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(302) //临时重定向 不会被浏览器缓存 每次请求都会打到后端 	}) r.GET(&#34;/b&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(301) //永久重定向 会被浏览器缓存 下次请求此则直接从缓存中读取响应报文 然后直接重定向到/ping 	}) r.Run(&#34;:8080&#34;) } 用户主动刷新、地址栏重新输入、ctrl+f5强制刷新等动作浏览器会自动的在请头中设置Cache-Control的值为max-age=0 或则 no-cache ，表示直接请求服务器而不从缓存中读取，不管缓存是否过期都会请求服务器]]></description></item><item><title>Go文件读写和IO操作</title><link>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</guid><description><![CDATA[IO接口 io.Reader 读IO接口
type Reader interface { Read(p []byte) (n int, err error) } io.Writer 写IO接口
type Writer interface { Write(p []byte) (n int, err error) } io.Closer 关闭IO接口
type Closer interface { Close() error } ​
文件读取 方式一: 无缓冲直接读取
func fileDemo1() { file, err := os.Open(&#34;/go-test-learn/io/t1.go&#34;) CheckError(&#34;&#34;, err) defer file.Close() content := []byte{} buf := make([]byte, 100) //每次读取的最大byte数组 	for { n, err := file.Read(buf) //返回真实读取的数据字节大小 (&lt;=len(buf)) 	if err == io.]]></description></item><item><title>一致性Hash</title><link>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</guid><description>分布式缓存 为了提高Redis缓存的读写能力，一般会建一个Redis集群，此时我们就需要通过hash算法将key存储到指定的一台节点中，这样每次取这个key的时候到key对应的节点中去获取即可
假如现在有10台Redis，计算key对应的节点的hash公式如下:
node = hash(key)%10 静态分配策略在集群节点数量固定的时候是没问题的，但是当集群节点数量进行动态扩缩的情况下就会出现 缓存雪崩 问题
比如现在新加了10个节点，那么上面的公式就变成了如下:
node = hash(key)%20 也就是说之前所有的key计算出的节点在集群扩大的时候再次计算时就可能不是同一个节点，那么就无法在对应节点中获取到key的缓存。如果这样的key数量很多的话就会造成缓存雪崩问题，那么后端数据库的压力就会在集群扩容的时候剧增
为了解决这个问题，于是就有了后面的 一致性Hash算法
​
一致性Hash算法 一致性hash算法将节点映射到这个环上，同时也将key映射到一个2^32大小的环上，并且沿着key所在的位置顺时针查找，找到的第一个节点就是这个key要保存的节点
如果加了一个node或则减少了一个node，那么只会影响环上的node顺时针对应的前一个node之间的数据
​
节点倾斜问题 当hash环上的节点数量较少时就可能造成节点倾斜问题，比如所有节点都被映射到了同一边的一个角落，那么就会有大量的key只存在一个node上，而其他node则没有多少key
为了解决节点倾斜问题，引入了 虚拟节点 。 就是在每个实际的节点下虚拟出几个不存在的节点将其映射到hash环上，让hash环上节点分布的比较均匀。如果key保存在虚拟节点上，则实际上是保存在这个虚拟节点对应的实际节点中。通过虚拟节点就解决了数据倾斜问题
​
参考 好刚: 7分钟视频详解一致性hash 算法
一致性hash</description></item><item><title>常见的开源数据库</title><link>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>KV数据库 BoltDB go语言写的kv数据库，现在已经停止维护
https://github.com/boltdb/bolt
但是etcd扩展了BoltDB，重新命名叫 BBolt，作为是etcd的底层kv存储
https://github.com/etcd-io/bbolt
levelDB google开源的，使用c++写的kv数据库
https://github.com/google/leveldb
​
时序数据库 influxDB go语言写的时序数据库，分为商业版和开源版，开源版本不支持分布式
https://github.com/influxdata/influxdb
TDengine 用C写的时序数据库，支持分布式，全部开源
https://github.com/taosdata/TDengine
关于时序数据库参考博客 时序数据库 InfluxDB（一）
时序数据库InfluxDB使用详解</description></item><item><title>TCP半连接和全连接队列</title><link>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</guid><description>什么是半连接和全连接队列 操作系统在listen开启监听时就会建立两个队列
半连接 全连接 半连接队列存放的就是一些还没建立TCP连接，并且还在三次握手过程中的客户端连接
全连接队列存放的就是一些已经完全建立TCP连接但是还没被应用层取走的连接，每次应用层调用accept时就会从全连接队列里取一个连接去处理，但是如果队列中没有连接就会阻塞
​
半连接队列 当服务器端在LISTEN状态时能接受其他客户端的TCP建立连接请求，当服务器收到客户端发来的SYN包时就会回复ACK+SYN，此时服务器就进入了 SYN_RECV的状态，这个时候服务器就会将这个连接存放到半连接队列中，并且等待客户端发来应答的ACK
如果在指定时间内客户端没有发第三次握手，则服务器会进行重试直到超过一定次数则会将此连接从半连接队列里面删除
#SYN+ACK重试次数 默认为5 /proc/sys/net/ipv4/tcp_synack_retries 如果客户端发来了第三次握手ACK，则会将此连接放入全连接队列等待用户应用去队列里面取
如果半连接队列满了的话，则服务器不会继续接受客户端的连接请求，当其他客户端想要建立TCP连接发送SYN时，服务器就会发送RST报文告诉客户端 &amp;ldquo;连接失败&amp;quot;或则是直接丢弃
​
半连接队列大小 半连接队列大小收到下面几个因素影响
用户层 listen 传入的backlog （用户传入的全连接队列大小） 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128 （Linux配置的全连接队列大小） int listen(int sockfd, int backlog); //第二个参数 /proc/sys/net/ipv4/tcp_max_syn_backlog #1024 /proc/sys/net/core/somaxconn #4096 如果我们想要增加半连接队列的大小，我们就需要同时增加上面三个值，而单单的增加其中的几个则可能无法增加半连接队列的大小
​
全连接队列 当服务器收到客户端发来的第三次握手的时候，服务器就会将这个连接从半连接队里里面转移到全连接队里面并等待应用去全连接队列里取连接进行处理，应用一旦取走该连接就不会保存在队列里了
全连接队列只是用来保存已经建立TCP连接但是还没被用户取走待处理的连接
如果全连接队列满了的话服务器会使用下面两种策略，用户可以在一下文件中配置
/proc/sys/net/ipv4/tcp_abort_on_overflow 0 全连接队列满了则server会丢弃ACK，当作没收到
即使收到了客户端发来的第三次握手ACK也会丢弃当做没收到，则此半连接就无法进入全连接队里，同时server端也会在超时的时候继续发送SYN+ACK，当重试超过指定次数之后全连接队列还是满的则会因为将此半连接删除
1 全连接队列满了则会发送RST包告诉客户端废除这个连接请求
一般配置为0可以有效的增加服务器的并发能力，可能全连接队列只是短暂的满了，之后会被快速取走，则配置为0之后，在后面重试的ACK中还是可以建立连接的
​
全连接队列大小 全连接大小由操作系统配置somaxconn和用户应用配置的backlog两个值确定的
min(somaxconn, backlog) int listen(int sockfd, int backlog) //用户决定 /proc/sys/net/core/somaxconn #4096 操作系统参数 我们如果要增加全连接大小，则需要考虑操作系统的配置以及应用程序传入的配置，取他们之间最小的一个，也就是说即使应用程序传入的backlog再大，如果somaxconn很小的话则依然无法增加全连接队列的大小</description></item></channel></rss>