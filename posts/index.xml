<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>所有文章 - lyer's blog</title><link>/posts/</link><description>所有文章 | lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Tue, 01 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/" rel="self" type="application/rss+xml"/><item><title>XSS和CSRF攻击</title><link>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/xss%E5%92%8Ccsrf%E6%94%BB%E5%87%BB/</guid><description><![CDATA[XSS攻击 Cross Site Script 跨站脚本攻击，为了不和CSS混淆，所以缩写为XSS
在网页的输入框中最容易被XSS攻击，比如在一个评论框中，用户输入了以下内容
&lt;script&gt;alert(“hello,XSS”)&lt;/script&gt; 那么网页在渲染这段数据的时候就相当于嵌入了一段js脚本代码，以后所有用户访问此网站都会被执行这段代码
上面注入的只是简单的弹窗代码，但是如果注入的是一些恶意的js脚本，那么每个用户访问都会在后台默默的执行注入的恶意js代码
恶意的js代码可以做啥呢
 窃取用户的Cookie，如果Set-Cookie没有设置HttpOnly的话则可以被js代码读取并且通过网络转发给黑客，那么用户的Cookie数据就泄露了 伪造用户，通过js脚本使用用户的Cookie来请求网站，以此假冒用户登入 (利用浏览器的同源策略可以避免) 劫持流量实现恶意跳转，每当用户访问时js代码执行强行跳转劫持用户到另外的站点  预防XSS
  过滤用户的输入
  将用户的输入内容插入特殊符号进行转义
  ​
CSRF攻击 Cross Site Request Forgery 跨站请求伪造攻击
攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求
利用受害者在被攻击网站已经获取的注册凭证Cookie，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的
下面是一个案例
 小明登入了银行网站A，网站A设置Cookie来作为用户之后请求的Token 小明在登入银行A之后被诱导点击了网站B 网站B向A发送了一个转账请求，浏览器会携带上之前网站A设置的Cookie A收到请求之后就会验证通过，此时小明的钱就被网站B转走了  网站B在受害者不知情的情况下冒充受害者，通过Cookie让网站A执行了网站B定义的操作
由于浏览器有同源策略，因此网站B向网站A发送请求会被浏览器认定为跨域，因此会被浏览器拦截
但是有下面几种情况不会被拦截:
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为浏览器认为这些标签肯定是网站主动引用外部资源所加入的的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
  浏览器为了方便表单的提交，所以 &lt;form&gt; 中填的action 也不会限制同源策略，可以填写任意的URL，一旦用户提交表单那么就会请求URL发生跨域。如果用户在恶意网站里面填写并提交了表单则可能会被CSRF攻击
  如何防止CSRF攻击？
 服务端验证请求，比如验证HTTP请求头的Referer字段 浏览器同源策略，防止跨域请求 加入token，比如我们可以在请求参数后面附加一个token，每次请求都验证一下这个token，因为黑客并不知道这个token，则可以防止CSRF攻击  ​
参考 如何防止XSS攻击？
如何防止CSRF攻击？
安全篇——如何预防CSRF攻击
Cookie 的 SameSite 属性]]></description></item><item><title>同源策略和跨域请求</title><link>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/06/01/%E5%90%8C%E6%BA%90%E7%AD%96%E7%95%A5%E5%92%8C%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/</guid><description><![CDATA[何为同源，何为跨域 首先需要知道什么是 同源和非同源
同源: 域名、协议、端口 完全一致就是同源头
不同源之间相互访问就叫 跨域访问
google.com www.google.com #域名不一致 不同源 google.com:8080 google.com:9090 #端口不一致 不同源 http://google.com https://google.com #协议不一致 不同源 google.com/b.html google.com/c.html #同源 ​
什么是同源策略 浏览器对于非同源请求做出了如下限制，也就是同源策略
  无法读取非同源的 Cookie、LocalStorage IndexDB等内容
  无法读取和修改非同源的DOM
  无法发送非同源的AJAX，如果发送了非同源请求就会被浏览器拦截
  无法发送非同源的请求
  ​
为什么需要同源策略 如果没有同源策略，那么假如小明在A网站登入了，如果小明在没有注销期间访问了B网站，B网站中携带了js脚本向A网站发起了模拟用户的请求，那么此请求会携带上浏览器保存的Cookie，这样B网站的js脚本就可以模拟小明随意操作了，这就是 CSRF跨站脚本伪造攻击
​
跨域请求 在前后端分离的应用中需要规避这个同源策略，因为这是我们主动发起的跨域请求，自认为是安全的，例如前端地址为abc.com:8080,后端API为abc.com:9090 直接访问API会触发同源策略被浏览器拦截，所以需要想办法跨过去
主要有如下几个跨域请求的方法:
  CORS 跨域资源共享
HTTP设置了跨域专用的请求头，后端API服务器abc.com:9090 告诉浏览器特定URL abc.com:8080的ajax请求可以直接使用，不会激活同源策略
  nginx反向代理
前端通过指定路径 abc.com:8080/api 访问后端请求，nginx配置此前缀的URL反向代理到abc.com:8080
  所有拥有src属性的 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt; 以及&lt;a&gt;标签等，是不会经过同源策略，因为这些标签肯定是网站主动引用外部资源的所以不需要规定同源策略，例如baidu.com引用了CDN的jquery
所以我通过调用js脚本的方式，从服务器上获取JSON数据绕过同源策略]]></description></item><item><title>HTTP缓存</title><link>/2021/05/31/http%E7%BC%93%E5%AD%98/</link><pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/31/http%E7%BC%93%E5%AD%98/</guid><description><![CDATA[浏览器缓存原理 浏览器会把请求的URL作为key，value就是此次请求对应的响应。每次查找缓存的时候就会到内存或则磁盘去查找key对应的响应信息即可
​
Cache-Control 强缓存 Cache-Control 控制浏览器缓存的时间，注意此头部是通用头部，请求和响应都可以有
如果是服务器响应头部的话则是告诉浏览器此信息可以缓存多久，下面的报文表示可以缓存10s
GET /ping HTTP/1.1 Cache-Control: max-age=10 Content-Length: 4 Content-Type: application/json; charset=utf-8 Date: Tue, 01 Jun 2021 13:23:49 GMT 比如我现在一个重定向到此请求，则下次重定向就不需要再次请求/ping了，直接从缓存里面读取，下面是go后端演示程序
func main() { r := gin.Default() r.GET(&#34;/ping&#34;, func(context *gin.Context) { context.Header(&#34;Cache-Control&#34;, &#34;max-age=10&#34;) context.JSON(200, &#34;OK&#34;) }) r.GET(&#34;/a&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(302) //临时重定向 不会被浏览器缓存 每次请求都会打到后端 	}) r.GET(&#34;/b&#34;, func(context *gin.Context) { context.Header(&#34;Location&#34;, &#34;/ping&#34;) context.Status(301) //永久重定向 会被浏览器缓存 下次请求此则直接从缓存中读取响应报文 然后直接重定向到/ping 	}) r.Run(&#34;:8080&#34;) } 用户主动刷新、地址栏重新输入、ctrl+f5强制刷新等动作浏览器会自动的在请头中设置Cache-Control的值为max-age=0 或则 no-cache ，表示直接请求服务器而不从缓存中读取，不管缓存是否过期都会请求服务器]]></description></item><item><title>Go文件读写和IO操作</title><link>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/go%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%92%8Cio%E6%93%8D%E4%BD%9C/</guid><description><![CDATA[IO接口 io.Reader 读IO接口
type Reader interface { Read(p []byte) (n int, err error) } io.Writer 写IO接口
type Writer interface { Write(p []byte) (n int, err error) } io.Closer 关闭IO接口
type Closer interface { Close() error } ​
文件读取 方式一: 无缓冲直接读取
func fileDemo1() { file, err := os.Open(&#34;/go-test-learn/io/t1.go&#34;) CheckError(&#34;&#34;, err) defer file.Close() content := []byte{} buf := make([]byte, 100) //每次读取的最大byte数组 	for { n, err := file.Read(buf) //返回真实读取的数据字节大小 (&lt;=len(buf)) 	if err == io.]]></description></item><item><title>一致性Hash</title><link>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E4%B8%80%E8%87%B4%E6%80%A7hash/</guid><description>分布式缓存 为了提高Redis缓存的读写能力，一般会建一个Redis集群，此时我们就需要通过hash算法将key存储到指定的一台节点中，这样每次取这个key的时候到key对应的节点中去获取即可
假如现在有10台Redis，计算key对应的节点的hash公式如下:
node = hash(key)%10 静态分配策略在集群节点数量固定的时候是没问题的，但是当集群节点数量进行动态扩缩的情况下就会出现 缓存雪崩 问题
比如现在新加了10个节点，那么上面的公式就变成了如下:
node = hash(key)%20 也就是说之前所有的key计算出的节点在集群扩大的时候再次计算时就可能不是同一个节点，那么就无法在对应节点中获取到key的缓存。如果这样的key数量很多的话就会造成缓存雪崩问题，那么后端数据库的压力就会在集群扩容的时候剧增
为了解决这个问题，于是就有了后面的 一致性Hash算法
​
一致性Hash算法 一致性hash算法将节点映射到这个环上，同时也将key映射到一个2^32大小的环上，并且沿着key所在的位置顺时针查找，找到的第一个节点就是这个key要保存的节点
如果加了一个node或则减少了一个node，那么只会影响环上的node顺时针对应的前一个node之间的数据
​
节点倾斜问题 当hash环上的节点数量较少时就可能造成节点倾斜问题，比如所有节点都被映射到了同一边的一个角落，那么就会有大量的key只存在一个node上，而其他node则没有多少key
为了解决节点倾斜问题，引入了 虚拟节点 。 就是在每个实际的节点下虚拟出几个不存在的节点将其映射到hash环上，让hash环上节点分布的比较均匀。如果key保存在虚拟节点上，则实际上是保存在这个虚拟节点对应的实际节点中。通过虚拟节点就解决了数据倾斜问题
​
参考 好刚: 7分钟视频详解一致性hash 算法
一致性hash</description></item><item><title>常见的开源数据库</title><link>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/29/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93/</guid><description>KV数据库 BoltDB go语言写的kv数据库，现在已经停止维护
https://github.com/boltdb/bolt
但是etcd扩展了BoltDB，重新命名叫 BBolt，作为是etcd的底层kv存储
https://github.com/etcd-io/bbolt
levelDB google开源的，使用c++写的kv数据库
https://github.com/google/leveldb
​
时序数据库 influxDB go语言写的时序数据库，分为商业版和开源版，开源版本不支持分布式
https://github.com/influxdata/influxdb
TDengine 用C写的时序数据库，支持分布式，全部开源
https://github.com/taosdata/TDengine
关于时序数据库参考博客 时序数据库 InfluxDB（一）
时序数据库InfluxDB使用详解</description></item><item><title>TCP半连接和全连接队列</title><link>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</guid><description>什么是半连接和全连接队列 操作系统在listen开启监听时就会建立两个队列
半连接 全连接 半连接队列存放的就是一些还没建立TCP连接，并且还在三次握手过程中的客户端连接
全连接队列存放的就是一些已经完全建立TCP连接但是还没被应用层取走的连接，每次应用层调用accept时就会从全连接队列里取一个连接去处理，但是如果队列中没有连接就会阻塞
​
半连接队列 当服务器端在LISTEN状态时能接受其他客户端的TCP建立连接请求，当服务器收到客户端发来的SYN包时就会回复ACK+SYN，此时服务器就进入了 SYN_RECV的状态，这个时候服务器就会将这个连接存放到半连接队列中，并且等待客户端发来应答的ACK
如果在指定时间内客户端没有发第三次握手，则服务器会进行重试直到超过一定次数则会将此连接从半连接队列里面删除
#SYN+ACK重试次数 默认为5 /proc/sys/net/ipv4/tcp_synack_retries 如果客户端发来了第三次握手ACK，则会将此连接放入全连接队列等待用户应用去队列里面取
如果半连接队列满了的话，则服务器不会继续接受客户端的连接请求，当其他客户端想要建立TCP连接发送SYN时，服务器就会发送RST报文告诉客户端 &amp;ldquo;连接失败&amp;quot;或则是直接丢弃
​
半连接队列大小 半连接队列大小收到下面几个因素影响
用户层 listen 传入的backlog （用户传入的全连接队列大小） 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128 （Linux配置的全连接队列大小） int listen(int sockfd, int backlog); //第二个参数 /proc/sys/net/ipv4/tcp_max_syn_backlog #1024 /proc/sys/net/core/somaxconn #4096 如果我们想要增加半连接队列的大小，我们就需要同时增加上面三个值，而单单的增加其中的几个则可能无法增加半连接队列的大小
​
全连接队列 当服务器收到客户端发来的第三次握手的时候，服务器就会将这个连接从半连接队里里面转移到全连接队里面并等待应用去全连接队列里取连接进行处理，应用一旦取走该连接就不会保存在队列里了
全连接队列只是用来保存已经建立TCP连接但是还没被用户取走待处理的连接
如果全连接队列满了的话服务器会使用下面两种策略，用户可以在一下文件中配置
/proc/sys/net/ipv4/tcp_abort_on_overflow 0 全连接队列满了则server会丢弃ACK，当作没收到
即使收到了客户端发来的第三次握手ACK也会丢弃当做没收到，则此半连接就无法进入全连接队里，同时server端也会在超时的时候继续发送SYN+ACK，当重试超过指定次数之后全连接队列还是满的则会因为将此半连接删除
1 全连接队列满了则会发送RST包告诉客户端废除这个连接请求
一般配置为0可以有效的增加服务器的并发能力，可能全连接队列只是短暂的满了，之后会被快速取走，则配置为0之后，在后面重试的ACK中还是可以建立连接的
​
全连接队列大小 全连接大小由操作系统配置somaxconn和用户应用配置的backlog两个值确定的
min(somaxconn, backlog) int listen(int sockfd, int backlog) //用户决定 /proc/sys/net/core/somaxconn #4096 操作系统参数 我们如果要增加全连接大小，则需要考虑操作系统的配置以及应用程序传入的配置，取他们之间最小的一个，也就是说即使应用程序传入的backlog再大，如果somaxconn很小的话则依然无法增加全连接队列的大小</description></item><item><title>TCP协议中的KeepAlive机制</title><link>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/27/tcp%E5%8D%8F%E8%AE%AE%E4%B8%AD%E7%9A%84keepalive%E6%9C%BA%E5%88%B6/</guid><description>HTTP中的keep-alive 在HTTP的头部中，也有一个字段
connection: keep-alive 此字段告诉服务器HTTP会复用这一条TCP连接，当前的HTTP请求完毕之后不会立即断开连接，还可以被另外的HTTP请求复用这条连接，这样就可以减少建立TCP连接的次数
​
TCP的长连接和短连接 TCP连接并没有分为长短连接，长短连接只是在于你如何使用TCP
如果建立TCP连接短暂通讯结束之后立即释放这条连接则此连接就为短连接，比如我HTTP发一次请求就建立一次TCP连接，HTTP响应回来之后就立即断开TCP连接
短连接的缺点就是需要频繁的建立TCP连接，比较耗时，优点就是可以很快的释放TCP连接队列，以便于空出位置建立其他TCP连接
如果建立TCP连接在使用时候不立即断开，如果一直没有请求的话就将这条连接空闲即可，以便与后面如果还要请求通讯的话就不需要建立TCP连接了，直接复用那条已经建立好的TCP连接即可。比如我HTTP请求建立TCP连接，响应结束之后浏览器不会立即释放与服务器的TCP连接，如果下次还有其他请求的话则可以复用之前建立的TCP连接即可，如果一时半会儿还没有请求的话只需要将TCP连接空闲着即可，等下次有请求了就可以继续用这条连接进行传输
长连接的优点就是可以减少建立TCP连接的消耗，复用连接。缺点就是如果很长一段时间都没有数据可发的话就会占用操作系统的TCP全连接队列，如果TCP全连接队列比较紧张的话那么就无法建立其他的TCP连接了
​
TCP的KeepAlive机制 TCP的KeepAlive机制会在指定的间隔时间发送KeepAlive探活包，如果收到了KeepAlive包的ACK则表明对方还在，如果多次发送KeepAlive包都得不到回复则可以认为对方已经挂了，就可以将这个TCP连接从队列里面删除了
KeepAlice主要有如下几个作用:
保活 解决窗口值为0的情况 在空闲的长连接里我们可以通过KeepAlive机制探测对方是否存活，如果收到ACK则表明对方还存活并且还需要复用这条连接
如果多次发送KeepAlive都收不到则说明对方已经挂了或则对方拒绝回复，这样就表明这条长连接可以断开清除了。如果没有KeepAlive机制如果对方挂了则这个连接还会一直保留在服务区占用着TCP全连接队列
还有一种情况就是在接收方的窗口值为0的情况下，那么发送方就不能继续发送数据了，那么即使接收方的窗口扩大了也没有办法告诉发送方，此时就相当于死锁了双方都不会发送数据
所以KeepAlive探测包还可以用于解决窗口值减少为0而造成死锁的情况。当接收方的窗口为0的时候，发送方可以定时的发送KeepAlive包来探测接收方的窗口是否扩大了
​
Linux中KeepAlive相关配置 #7200 每7200s发送KeepAlive包 /proc/sys/net/ipv4/tcp_keepalive_time #75 如果75s内没有收到KeepAlive的ACK则再次发送 /proc/sys/net/ipv4/tcp_keepalive_intvl #9 如果重试9次都没有响应则把此连接删除掉 /proc/sys/net/ipv4/tcp_keepalive_probes ​
KeepAlive能携带数据吗 注意，KeepAlive包的seq也是没有意义的，seq一般和初始化的seq一致，KeepAlive是不携带数据的</description></item><item><title>Redis事务</title><link>/2021/05/26/redis%E4%BA%8B%E5%8A%A1/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/26/redis%E4%BA%8B%E5%8A%A1/</guid><description>TODO</description></item><item><title>面试常见问题总结</title><link>/2021/05/26/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><author>作者</author><guid>/2021/05/26/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</guid><description>MySql MySql索引说说看? InnoDB索引使用什么数据结构?
MyISAM和InnoDB索引的区别?
什么是聚集索引，什么是非聚集索引?
什么时候适合建索引?
Redis Redis网络模型说说看?
Redis有哪几个常用的数据类型和数据结构?
Redis持久化RDB和AOF?
Redis集群有了解吗?
你项目里用到了Redis的哪些数据结构?
Redis键的过期策略了解吗?
参考博客
https://segmentfault.com/a/1190000022670317
网络相关 TCP四次握手过程? 为什么需要四次? 为什么需要TIME_WAIT?
Go语言 new和make的区别
go中的slice机制是怎么样的?
map的并发安全的吗? 为什么?
获取一个map中不存在的key会出现什么情况? 删除一个不存在的key呢?
channel了解吗? 缓冲channel和非缓冲channel的区别
channel你使用过吗? 有什么应用场景
往一个已经close的channel发数据会怎么样? 读数据呢?
go的GMP模型了解吗
GC知道吗？go使用了gc算法说说看
go1.14之后的抢占式调度知道吗
操作系统 线程和进程的区别
操作系统进程调度说说看
其他 设计模式知道吗? 常见的设计模式说说看?</description></item></channel></rss>