<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on lyer's blog</title><link>/posts/</link><description>Recent content in Posts on lyer's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>icepan@aliyun.com (lyer)</managingEditor><webMaster>icepan@aliyun.com (lyer)</webMaster><lastBuildDate>Sun, 18 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>MySql安装和启动</title><link>/2021/04/18/mysql%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8/</link><pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/18/mysql%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8/</guid><description>Linux安装 Linux下可以直接下载tar的二进制文件，在官网下载即可
下载之后文件里面有如下几个内容:
bin docs include lib LICENSE man README share support-files 我们需要设置一个MYSQL_HOME 环境变量指向这个地址
​
初始化数据目录 MySql第一次启动需要初始化数据目录，数据目录的位置默认不指定的话则为MySql安装目录下的data (这个和环境变量无关，不设置MySql家目录的环境变量也会到这个路径下找，这个是因为Mysql二进制包已经编译好了就是这个目录)当然也可以自己拿源码编译为其他路径
初始化数据目录需要执行一下命令:
mysqld --initialize --user=root #--user=root表示以root用户执行，mysql官方不建议以root执行mysql，如果需要强制执行则需要指定--user=root 初始化之后就会生成一个data目录，此目录就和存储有关了，所有的数据都存储在此目录下
然后就可以执行如下命令启动mysqld进程了
初始的用户密码在初始化时会打印在屏幕下
mysqld --user=root 首次用客户端连接时，系统会要求你必须修改root密码
ALTER USER &amp;#39;root&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED WITH mysql_native_password BY &amp;#39;123&amp;#39;;</description></item><item><title>密码加盐和彩虹表攻击</title><link>/2021/04/18/%E5%AF%86%E7%A0%81%E5%8A%A0%E7%9B%90%E5%92%8C%E5%BD%A9%E8%99%B9%E8%A1%A8%E6%94%BB%E5%87%BB/</link><pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/18/%E5%AF%86%E7%A0%81%E5%8A%A0%E7%9B%90%E5%92%8C%E5%BD%A9%E8%99%B9%E8%A1%A8%E6%94%BB%E5%87%BB/</guid><description>密码明文存储 这种密码存储方式直接将用户密码明文存储在数据库中，一旦数据库被黑客获取，那么所有信息都泄露，有些用户的密码可能在好几个账户上都是相同的，这是一种最不完全的方式
​
密码hash加密存储 这种方式比上一种略微安全，用户注册时将用户的密码使用指定的hash算法进行加密，然后存储在数据库中，当用户登录的时候将登录的密码使用相同的hash算法进行计算hash值然后与数据库存储的hash值进行比较即可
这种方式可能造成 彩虹表攻击 ，攻击者建立一个 明文-&amp;gt;密文 的一个巨大的映射表，如果凑巧你的密码密文被包含在了这个表中，那么黑客就可以知道你的密码明文了
这个数据字典很容易收集，CSDN 泄露的那 600w 个密码，就是很好的原始素材
如果用户密码很复杂那么被包含到彩虹表里面的可能性越小
​
密码加盐进行hash 这种方式会在用户注册的时候给用户随机上次一个salt值，然后再和用户的密码进行计算hash值
salt 可以是任意字母、数字、或是字母或数字的组合，但必须是随机产生的，每个用户的 Salt 都不一样，用户注册的时候，数据库中存入的不是明文密码，也不是简单的对明文密码进行散列，而是 hash( 明文密码 + Salt)，
密码加盐之后还是无法保证100%的安全，如果数据库泄露了，黑客还是可以在他们原来的数据字典中的密码，加上我们泄露数据库中的 Salt，然后散列，然后再匹配，但是由于salt是随机产生的，假如我们的用户数据表中有 30w 条数据，数据字典中有 600w 条数据，那么需要获取30w的salt然后分别对600w的数据字典中的明文密码都加上一个salt计算hash，那最终加盐的彩虹表大小就是30w*600w的条目，这个计算量是巨大的，然后再根据用户数据表的hash值遍历这个彩虹表，这个遍历耗时也是巨大的
并且salt插入的地方也无法知道，可能插入在头、尾、中间任意位置都有可能，这就加大了破解的难度，所以密码加盐还是能够保证安全性的
​
参考 CSDN600万账户密码泄露事件
为什么要在密码里加点“盐”</description></item><item><title>常见的Hash算法</title><link>/2021/04/17/%E5%B8%B8%E8%A7%81%E7%9A%84hash%E7%AE%97%E6%B3%95/</link><pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/17/%E5%B8%B8%E8%A7%81%E7%9A%84hash%E7%AE%97%E6%B3%95/</guid><description>什么是Hash算法 Hash表这种数据结构中就是使用了Hash算法，其将值进行Hash转化为表数组对应的下标，这种Hash算法的目的就是将其他数据比如 字符串、int、bool 转化为数组下标(正整数)
下面来看看JDK11里面HashMap的hash函数
static final int hash(Object key) { int h; return key == null ? 0 : (h = key.hashCode()) ^ h &amp;gt;&amp;gt;&amp;gt; 16; } 主要通过key的hashCode函数来计算hash值，并且还进行了二次hash来减少碰撞
用户实现的这个hashCode有如下几个规定:
如果 key1 = key2，那 hash(key1) == hash(key2) 如果 key1 != key2，那 hash(key1) != hash(key2) 如果不同的key产生了相同的hash值那么就代表产生了hash碰撞 hashCode必须返回一个非负整数 我们再来看一看String的hashCode的实现，下面是英文的拉丁字母的hashCode函数
至于为什么31这是为什么减少hash碰撞，因为31是一个不大不小的质数
public static int hashCode(byte[] value) { int h = 0; byte[] var2 = value; int var3 = value.length; for(int var4 = 0; var4 &amp;lt; var3; ++var4) { byte v = var2[var4]; h = 31 * h + (v &amp;amp; 255); //字母会转化为对应的ASCII码值然后计算hash } return h; } Java中Integer类型的hashCode是它本身</description></item><item><title>Cache高速缓存</title><link>/2021/04/07/cache%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/07/cache%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</guid><description>Cache和内存地址映射 1、直接相联映射 内存指定的块只能缓存到指定的Cache行中，采用mod的方式，并且块号用中间的位数，这样主要是为了能利用局部性原理将附近的几个块都能够有机会同时缓存起来
缺点是缓存利用率底，指定的块只能对应指定的行，如果对应的缓存行慢了，即时其他缓存行空着也无法缓存，需要将自己对应的缓存行的数据置换出去
2、全相联映射 内存每块都可以映射到Cache的每一行，优点是缓存利用率高，缺点是查找缓存效率低，需要遍历查找是否存在与缓存中
3、组相联映射 直接映射+全相联映射的结合，将多块分为一组，同时将缓存行里面的多行分为一组，每组内采用全相联映射，组间采用直接相联映射
​
Cache数据读取和写入 读命中和读不命中 CPU拿到真实的内存地址之后需要先检查Cache是否命中，如果命中则直接返回否则需要向下一级Cache加载数据，如果下一级也没有命中则需要直接访问内存，访问内存的时候通常会根据局部性原理预读一些数据到各级缓存中
写命中 写数据的时候如果Cache命中了，则我们需要考虑多级缓存以及和内存同步问题，因为L3缓存、内存等都是多核共享的，如果不能及时将脏数据更新回L3或则内存则会造成数据不一致问题，通常有下面两种处理方式:
Write Through 直写
如果写命中，则直接同时跟新当前Cache以及下一级Cache、内存等，这种方式能很好的保障数据一致性，但是会引起总线流量过大，每次写都需要立即更新
Write Back 写回
如果写命中则不会立即更新下一级缓存或则内存，而是标记位dirty ，等到此缓存行被替换的时候再写回，此策略的缺点就是无法保障数据一致性，优点就是可以减少总线流量
写不命中 写数据如果没有命中Cache，则也会有如下几个策略:
Write Allocate 写分配
首先加载对应的数据到缓存行中，然后往缓存里面写入，此策略通常和 Write Back 配套
Not Write Allocate 非写分配
避开高速缓存，直接操作内存，此策略通常是与 Write Through 配套
综上: 我们得出，Cache一致性问题有两种策略解决 (命中和不命中两种情况对应的策略)
Write Through+Not Write Allocate Write Back + Write Allocate ​
Cache分级 L1缓存分为两种: 指令缓存和数据缓存</description></item><item><title>原型模式</title><link>/2021/04/07/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/07/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</guid><description>为什么要使用原型模式 原型模式又叫 克隆模式，是对一个对象的拷贝，当一个对象的创建比较复杂的时候就可以使用原型模式进行拷贝然后再修改需要修改的部分
​
代码实现 public class EnglishBook extends Book{ public EnglishBook(String title,Author author) { super(title,author); } @Override public String toString() { return String.format(&amp;#34;%s:《%s》&amp;#34;,this.author.getName(),this.title); } @Override protected Book clone() { return new EnglishBook(this.title,this.author); } } ​
原型模式在Spring中的应用 Spring的Bean通常是单例的，如果我们显式需要多个对象则会使用原型模式创建多个对象</description></item><item><title>建造者模式</title><link>/2021/04/07/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/07/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/</guid><description>为什么要使用建造者模式 建造者模式将对象本身和对象的创建进行解耦，用户不需要知道对象创建的细节和流程
建造者模式解决了对象的创建过程和流程，这些都不需要用户关心
建造者和工厂模式不同的是建造者更加关系构建对象的流程，各个部件的构建顺序，而工厂模式更加关心的是对象的整体，工厂模式创建的对象比较单一，没有很复杂的组件，而如果对象由好几个对象组成，并且对象属性比较多，构建顺序有一定的要求则需要使用建造者模式
​
实现 创建一个电脑
public class Computer { private String brand; private String cpu; private String mainBoard; private String hardDisk; private String displayCard; private String power; private String memory; // 省略 getter, setter, toString } Builder抽象类
public abstract class Builder { protected Computer computer = new Computer(); public abstract void buildBrand(); public abstract void buildCPU(); public abstract void buildMainBoard(); public abstract void buildHardDisk(); public abstract void buildDisplayCard(); public abstract void buildPower(); public abstract void buildMemory(); public Computer createComputer() { return computer; } } 具体的实现</description></item><item><title>知识体系总结</title><link>/2021/04/06/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/06/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E6%80%BB%E7%BB%93/</guid><description>设计模式 书籍 设计模式的艺术-一本实例驱动的设计模式实践指南-刘伟
重学Java设计模式
优秀博客 操作系统和计算机组成原理和计算机基础 计算机网络 数据结构</description></item><item><title>工厂模式</title><link>/2021/04/05/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</link><pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/05/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</guid><description>为什么要使用工厂模式 工厂模式是一种创建型的设计模式，专门用于创建对象，通过工厂模式创建对象我们就不需要手动创建对象了，直接重工厂类里面获取即可。
工厂方法主要有如下几个优点:
隐藏了创建对象的复杂度，用户不需要知道如何创建对象，只需要调用相关的方法API即可创建对象， 降低了代码耦合，一旦我们需要修改创建对象的方式或则参数，如果不使用工厂模式直接new的话那么我们需要手动查找并且修改所有new的代码，而如果使用了工厂模式因为我们获取对象都是通过工厂获取的，我们只需要修改工厂类的相关代码即可 ​
工厂模式实现方法 简单工厂 工厂方法模式 抽象工厂 ​
简单工厂 简单工厂模式就是只有一个工厂，然后用户通过传入不同的名字或则参数，此工厂类再根据用户传入的参数进行判断需要创建哪个对象(被创建的实例具有相同的接口或则父亲，当然了，返回值直接设置成Object也是可以的)
简单工厂模式有如下几个缺点:
违背开闭原则(对扩展开放，对修改关闭)，如果需要增加一个类则需要修改工厂类 工厂类只有一个，职责过重，逻辑复杂 interface Computer { String Brand(); //品牌 } public class MacComputer implements Computer { public static final String BrandName = &amp;#34;Mac&amp;#34;; @Override public String Brand() { return BrandName; } } public class LenovoComputer implements Computer { public static final String BrandName = &amp;#34;Lenovo&amp;#34;; @Override public String Brand() { return BrandName; } } public enum ComputerBrand { Mac, Lenovo } 创建计算机的简单工厂，根据传入的Type不同分别创建不同品牌的计算机，如果需要增加一种品牌则需要改动此部分代码，所以违背了 开闭原则</description></item><item><title>Java枚举</title><link>/2021/04/04/java%E6%9E%9A%E4%B8%BE/</link><pubDate>Sun, 04 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/04/java%E6%9E%9A%E4%B8%BE/</guid><description>Java枚举的简单使用 public enum HttpStatus { OK, NoContent, NotFound, InternalServerError, BadGateway } 可以使用如下几个常见的枚举方法
public static void main(String[] args) { HttpStatus ok = HttpStatus.OK; String okStr = ok.name(); //OK Integer okIndex = ok.ordinal(); //0 HttpStatus notFound = HttpStatus.valueOf(&amp;#34;NotFound&amp;#34;); //str-&amp;gt;enum HttpStatus[] values = HttpStatus.values(); //string values } ​
枚举实现原理 枚举是Java的一种语法糖，内部通过继承 Enum抽象类来实现，下面我写了一个类来说明枚举类实现原理，就是通过 static变量+static初始代码块 来实现的，这就是为什么枚举非常适合作单例的原因
public final class WeekDay { private final String name; private final Integer ordinal; private WeekDay(String name, Integer ordinal) { this.</description></item><item><title>单例模式</title><link>/2021/04/03/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</link><pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/03/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</guid><description>为什么要使用单例模式 有时候系统只需要一个对象，比如 数据库连接对象、线程池对象 等
线程池这种对象如果建立多个就会失去它的意义，因为线程池本来就是用来管理多个线程的只需要一个即可
数据库连接对象使用单例并不是指只有一个数据库连接，数据库连接对象里面保存的只是数据库连接相关的信息，比如数据库类型、用户名、密码、URL、字符集等
实际创建个多少TCP连接和实际的并发量有关，因此数据库连接对象也不必每次查询SQL的时候去创建对象，这样就显得多余和麻烦了
这种为了让系统中只存在一个对象的模式就叫 单例模式
​
单例模式实现方法 饿汉式 方法级别锁、双重检查锁 静态内部类 枚举 ​
饿汉式单例 饿汉式单例指的就是在系统初始化的时候就创建对象
优点是无需考虑多线程问题
缺点是无法懒加载，万一对象始终用不到那就白加载了
Java类成员变量初始化实现 public class DataBaseManager { //初始化时就创建 private final static DataBaseManager db = new DataBaseManager(&amp;#34;lyer&amp;#34;,&amp;#34;55555&amp;#34;); private String username; private String password; //必须隐藏构造方法 外界无法创建 private DataBaseManager(String username,String password){ this.username = username; this.password = password; } public static DataBaseManager getInstance(){ return db; } } Go全局变量实现 go中可以通过 全局变量 或则init函数实现，不过这不是最佳实现方式
var database1 = &amp;amp;DataBase{} func main() { database1.</description></item><item><title>操作系统中的各种栈</title><link>/2021/04/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%A0%88/</link><pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%A0%88/</guid><description>栈的作用 程序中栈的作用主要有如下:
局部变量的空间快速分配和释放 函数调用与返回 保存状态，以便恢复 在函数里面的变量都属于局部变量，函数调用结束，出了函数这个局部遍历就没有用了，那么其空间也不需要保留了
所以栈可以在函数调用时快速分配局部变量的内存地址，而在函数调用结束之后可以立即销毁，所以在C语言中不能在函数中返回局部变量的指针，这样会造成 悬挂指针 问题，因为在函数返回时其地址就已经被回收了
栈还有另外的作用就是嵌套函数调用，比如 递归，其实就是一层层的函数调用栈，所以所有的递归代码都可以用 迭代 来改写
栈还在 中断处理 中发挥着中断恢复的作用，进程在发生中断的时候会将进程当前的寄存器状态和当前的PC指针都压入内核栈然后开始执行中断处理代码，中断处理也是使用这个内核栈的，等中断处理完毕之后就弹出内核栈恢复寄存器继续回到之前的代码中执行
​
线程栈和进程栈 Linux的进程和线程其实都是同一个结构体task_struct来表示，Linux并没有线程的概念，只是Linux的进程有父进程子进程的概念，有一颗进程树
Linux的线程也叫轻量级进程，Linux通过多个进程共享内存空间来实现进程中的多线程
主线程就是创建进程的那个执行流，而子线程都从主线程也就是进程中fork出来，只是fork之后相当于copy，所以他们能共享内存空间等其他资源(包括文件描述符等)这样就可以实现线程的效果了
虽然他们内存空间都一样，很多资源都是一样的，但是各个线程之间的stack还是需要fork之后重新改变的，多个线程之间必须使用独立的栈，因为他们都是不同的执行流，是并行执行的，而不是向函数一样一层层嵌套的
如果线程栈都使用同一个的话那么如果发生线程切换调度，原来线程的执行过程中保存在栈中的数据就会被破坏掉，或则不是他想要的数据了
线程的stack大小是固定的，是从父进程的堆空间映射过来的，也就是说线程的栈开辟在父进程的堆中
linux创建线程都是使用fork，必须要有一个父进程(第一个用户进程init进程1号进程是由操作系统在初始化时创建的，第一个内核级进程是2号进程)，如果是创建线程则直接共享内存空间改变stack和PID、PPID等一些主要的信息即可，如果是创建进程则需要重写进程映象，加载可执行文件重新建立属于自己的内存地址空间，重新建立页表映射
​
进程内核栈 操作系统会为每个进程都创建内核栈，此栈用于系统调用、中断等发生特权级转换执行内核代码使用，在发生中断引发特权级别转化时，操作系统会将进程触发中断时的上下文都压入内核栈以便能继续回到用户态，然后在执行内核代码
注意内核栈是和PCB一起管理的，也就是说一个PCB包含了内核栈，内核栈大小是固定的
内核栈也是必须要独立的，为什么内核栈不能使用进程的栈呢?
这主要是为了保护内核，内核级的数据不允许出现在用户级空间上
哪为什么要为每个进程都建立一个内核栈呢?
这主要是为了防止进程调度之后导致的问题，就像每个线程不能共享进程栈一样，一个进程即使陷入内核了还是会发生进程调度，因为进程陷入内核还是在这个进程范围内为这个进程服务
为什么进程和子线程需要独立的内核栈?
这个问题其实和上面那个重复了，进程(也就是主线程)和子线程的内核栈也必须在独立的，同样为了防止线程调度引发的数据破坏问题 ，这个很好理解，因为Linux线程其实就是进程模拟出来的，那么自然在陷入内核时必须为其创建独立的内核栈
​
参考 Linux 中的各种栈：进程栈 线程栈 内核栈 中断栈</description></item><item><title>进程状态恢复</title><link>/2021/04/03/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D/</link><pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/03/%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%E6%81%A2%E5%A4%8D/</guid><description>系统调用和中断时的状态恢复 发生系统调用的时候，需要发生 特权级转化 ，这样才可以指向内核代码执行系统调用代码等，这时候也需要保存进程的状态，因为系统调用或则中断处理完毕之后需要回到之前的用户进程继续执行
操作系统会为每个进程分配一个 内核栈，此栈每个进程都有并且内核栈大小是固定的，其地址空间保存在PCB中，也就是 task_struct中，方便和PCB一起管理
内核栈用于存放一些系统调用执行的数据等，因为系统调用执行的代码也需要用到栈，因此为了在系统调用结束之后还可以继续回到之前的位置执行于是在发生系统调用之前需要将进程相关的上下文信息都压入内核栈中，比如 PC指针、各个寄存器值、堆栈指针等 因为进入内核态之后堆栈也会发生变化，所以这里需要保存进程之前的堆栈信息
**注意，发生中断时进程的 **CR3 寄存器是不会改变的也不需要保存，此寄存器保存了用户进程的页表，因此操作系统可以根据这个页表将内核空间的数据copy到用户空间(内核态和用户态的数据有两个系统调用函数: copy_to_user和copy_from_user)
因为用户的页表永远都有操作系统的地址映射，所以不影响内核代码的执行
上下文信息保存完毕之后，就可以执行内核代码了，内核代码指向完毕之后栈相关数据也空了，然后继续恢复之前在栈底保存的进程上下文信息即可，这样就可以继续回到进程中断前的代码去执行了
​
进程调度时的状态恢复 发生进程调度时需要将进程当前的所有信息都保存在task_struct中，以便下次被调度之后可以继续恢复之前的状态，比如恢复 页表、PC指针、栈指针、各个寄存器值、进程页表 等
进程调度发生的上下文切换是比 中断 引发的上下文切换代价要大的，因为进程调度还需要切换页表加载页表清空TLB缓存等操作，而中断是在一个进程内引发并且中断完毕之后需要继续回到之前的进程，相当于在进程中调用了系统内核函数一样只不过调用系统函数执行内核代码需要转化特权级和内核堆栈等，还有很多进程的信息是不需要切换的
​
参考 进程切换与系统调用(中断和异常)切换哪个耗时耗资源多
Linux 中的各种栈：进程栈 线程栈 内核栈 中断栈</description></item><item><title>IO模型</title><link>/2021/04/01/io%E6%A8%A1%E5%9E%8B/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/01/io%E6%A8%A1%E5%9E%8B/</guid><description>直接IO和非直接IO 磁盘 I/O 是非常慢的，所以 Linux 内核为了减少磁盘 I/O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是页缓存，只有当缓存满足某些条件的时候，才发起磁盘 I/O 的请求
直接 I/O: 不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。 非直接 I/O: 读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘 内核会在一下几种情况下对真实的磁盘进行读写:
内核缓存区满了 用户主动调用sync 缓存数据超过指定时间 &amp;hellip;. ​
缓冲IO和非缓冲IO 缓冲IO 指的是标准库在应用程序进行读写数据的时候会开辟一个缓冲区，进行系统调用的时候回先调用标准库函数，然后标准库函数再去进行系统调用读取数据，系统调用会预先读取一部分数据缓存在用户标准库里面的缓冲区中，这样就不必每次读取数据都进行系统调用了，减少了系统调用的开销
非缓冲IO 则是每次读写数据都直接进行系统调用，系统调用结果直接返回到应用程序
​
阻塞IO(BIO)和非阻塞IO(NIO) 阻塞IO 指的是用户线程在read系统调用时会一直等待内核读取数据，等内核读取数据到内核缓冲区(比如从网卡读取数据、通过底层文件系统从磁盘读取数据到内核缓冲区)然后将内核缓冲区数据copy到用户空间，这样整个read调用才会返回
阻塞IO线程需要等待的时间: 操作系统读取数据时间+内核缓冲区到用户缓存区copy的时间
非阻塞IO 指的是用户线程在read系统调用之后可以立即返回，但是需要自己主动再次向内核询问数据是否读取到内核缓冲区中，这里需要多次询问直到数据读取完毕(在轮询期间可以干一些其它事情)，当数据准备好了之后，则需要阻塞的等待内核将内核缓冲区的数据copy到用户空间中(注意这个过程是阻塞的)
非阻塞IO线程需要等待的时间: 不断轮询的消耗的时间+内核缓冲区到用户缓存区copy的时间
​
IO多路复用 传统的非阻塞IO模型有如下缺点:
一个线程不断轮询效率低下问题
一个线程只能监听一个IO，为了达到多个网络IO并发连接就只能多线程，多线程多进程有系统调度的开销
于是就出现了 IO多路复用
多路复用是一种 非阻塞IO模型 ，传统同步IO模型比如阻塞IO和非阻塞IO只能在一个线程中监听一个IO句柄，并且需要用户程序主动轮询，但是多路复用则可以在一个线程中监听多个IO句柄，并且不需要用户程序主动轮询，相当于进行系统调用操作系统帮你进行轮询管理多个IO句柄了，所以非阻塞IO需要操作系统的支持
数据从内核缓冲区copy到用户缓冲区等一系列操作，这个copy的过程还是阻塞的，因此多路复用是一种 同步IO模型中的非阻塞IO
​
select、poll、epoll TODO
​
异步IO(AIO)和同步IO 同步IO中用户程序还是会在内核缓冲区copy到用户缓存区的时候阻塞等待，而异步IO在 内核数据准备+数据从内核态拷贝到用户态这两个过程都不用等待，发起aio read就立即返回，用户不需要等待也不需要轮询，操作系统会在后台进行数据准备，数据准备完毕之后会将数据从内核态copy到用户数据区域，这一系列动作都完成之后就会通知用户程序，用户程序收到通知之后数据就已经在自己的用户空间了
​
参考 一口气搞懂「文件系统」，就靠这 25 张图了</description></item><item><title>Linux进程和线程</title><link>/2021/04/01/linux%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/01/linux%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/</guid><description>CopyOnWrite 由于操作系统创建进程必须通过fork来创建，fork创建的子进程和父进程一模一样只是task_struct不一样，其虚拟地址空间底层的物理地址指向的都是同一个页面，只有在子进程需要修改的时候才会重新分配一个物理然后将原来的内容copy过去，最后再修改子进程的物理页，这样子进程的修改就不会影响到父进程了，这个就是 Copy On Write技术
操作系统主要是为了减少物理页的分配和copy的消耗，因为创建子进程之后一般子进程会通过exec系统调用重写自己的进程映象，所以就没有必要copy一份了，而且Linux线程是通过进程实现了，这样就可以实现多个线程共享主线程也就是父进程的内存地址空间了
​
Linux线程的实现 Linux中没有线程这一个单独的概念，Linux中所有的执行流所有的线程进程都通过一个task_struct来进行标识，Linux就是通过task_struct来感知线程和进程，也是通过task_struct中的信息来进行线程进程调度的
所以在C下创建线程都是能被Linux的内核感知到的，也就是说Linux的线程模型是 一对一模型 ，当然其他高级语言可以自己实现自己的用户线程库来实现 一对多、多对多线程模型，比如Go就通过自己goroutinue来实现了 多对多模型 ，所以goroutinue是比较轻量并且高效的，这也是为什么go的并发这么优秀的原因
Linux下每个进程都有自己的父亲，一个进程如果没有其它子线程那么就只有一个主线程，也就是进程，如果该进程创建了多个线程，那么这多个线程的父亲也就是PPID都指向同一个: 主线程，主线程的PPID指向fork它的那个进程，这两个进程是独立的不同的进程。然后每个task_struct中都有一个gid，用来标识多个task_struct属于同一个 进程组，子线程的gid指向主线程的pid，主线程的gid指向自己，这样就将进程和线程区别开来了，只要是属于同一个gid的task_struct就属于同一个进程，只要是gid=pid的则这个就是主线程也就是进程本身
另外还需要注意的就是每个task_struct的虚拟地址空间中都有一个栈区，这个栈每个线程进程都必须是独立的，主线程的栈空间就是创建进程时的那个栈空间，而子线程的栈空间是从主线程也就是进程的堆空间中map出来的，这个堆空间每个线程都是共享的，fork之后如果是线程则不会重写重写自己的进程映象，也就是意味着可以和主线程共享内存空间，而如果是进程则会立即重写自己的进程映象，属于独立与父进程的一个进程
​
进程的虚拟地址空间 一些特殊的进程 操作系统进程: idle[0] 唯一一个没有通过fork创建的进程，也就是内核代码的main执行流
第一个用户进程: init[1]
第一个内核进程: kthreadd[2]
参考 虚拟内存[01] 用户内存空间的各个段分布
写时复制技术</description></item><item><title>VFS和虚拟文件系统</title><link>/2021/04/01/vfs%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/04/01/vfs%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</guid><description>为什么磁盘需要分区分块 1、磁盘为什么要分区 磁盘分区的主要就是划分几个大块，每个分区里面可以安装不同的底层文件系统，分区之间都是独立的，也可以在不同的分区上安装不同的操作系统，就好像把磁盘容量看成一整块，然后在这个一整块上进行划分几个区域(当然只划分一个区域也是可以的)
分区主要有一下几个优点:
方便数据管理 隔离数据，保证数据安全，不同分区之间数据互不干扰，分区之间独立 加快数据查找：因为文件系统会将磁盘分成一个个的数据块，单个文件数据可能是存放在不连续的块中，如果分区太大，某个文件数据块分散的存在开头和结尾那么磁头臂的移动就会非常频繁造成读取效率低下，所以一个分区的大小不能划分太大，如果磁盘容量很大的话则可以多划分几个分区 可以在一台计算机上不同的分区上安装不同的操作系统、不同的文件系统，实现双系统等 2、磁盘为什么要分块 机械磁盘读写数据是以 扇区 为单位的，一个扇区大小为512字节或则4kb
扇区是抽象的概念，物理上是没有的，物理上只有盘片，一张盘都是一整块的，只是物理部件在读写的时候是以这个为单位读写的，所有文件的容量大小必须是扇区数量的整数，需要按照扇区大小对齐
SSD固态硬盘没有盘片的概念，但也有数据单元和数据页的概念，SSD相当于内存一样但是可以持久化，每个数据单元就是1byte，同时一个数据页就包含了多个数据单元，SSD读写的基本单位就是数据页，也是需要做到数据页对齐的
但是物理划分的区块太小了，如果一个文件按照物理区块进行存储的话，因为保存文件的区块不一定连续(如果连续的话会造成碎片问题，所以都是分散存放然后建立索引表)，所以读写一个文件会造成IO次数太多造成而造成效率太低
所以底层的文件系统再次进行了重新划分区块大小，一个数据块对应着物理上 连续的几个扇区或则几个数据页，文件存储的基本单位就是以文件系统划分的数据块为单位的，数据块大小一般和内存页大小一致，方便与内存数据进行交换
如果需要读一个文件，则需要找到保存文件所有数据块的索引表，此表由操作系统和文件系统维护，这些数据块之间可能是分散的，虚拟块是连续的，需要读写哪部分则按照偏移然后加载对应的数据块到内存然后进行读写，这个和内存虚拟地址思想一样
​
ext4文件系统 1、ext2 ext3 这就是最简单的ext2、ext3的底层结构，具体的区别不深究了，大概就是这样，跳出细节才更有利于学习
引导块 存放引导操作系统启动的代码程序，每个分区都有一个引导块，这样可以实现多系统，只需要在MBR或EFI系统上放置一个bootloader，该bootloader就会确定活动分区（通常由用户在启动界面选择启动哪个系统），然后就会跳转到响应的 活动分区中的引导块中加载引导块中的代码到内存进行执行，然后就会加载该活动分区中的操作系统
superblock超级块 super block在索引导块后面，主要包含整个文件系统的一些基本元数据，可以说一个super block就代表了一个文件系统，因此此块一般会进行备份，因为如果这里面的数据被销毁了那么这个磁盘就没办法使用了，里面的数据就无法读取了，该块主要保存如下几个数据:
文件系统设置的数据块大小(一个数据块通常占据整数个扇区比如：8个扇区 4k大小) 空闲块数 空闲的inode节点数 &amp;hellip;&amp;hellip;. 操作系统在启动之后就会将super block从磁盘加载到内存，然后建立 super_block对象，该对象是常驻内存的
空闲块位图和inode位图 空闲区块位图bitmap
管理整个分区中空闲的数据块，占用多个数据块block
inode位图bitmap
管理整个分区中inode的使用和分配，占用多个连续的数据块block，如果inode分配完了就无法再创建文件了
inode节点区块 是一个数组结构，存放整个文件系统的inode信息，每个inode就代表一个文件，inode节点个数代表该文件系统最多能创建多少个文件
注意，inode的大小是固定的，每个inode节点的大小，一般是128字节或256字节，用于标识一个唯一的文件，所以没有保存文件名，文件名保存在文件对应的目录文件的data block中
inode 节点主要包括了以下信息：
文件的inode ID 文件权限信息 所有者 ID、组 ID 文件大小（字节数）、文件类型 文件的硬链接数 上次访问时间、最后修改时间、inode 上次修改时间 文件的数据块block映射表 ext文件系统的数据保存的数据块是分散的(为什么要分散前面说了)，为了找到这些数据所以需要建立索引表，索引表如果都放在inode结构上，那么如果文件太大则索引表就会变的很大，但是inode大小是固定的，所以ext3文件系统采用了如下多级索引的方式，inode一共保存了15个索引项在inode中，如果文件很小则前面几个索引项直接指向真实的数据块，如果文件很大那么后面索引项指向的数据块就不是保存数据了而是保存索引信息了，相当于二级索引，每个数据块又能保存256个索引项，如果文件还很大则又会建立三级索引、四级索引等</description></item><item><title>BloomFilter布隆过滤器</title><link>/2021/03/31/bloomfilter%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/31/bloomfilter%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</guid><description>布隆过滤器原理 布隆过滤器就是通过 3个hash函数，当然hash函数的数量不限，hash函数越多判断越准确，但是同时消耗也越大
将值进行一个hash，计算出对应的index，然后设置对应的bitmap
查找的时候再将值进行hash，分别查找对应的bitmap的位数是否为1，,如果都为1那么则表示找到，如果有一个不为1则表示不存在
BloomFilter 的缺点就是发生hash碰撞之后会出现误判的情况 ，也就是说有可能多个值都映射到相同的位置，所以如果判断出元素存在的话还需要进一步到真实的数据中去再次确认元素是否存在，但是如果判断出不存在，则肯定是不存在
同时布隆过滤器也有 删除问题，也就是说如果删除了一个值，那么其对应的bitmap就要置为0 ，但是如果和他产生hash碰撞的值也都无法判断了，比如原来本来存在的值其中一位和删除的值的bit位一样，但是被删除了，那么判断这个值得时候就会误判为不存在
综上，我们得出 BloomFilter 的主要作用如下:
一个元素如果判断结果为存在的时候元素不一定存在，但是判断结果为不存在的时候则一定不存在。 布隆过滤器可以添加元素，但是不能删除元素 ​
BloomFilter的应用场景 网页爬虫对URL的去重，避免爬取相同的URL地址；
反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱；
防止缓存击穿，将已存在的key放到布隆过滤器中，当访问不存在的缓存时迅速返回避免去真实的数据库查询缓存，这样如果黑客暴力故意查询一个不存在的键时也不会打到后台真实的服务器上而是直接在BloomFilter缓存中就已经判断出不存在了
​
BloomFilter的实现 TODO
​
布谷鸟过滤器 布谷鸟过滤器是布隆过滤器的升级版，其支持删除操作并且不影响判断，我在github上找到了一个实现
https://github.com/linvon/cuckoo-filter/blob/main/cuckoofilter.go
​
参考 https://developer.aliyun.com/article/773205 【布隆过滤器，这一篇给你讲的明明白白】
https://segmentfault.com/a/1190000039156246 【布隆，牛逼！布谷鸟，牛逼！】讲的不错</description></item><item><title>B树B+树AVL树红黑树</title><link>/2021/03/31/b%E6%A0%91b-%E6%A0%91avl%E6%A0%91%E7%BA%A2%E9%BB%91%E6%A0%91/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/31/b%E6%A0%91b-%E6%A0%91avl%E6%A0%91%E7%BA%A2%E9%BB%91%E6%A0%91/</guid><description>B树B+树AVL树红黑树 把这四颗 可爱 的树放在一篇博客来写就是因为他们都有一个共同点: 都是平衡树
传统的二叉树一旦发生倾斜那么就会退化为链表，这是二叉树最致命的缺点，所以就出现了如此多种的树，来提高数据查找的效率
B树 不同于二叉树，B树一个节点可能会有多颗子树，相当于是一颗多叉树，并且按照一定的规则来保持这种状态那么这个树就会维持的比较 矮胖，又因为B树有搜索树的性质所以二分查找起来速度就快了
B+树 就是B树的升级版，B+树和B树的不同在于叶子节点，B+树的每个叶子节点都会用链表连接起来，这样就支持 范围查找，一旦找到起始节点那么中间的节点就可以一起获取到，就不需要每次都从root节点开始遍历了
AVL树 是一颗平衡的二叉搜索树，一旦左右子树的平衡因子太大或则太小了那么就表示树已经失衡了，就会通过旋转操作来继续维持平衡因子到指定的值，所以旋转操作执行次数多的话也是比较耗时的
红黑树 和AVL树一样也是通过一定规则并且靠旋转、变色来维持树的平衡
在学习这些数据结构的时候不需要背规则，知道个大致原理即可
​
B树 又叫 多路查找树，和二叉树不同的是一个节点最多可以有多个子树
B树靠如下几个规则来保持树的平衡和矮胖:
根节点如果有孩子节点的话则至少有2个子节点
一颗m阶的B树中所有节点的最大孩子节点数量&amp;lt;=m，所以最多包含m-1个关键字(因为孩子节点是在两个关键字之间进行插入的)
中间节点关键字数量为k: ceil(m/2)&amp;lt;=k&amp;lt;=m-1
关键字之间是有序的，并且有搜索树的性质
所有叶子节点在同一层，也就是说根节点到所有叶子节点的距离都是一样的
​
B+树 B+树就是在B树的基础上对叶子节点进行了改进，将所有的叶子节点都用链表连接起来，B+树的只在叶子节点保存数据，其他节点保存索引值
B+树和B树的区别如下:
子树数量和关键字数量一致(B树中子树数量比关键字数量多1) 叶子节点使用链表连接 非叶子节点会存放冗余的索引，叶子节点会存放具体的值和所有索引，所以非叶子节点有值重复(而B树所有节点都是唯一的) 因为B+树的所有叶子都使用链表连接，所以B+树支持范围查找，只需要找到起始节点即可
​
AVL树 参考 B树-王道考研视频 【讲的很好】
数据结构-B树【宁哥算法课堂】
2020B站最详细红黑树结构-二叉树-哈希-B+树-HASH-平衡算法
MYSQL核心底层原理大盘点！看完心里有B树了吗？ 【InnoDB讲的很好】</description></item><item><title>位运算骚操作</title><link>/2021/03/31/%E4%BD%8D%E8%BF%90%E7%AE%97%E9%AA%9A%E6%93%8D%E4%BD%9C/</link><pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/31/%E4%BD%8D%E8%BF%90%E7%AE%97%E9%AA%9A%E6%93%8D%E4%BD%9C/</guid><description>XOR 异或: 相同为0，不同为1
x^0=x x^(~x)=全1 #位数和x一样的全1 x^x=0 交换两个整数变量
a^=b b^=a a^=b 判断奇偶性
x&amp;amp;1 == 1 #奇数 x&amp;amp;1 == 0 #偶数 计算某个数字二进制位1的个数
int countOne(int num) { int cnt = 0; for (int i = 0; i &amp;lt; 8 * sizeof(num); ++i) { cnt += num &amp;amp; 1; num &amp;gt;&amp;gt;= 1; } return cnt; } 判断某一位是否为1
(n&amp;gt;&amp;gt;(pos-1))&amp;amp;1 乘2除2
n&amp;gt;&amp;gt;1 #/2 n&amp;lt;&amp;lt;1 #*2 掩码操作，获取前面几位
mask=11110000 n=10100000 mask&amp;amp;n #获取前面4位 其它位置0 将最低位的1置0
num &amp;amp; (num - 1) 一个数组中其他数都出现了2次，只有一个数出现了1次，找出那个数</description></item><item><title>github上的docker镜像仓库</title><link>/2021/03/30/github%E4%B8%8A%E7%9A%84docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/30/github%E4%B8%8A%E7%9A%84docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</guid><description>github镜像仓库 github上提供两种镜像仓库服务:
基于仓库和项目的专有docker仓库，和项目仓库关联，只有删除仓库才可以删除image 基于个人账户的独立的docker仓库，和任何项目无关，完全独立 ghcr.io #账户仓库 ghcr.io/USERNAME/IMAGE_NAME:VERSION #打标签案例 docker.pkg.github.com #具体项目仓库 docker.pkg.github.com/USERNAME/REPO_NAME/IMAGE_NAME:VERSION #打标签案例 使用github镜像仓库之前需要进行登入，登入的用户名就是github的用户名，密码就是github上创建的TOKEN，注意需要赋予package权限
echo $GITHUB_DOCKER_IMAGE_TOKEN | docker login ghcr.io -u biningo --password-stdin ​
参考 GitHub 镜像仓库服务 Ghcr 快速上手教程
Container guides for GitHub Packages【官方文档】</description></item><item><title>github美化README</title><link>/2021/03/30/github%E4%B8%8A%E7%BE%8E%E5%8C%96readme/</link><pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/30/github%E4%B8%8A%E7%BE%8E%E5%8C%96readme/</guid><description>收集一些有趣的东西 【给自己弄一个酷酷的Github主页】
https://blog.csdn.net/sinat_23133783/article/details/107643656
【关于wakatime的SpringBoot项目】
https://github.com/wf2311/wakatime-sync
【wakatime统计信息的action，展示在README上】
https://github.com/anmol098/waka-readme-stats
【展示自己github上统计信息的动态卡片到README】
https://github.com/anuraghazra/github-readme-stats
【为你的Github生成漂亮的徽章和进度条】
https://shikieiki.github.io/2017/03/01/为你的Github生成漂亮的徽章和进度条/
【GitHub新功能 建立你的GitHub个人页面】
https://dolorhunter.com/new-feature-build-your-github-profile-readme/
https://github.com/DolorHunter/DolorHunter
【图标库】
https://shields.io/#/
github-profile-readme</description></item><item><title>Go反射</title><link>/2021/03/29/go%E5%8F%8D%E5%B0%84/</link><pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/29/go%E5%8F%8D%E5%B0%84/</guid><description>待更新&amp;hellip;&amp;hellip;
什么是反射 反射 是指一类应用，它们能够自描述和自控制。也就是说，这类应用通过采用某种机制来实现对自己行为的描述（self-representation）和监测（examination），并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义
go官方自带的reflect包就是反射相关的，go反射主要有下面两大对象:
Value 值对象，通过reflect.ValueOf获取 Type 类型对象，通过reflect.Typeof获取 ​
Typeof 获取一个对象的类型对象Type，Type是一个接口，go中每种类型都实现了Type接口，比如chanType表示chan的Type对象
通过Type对象就可以获取类型相关的信息，比如 Name() 类型的名字、PkgPath() 包路径、**Size()**此类型占用的字节大小等，Type接口的方法不是每种类型都可以调用的，比如 Len() 方法只能arrayType类型才可以调用，表示数组的长度 ，Size() 方法则只可以由定长的类型才可以调用，比如数组、string、int64等，而slice、map就不可以调用Size方法，会报错
func main() { var i interface{} i = [2]int{1,2} //int类型默认和平台位数一致 这里为int64 t := reflect.TypeOf(i) log.Println(t.Len(),t.Size()) //2 8*2=16 } ​
ValueOf ValueOf就和TypeOf同理了，这里不多赘述，重点说明下面几个问题
Interface() 将一个对象转化为interface{}空接口类型
Elem() 如果值是一个指针的话，调用此方法获取指针指向的值的Value对象
Recv() 获取一个chan的值
Call() 调用一个函数，传入各个参数的Value对象
Field() 获取一个struct对象的各个属性的Value对象
​
反射原理 go在1.5之后就实现了 自举，自举过程如下:
先用C和汇编写一个Go的编译器，用C的编译器编译成可执行文件，此二进制文件就可以编译go代码了 用Go写一个Go的编译器，用上述编译器编译成二进制文件，此二进制文件就是用Go来实现的Go编译器 go的反射与 interface和unsafe.Pointer 结合的比较紧密 TODO
​
参考 https://i6448038.</description></item><item><title>中断</title><link>/2021/03/24/%E4%B8%AD%E6%96%AD/</link><pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/24/%E4%B8%AD%E6%96%AD/</guid><description>中断分类 中断按照是否由CPU内部发生分为:
外部中断 (由CPU外部引发，比如外设、网卡等) 内部中断 (由CPU内部引发，比如系统调用) 外部中断分为:
可屏蔽中断 (比如网卡发出数据读取中断，可以屏蔽) 不可屏蔽中断 (比如掉电、设备损坏等) 内部中断分为:
软中断 (由软件程序触发，比如系统调用0x80号中断) 异常 (异常也是一种特殊的中断，比如除0异常、缺页异常) ​
中断产生和调用过程 触发中断其实就是给出一个 中断号 ，然后CPU根据中断号去查找中断对应的程序进行执行的一个过程
操作系统会设置一个 IDT中断描述符表 ，里面记载了各个中断号对应的程序的入口地址，操作系统内核在运行初始化的时候必须初始化 中断寄存器指向的位置 ，因为一旦发生中断CPU就会去中断寄存器指向的IDT中去寻找中断程序
发生中断时用户态就会转化为内核态，CPU会保存程序当前执行的状态，比如会将栈指针、各个寄存器值、PC指针压入内核栈，然后开始执行中断处理程序，执行完毕之后再恢复现场，也就是将栈中的值都出栈然后放到各个寄存器中继续执行之前的代码
这里需要注意中断的进程状态管理和进程调度的进程状态管理这两个是不一样的
中断发生时的进程状态是保存在内核栈中，而进程调度发生时需要将进程的状态保存在PCB中
那么这个中断是如何引发的呢?
软中断和异常容易理解，CPU有一个int指令，后面跟给一个中断号，程序只需要执行这个指令即可触发软中断或异常，最常见的软中断就是int 0x80中断，此中断是系统调用中断，所有的系统调用都会触发这个中断，系统调用中断还需要给出 系统调用号 ，系统调用中断处理程序会根据系统调用号去执行相应的系统调用代码
外中断需要经过一个叫 中断代理 的硬件，该硬件连接了所有外设接口的中断线，外设如果需要引发中断则只需要往这个中断线里面传输信号到中断代理即可，中断代理会根据不同的信号转化为相应的 中断号 ，中断代理和CPU只连接了两条线: INTR和NMI INTR表示可屏蔽中断，比如网卡发出的中断、NMI表示不可屏蔽中断
可屏蔽中断的话只需要CPU设置状态寄存器中相应的位就表示屏蔽这些中断，注意: 软中断、异常都是会忽略该位的 也就是说软中断和异常都是不可屏蔽的，软中断通常来说是系统调用，用户进程需要系统调用则操作系统必须响应，否则会造成用户程序卡死无法获得操作系统提供的帮助，会造成用户体验不好，异常更不用说了，需要立即处理
中断代理将相应的中断号输出到INTR线中通知CPU，CPU没执行一条指令都会检查该线是否有中断信号(注意:CPU检查中断是由硬件电路来实现的，并不会有任何的损耗)
如果有中断信号则CPU会立即检测到
​
中断的上半部分和下半部分 一个中断程序可以分为 上部分和下部分 ，中断处理时可以先执行上半部分，这个部分一般来说比较紧急，等CPU空闲之后再继续执行下半部分
比如网卡发出数据读取操作，此时CPU先执行上半部分的中断程序：先将网卡缓存区里的数据拷贝到内核数据区，这个网卡就不会因为缓存区满而频繁丢包了(相当于一个紧急救火)，然后等CPU空闲了之后再执行中断下半部分，也就是将内核数据区域的数据拷贝到用户空间供用户使用
​
操作系统时钟中断 这个时钟和CPU的时钟不是一个概念，但是他们的功能都是差不多的，都是为了使操作系统或则CPU能正确的工作，时钟就相当于一个 节拍器，很多硬件设备也有时钟，为的就是让各个电路有序的进行操作
操作系统的时钟中断由 可编程的脉冲器 产生的，因为操作系统需要和硬件配合的，所以一般和硬件结合的比较紧密，该硬件脉冲频率是和操作系统厂商商量好的，并且可以人为的编程去改变脉冲的频率
时钟中断会定时的引发然后传递到CPU的NMI引脚，时钟中断属于不可屏蔽中断
时钟中断的作用非常大，可以说没有时钟中断操作系统就没有控制权，时钟中断的作用如下:
更新系统的时间 定时的将控制权转移到操作系统的程序中，以便操作系统进行各个调度工作比如进程时间片调度，每经过一个时钟则时间片减一 (如果没有时钟中断，那么如果用户程序如果一直不进行系统调用、不引发异常那么操作系统可能永远也拿不到CPU的控制权) ​</description></item><item><title>JavaIO流总结</title><link>/2021/03/23/javaio%E6%B5%81%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/23/javaio%E6%B5%81%E6%80%BB%E7%BB%93/</guid><description>OverView Java 的 I/O 大概可以分成以下几类：
磁盘操作：File 字节操作：InputStream 和 OutputStream 字符操作：Reader 和 Writer 对象操作：Serializable 网络操作：Socket 非阻塞IO：NIO ​
File文件相关操作 File类是操作文件系统的相关操作，如果要读取文件内容的数据，则需要传递给IO流对象，通过IO流的方式进行读取
File f = new File(&amp;#34;/home/pb/tmp/printf.sh&amp;#34;); FileInputStream inputStream = new FileInputStream(f); 通过操作此对象可以创建文件、列出目录下的文件列表、判断文件是否可读、判断类型等操作
f.isFile(); f.createNewFile(); ​
InputStream 字节流接口，所有流的接口，比如:
FileInputStream文件流用于读取文件 ByteArrayInputStream 从字节数组里面读取流 OutPutStream就是将数据写入到目标处，这里将程序员作为主体，Out表示程序员将数据输出到计算机，Input则表示计算机的数据要输入到程序员中
​
BufferedInputStream 带有一个字节缓冲数组的InputStream ，需要传入一个实现了 InputStream 接口的流，比如文件，使用了装饰者模式 ，读取流的话不是直接操作文件了，而是每次读取会预先读取到一块byte[]中，相当于缓冲，然后更具用户读取的大小从缓冲区里面读取到用户的字节数组中
​
Reader 字符流接口 一个字符可能有多个字节组成比如汉字，实现的接口有:
InputStreamReader 接受一个 InputStream 对象，然后按照编码将字节进行转化为字符 FileReader 继承 InputStreamReader ，用于直接读取文件，里面就是根据传入的File对象或则文件名创建一个 FileInputStream 然后传入父类 InputStreamReader ​
BufferedReader 带缓冲的Reader，需要传入一个实现了 Reader 接口的流，比如文件FileInputStreamReader，读取的话会先读入到char[]中，然后直接从char[]缓冲区进行读取，装饰者模式</description></item><item><title>Java集合总结和源码浅析</title><link>/2021/03/21/java%E9%9B%86%E5%90%88%E6%80%BB%E7%BB%93%E5%92%8C%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/</link><pubDate>Sun, 21 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/21/java%E9%9B%86%E5%90%88%E6%80%BB%E7%BB%93%E5%92%8C%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/</guid><description>OverView ​
HashMap和HashTable HashMap刚开始是一个Node节点的数组 ，初始化为16大小 如果节点元素个数达到一定的值(这个值略小于 HashTable 的大小)，则会进行扩容
然后逐渐放入元素，刚开始如果发生碰撞就采用 拉链法 进行解决碰撞 ，如果链表的节点个数&amp;gt;=8同时 数组 大小大于64 则会进行树化，转化为 红黑树 来加快查找(红黑树是一颗高度平衡的二叉查找树) 如果链表节点个数大于8但是数组小于64则会进行扩容数组
HashTable和HashMap的主要区别如下:
HashTable是并发安全的，HashMap不安全 HashTable的value不允许null，HashMap允许 HashTable属于老的集合容器，HashMap属于新一代集合容器 ​
ConcurrentHashMap 和HashMap差不多，但是这个是并发安全的
在 JDK1.8 中，ConcurrentHashMap 选择了与 HashMap 相同的数组+链表+红黑树结构，在锁的实现上，采用 CAS 操作和 synchronized锁 实现更加低粒度的锁，将锁的级别控制在了更细粒度的 table 元素级别，也就是说只需要锁住这个链表的首节点，并不会影响其他的 table 元素的读写，大大提高了并发度
​
LinkedHashMap LinkedHashMap能保持插入的顺序，HashMap+双链表 实现
在插入的时候同时给每个节点都按照插入的顺序串成一个双链表(LinkedHashMap给之前HashMap中的链表节点多加了两个前后节点实现)，这样遍历的时候就可以保持插入的顺序了，同时用key取值得时候效率还和 HashMap 一样
​
TreeMap TreeMap使用 红黑树 (一种高度平衡的二叉搜索树) 来实现 K-V 存储，根据搜索树的特性可以保持key有序，这样查找一个key就可以利用二分来快速查找
​
ArrayList、Vector、LinkedList ArrayList
ArrayList底层是一个Object[]数组 在添加元素的时候如果发现容量不足则以初始容量的 1.5倍速度扩容 初始容量默认值是10 ArrayList不是并发安全的 Vector
Vector底层也是Object[]数组 在添加元素的时候如果发现容量不足则以初始容量的 2倍速度扩容 初始容量默认值也是10 Vector是并发安全的，都在方法级别加上了synchronized LinkedList</description></item><item><title>HTTP协议FAQ</title><link>/2021/03/20/http%E5%8D%8F%E8%AE%AEfaq/</link><pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/20/http%E5%8D%8F%E8%AE%AEfaq/</guid><description>为什么HTTP/1.1协议不支持服务器端推送 HTTP/1.1规定了只能是 请求-响应 模式，为什么这样设计呢，我个人认为主要有如下几个原因:
客户端和服务器容易实现HTTP协议，简单 当时对页面的实时性，数据量没有现在大 当时并发程度不高 浏览器等客户端以及服务器都是根据HTTP协议进行设计的，所以即使HTTP/1.1能保持TCP的keep-alive一直连接并能被多个HTTP请求复用，但是依然无法实现服务器推送
即使你自己的服务器程序实现了HTTP推送，有些浏览器不支持那也没办法，因为大家都是遵循协议来的
即使服务器和客户端都实现了，那么还有很多代理服务器、缓存服务器、CDN服务器等也可能都没有实现这个HTTP推送，所以依赖无法实现推送
所以有了WebSocket协议，浏览器和服务器双方根据HTTP先握手建立TCP连接，然后进行协议升级，双方就可以根据WebSocket协议进行通讯，服务器就可以拿到TCP句柄进行服务器推送了
请求-应答模式带来了两个问题:
队首阻塞 过多的HTTP通讯，往返延迟加大 HTTP/1.1正是因为这个 请求-应答 模式，在一个TCP连接上一个请求发送之后必须等待响应回来之后才可以用这个TCP连接发送另外一个请求，不然浏览器无法识别应答是哪个请求的应答，所以产生了 HTTP报文队首阻塞问题 只要一个请求的应答阻塞了那么这个请求就必须一直等，之后排队的请求也必须等
为了解决 队首阻塞 问题于是浏览器就为每个用户开辟多个TCP连接来并发的发送多个HTTP请求，因为他们使用不同的TCP连接所以浏览器可以识别哪个应答属于哪个请求，但是一个用户如果TCP连接过多比如一个用户有10个TCP连接，那么1000个用户将会产生1000*10=10000个并发连接，这样会造成服务器压力变大，所以浏览器就必须限制每个用户的TCP并发连接数
并且客户端请求一个页面，发现页面里面包含css、js等资源，于是又发起这些资源的请求，这样起码一个页面会产生多次请求，多次请求都会一个个排队等待响应，这样无形之中又加大了延迟，但是如果有服务器推送，那么在第一次客户端请求这个页面的同时就把页面还有css、js等资源一起推送过去，这样就只需要一次请求即可完成，减少了网络传输的HTTP包减少了请求次数，也降低了延迟
​
为什么 HTTP1.1 不能实现多路复用 HTTP不能实现多路复用是因为一个HTTP请求只能在一个TCP连接里面传输，因为HTTP的报文都是文本形式的，并且是不分帧，如果不在一个TCP连接里面传输的话浏览器就无法识别这个报文响应属于哪个请求，服务器必须将响应报文按原路返回回去
HTTP2则可以实现一个HTTP报文可以在不同的TCP连接里面传输，因为HTTP2的报文是二进制形式将HTTP报文分为一个个的数据帧的，并且有 流 的概念来识别一个请求的响应报文</description></item><item><title>Java泛型总结</title><link>/2021/03/20/java%E6%B3%9B%E5%9E%8B%E6%80%BB%E7%BB%93/</link><pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/20/java%E6%B3%9B%E5%9E%8B%E6%80%BB%E7%BB%93/</guid><description>为什么需要泛型 Java的泛型机制在Java 5.0中加入，为什么需要泛型呢?
在以前没有泛型的情况下，一个 List 类型要能存放所有类型那么底层只能是Object数组来接受所有类型，这样的话我们可以将所有类型都放入这个Lits中，从Lits中获取元素的时候再强转，这样很容易会引发 ClassCastException异常
再来想想，如果不使用Object会怎么样？
这样的话虽然可以避免 ClassCastException异常 但是就要为每种类型都写一个List类，增加了代码量
如果加入泛型之后就不会在运行时引发错误，因为错误都会在编译的时候就发现，泛型的引入能让编译器更好的优化和检查程序的前期错误而不是等到运行的时候再出现错误
并且也不需要为每种类型都写一个List了，直接在new的时候指定类型即可，相当于造了一个代码模具(因为这个代码对于每种类型的操作都是一样的)，使用的使用填充类型即可
总结一下为什么需要泛型:
强类型，编译器通过泛型实现类型检测，避免运行时类型转换错误，增强代码可读性 对象重用，减少代码量 ​
泛型在Java中的使用 泛型类和泛型方法的案例
public class Pair&amp;lt;T, U&amp;gt; { private T t; private U u; public Pair(T t, U u) { this.t = t; this.u = u; } public T getT() { return this.t; } //泛型可以单独应用在方法上 调用: p.&amp;lt;String&amp;gt;(&amp;#34;one&amp;#34;) public &amp;lt;E&amp;gt; void echo(E e) { System.out.println(e); } public U getU() { return this.u; } 泛型还可以应用在 接口 上</description></item><item><title>Java注解和反射</title><link>/2021/03/20/java%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/</link><pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/20/java%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/</guid><description>为什么需要注解 注解也是Java 1.5开始引入的，注解产生是为了替代早期的XML配置文件的，早期使用配置文件XML
其中注解与代码强耦合，一旦改变就需要重新编译，而XML配置文件则和代码分开，修改XML配置文件不需要重新编译因为XML原本就是不编译进字节码中的，Java代码通过文件读取的方式获取XML配置文件的信息
但是注解的优点就是方便简洁好维护，而XML则不方便不容易维护而且配置复杂
​
元注解 元注解 是一种注解在注解上的一种注解，由Java标准库提供，我们自定义注解必须要标注上元注解用于说明这个自定义注解的范围等
元注解有如下4个:
@Target 表示注解可以注解在方法上还是类上 @Retention 表示注解保留在什么范围 ，一般注解和反射配合使用，所以一般这个值为runtime 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们 @Documented 将注解中的元素包含到 Javadoc 中 @Inherited 子类可以继承父类的注解 ​
自定义注解 如果注解只有一个值，则需要设置为value()这样注解上就不需要key指定了
@Target(ElementType.METHOD) public @interface My { String value() default &amp;#34;&amp;#34;; //可以赋值默认值 } 直接这样使用即可，如果有多个则必须要指定key，没有指定默认值得必须写出值，否则可以不写使用默认值
@My(&amp;#34;A&amp;#34;) 注解也可以定义数组，数组元素只有一个时不需要花括号包裹
@Target(ElementType.METHOD) public @interface My { String value() default &amp;#34;&amp;#34;; String[] names(); } @My(value=&amp;#34;A&amp;#34;,names={&amp;#34;lyer&amp;#34;,&amp;#34;b&amp;#34;}) ​
为什么需要反射 首先来看反射能做什么我们才可以知道为什么需要反射机制了:
有了反射我们可以在程序运行时动态的加载类，只需要给定类的全路径名即可，而不需要硬编码代码中 反射相当于给了程序员一个后门 可以破坏封装，直接获取一个类的所有属性或则方法，让我们了解一个陌生类的所有属性和方法，知道这个类里面都有什么东西，并且可以创建这个类执行里面的私有方法等 知道反射能干啥之后我们就可以得出为什么需要反射机制了:
方便测试
运行时动态加载类，不需要编译时确定写死 (并且有些类无法在编译之前就知道需不需要加载，只有在运行时才知道是否需要加载，这时候就需要反射了，比如数据库驱动，用户可能选择不同的数据库，所以程序需要更具用户的XML配置等来决定加载哪个数据库的驱动)</description></item><item><title>Shell脚本基本语法总结</title><link>/2021/03/19/shell%E8%84%9A%E6%9C%AC%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</link><pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/19/shell%E8%84%9A%E6%9C%AC%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</guid><description>变量 变量类型分为:
全局 (declare或则直接写) 局部(函数内部) local声明 环境变量 只读变量
readonly name=&amp;#34;AAA&amp;#34; #之后再次赋值会报错 #只读变量也可以后来才设置 name=&amp;#34;BBB&amp;#34; readonly name 删除变量 (只读变量不能删除)
name=&amp;#34;AA&amp;#34; unset name if [ -z $name ];then echo &amp;#34;null&amp;#34; else echo &amp;#34;${name}&amp;#34; fi 特殊变量有如下几个类型:
量 含义 $0 当前脚本的文件名 $&amp;lt;n&amp;gt; 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。 $# 传递给脚本或函数的参数个数。 $* 传递给脚本或函数的所有参数。 $@ 传递给脚本或函数的所有参数。被双引号&amp;quot;&amp;quot;包含时，与 $* 稍有不同 $? 上个命令的退出状态，或函数的返回值，用于判断上一个函数或则命令是否执行成功 $$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 ${@}和${*} 的区别</description></item><item><title>Spring总结</title><link>/2021/03/19/spring%E6%80%BB%E7%BB%93/</link><pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/19/spring%E6%80%BB%E7%BB%93/</guid><description>Spring控制反转IOC和依赖注入DI 1、XML配置文件DI注入 Set注入 Set注入是调用对应的Set方法来实现的，方法名需要遵循 setName 形式，必须采用小驼峰法，否则无法注入，set注入首先会调用无参构造器创建类
&amp;lt;bean id=&amp;#34;hello&amp;#34; class=&amp;#34;di.model.User&amp;#34;&amp;gt; &amp;lt;property name=&amp;#34;username&amp;#34; value=&amp;#34;lyer&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;age&amp;#34; value=&amp;#34;18&amp;#34;/&amp;gt; &amp;lt;/bean&amp;gt; set注入可以注入多个数据类型的属性，常见的有如下几个类型
map array list 基本类型 set bean(对象) @Data public class Student { private Integer id; private String name; private List&amp;lt;String&amp;gt; hobby; private Map&amp;lt;String,Integer&amp;gt; scores; private Set&amp;lt;String&amp;gt; friends; private Address address; } &amp;lt;bean id=&amp;#34;stu&amp;#34; class=&amp;#34;di.model.Student&amp;#34;&amp;gt; &amp;lt;property name=&amp;#34;id&amp;#34; value=&amp;#34;1&amp;#34;/&amp;gt; &amp;lt;property name=&amp;#34;name&amp;#34;&amp;gt; &amp;lt;null/&amp;gt; #显示指定为null 默认不设置值也为null &amp;lt;/property&amp;gt; &amp;lt;property name=&amp;#34;scores&amp;#34;&amp;gt; &amp;lt;map&amp;gt; &amp;lt;entry key=&amp;#34;english&amp;#34; value=&amp;#34;100&amp;#34;/&amp;gt; &amp;lt;entry key=&amp;#34;chinese&amp;#34; value=&amp;#34;99&amp;#34;/&amp;gt; &amp;lt;/map&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property name=&amp;#34;friends&amp;#34;&amp;gt; &amp;lt;set&amp;gt; &amp;lt;value&amp;gt;xioamin&amp;lt;/value&amp;gt; &amp;lt;value&amp;gt;hong&amp;lt;/value&amp;gt; &amp;lt;/set&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property name=&amp;#34;hobby&amp;#34;&amp;gt; &amp;lt;list&amp;gt; &amp;lt;value&amp;gt;running&amp;lt;/value&amp;gt; &amp;lt;value&amp;gt;basketball&amp;lt;/value&amp;gt; &amp;lt;/list&amp;gt; &amp;lt;/property&amp;gt; #内联bean 也可以ref引用外部bean &amp;lt;ref bean=&amp;#34;address&amp;#34; /&amp;gt; &amp;lt;property name=&amp;#34;address&amp;#34;&amp;gt; &amp;lt;bean class=&amp;#34;di.</description></item><item><title>完全二叉树和满二叉树</title><link>/2021/03/19/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E6%BB%A1%E4%BA%8C%E5%8F%89%E6%A0%91/</link><pubDate>Fri, 19 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/19/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E5%92%8C%E6%BB%A1%E4%BA%8C%E5%8F%89%E6%A0%91/</guid><description>满二叉树 如果二叉树中除了叶子结点，每个结点的度都为 2，则此二叉树称为满二叉树
满二叉树有如下几个性质:
满二叉树第i层节点的个数2^(i-1)
深度为n的满二叉树必须有2^(n)-1个节点，叶子节点有2^(n-1) (也就是最后一层的节点数量)
满二叉树中不存在度为 1 的节点，每一个分支点中都两棵深度相同的子树
具有 n 个节点的满二叉树的深度为 log2(n+1)
第i个节点的左右孩子分别为i*2+1 i*2+2 (孩子节点从0开始算起，如果孩子节点从1开始算起的话就是i*2 i*2+1 )
第i个节点的父亲节点i/2-1 ，如果从1开始算起就是i/2
​
完全二叉树 结点依次从左到右分布，中间无法断开，则此二叉树被称为完全二叉树，完全二叉树适合用数组来存储
第i个节点的左右孩子分别为i*2+1 i*2+2 (孩子节点从0开始算起，如果孩子节点从1开始算起的话就是i*2 i*2+1 )
第i个节点的父亲节点i/2-1 ，如果从1开始算起就是i/2
注意上面的计算要注意范围
堆就是用完全二叉树来实现的</description></item><item><title>Redis命令总结</title><link>/2021/03/16/redis%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/16/redis%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</guid><description>Keys COPY 复制key
COPY name username #name-&amp;gt;username username必须不存在 COPY name username DB 1 #name-&amp;gt;1:username COPY name username REPLACE #存在则更新 DEL 删除key 返回值是删除的个数
UNLINK非阻塞删除，重新开辟一个线程去回收内存，立即返回
DEL key1 key2 EXISTS 查看可以是否存在 返回值是存在键的数量
EXISTS age username EXPIRE EXPIREAT 设置key的过期时间，如果重新设置的key的值，前者是设置n秒后过期，后者设置一个Unix时间戳，表示在指定时间戳后过期
TTL 查看key剩余的时间·秒，返回-1则表示永久 -2则表示key不存在，PTTL则是毫秒
PERSIST 解除timeout时间
EXPIRE name 10 EXPIREAT name 8233132131 TTL name PERSIST name KEYS 模式匹配展示出keys
KEYS name* # * 匹配所有 KEYS name? # ? 匹配一个 MOVE 移动key到指定的db
MOVE age 2 OBJECT 展示redis每个key的对象相关的信息，比如对象底层的数据结构是什么
redis有五大常见对象:</description></item><item><title>TSL(SSL)协议</title><link>/2021/03/16/tslssl%E5%8D%8F%E8%AE%AE/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/16/tslssl%E5%8D%8F%E8%AE%AE/</guid><description>什么是TSL协议 因为HTTP传输都是明文传输的，如果被中间人截获，那么报文内容就会被盗取
为了防止HTTP明文传输，于是可以讲HTTP报文和数据整个进行加密然后再将数据传递给下层的TCP层，传递到客户端再进行解密，TSL协议就是解决HTTP报文加密问题的，被TSL协议加密之后的HTTP协议就叫HTTPS HTTP over SSL 使用的是443端口
TSL是SSL的改进版，现在都是使用TSL来替换SSL了，但是延续了老的叫法，所有都叫SSL 这两个其实是同一个意思
TSL现在广泛使用的版本为TSL1.2 TSL1.3
​
TSL握手第一阶段 加密算法有 对称加密、非对称加密 ，如果将HTTP报文采用非对称加密的话那么带来的CPU运算是非常大的，速度也相对较慢，因为HTTP报文一般数据比较大
所以TSL采用对称加密的方式来加密HTTP报文加快加密解密的速度，但是这里就涉及到如何传递 对称密钥 的问题了，这就是 TSL握手 需要解决的问题，就是生成对称密钥
Client Hello TCP建立之后浏览器会先发送一个Client Hello TSL报文给服务器，目的是为了告诉服务器如下内容，重点关注如下内容:
客户端TSL版本 支持的加密套件Cipher Suites : 使用什么加密算法等，服务器会选择一个加密算法 随机字符串Random1 : 这个随机数和之后的生成对称密钥有关 Session ID 用来恢复会话 SessionTicket 客户端保存的TSL的session信息 Server Hello 服务器接受到客户端的Client Hello之后就会检查客户端版本、加密套件等信息，检查通过并且符合服务器的条件则服务器会进行回复，也就是发送Server Hello包
回复内容主要是告诉客户端如下几个重要的内容:
服务器的TSL版本
从Client Hello中选择一个加密套件，告诉服务器选择了哪个套件
随机字符串Random2 此时客户端和服务器都拥有 Random1、Random2
Session ID 初次握手服务器会返回一个Session ID，客户端会保存这个ID，之后再进行握手发送Client Hello的时候就会携带上这个Session ID，服务器就会直接查询Session ID对应的信息比如对称加密的密钥，这样就可以直接复用了就不需要再次生成了，因为生成过程也有一定的消耗</description></item><item><title>WebSocket协议</title><link>/2021/03/16/websocket%E5%8D%8F%E8%AE%AE/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/16/websocket%E5%8D%8F%E8%AE%AE/</guid><description>WebSocket要解决的问题 由于HTTP是请求应答模式，所以如果是聊天室这样的项目的话，那么为了立即获取到信息浏览器就必须进行不断的轮询服务器，不仅效率低下，而且还无法立即获取到数据
于是就有了WebSocket协议，WebSocket是通过HTTP协议进行握手然后再进行通讯的，因为浏览器无法同服务器直接建立TCP连接，所以只能先通过HTTP协议建立一个TCP连接通道，之后再升级协议采用WebSocket协议，这样WebSocket就和HTTP采用相同的端口进行和服务器通讯了
ws://www.chrono.com ws://www.chrono.com:8080/srv wss://www.chrono.com:445/im?user_id=xxx #加密的websocket协议 ​
WebSocket握手 WebSocket握手是通过HTTP协议进行的
首先浏览器请求升级协议
GET /xx HTTP/1.1 Connection: Upgrade Upgrade: websocket Sec-WebSocket-Key: sdadsxxada== Sec-WebSocket-Version: 13 Sec-WebSocket-Key 是一个 Base64的16byte的随机数 用于简单认证，防止误连
然后浏览器返回101响应
HTTP/1.1 101 Switching Protocols Sec-WebSocket-Accept: dsdada Sec-WebSocket-Accept 是把请求头里Sec-WebSocket-Key的值，加上一个专用的 UUID “258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，再计算 SHA-1 摘要，客户端接受到响应之后使用相同的方法计算出摘要然后判断是否相等，相等表示认证成功
握手成功之后传递的就是WebSocket报文了
​
WebSocket报文格式 域 说明 FIN 1bit，是否为信息的最后一帧 RSV 1-3 1bit，备用，默认为0 opcode 4bit，帧类型 1 表示帧内容是纯文本，2 表示帧内容是二进制数据，8 是关闭连接，9 和 10 分别是连接保活的 PING 和 PONG MASK 1bit 掩码，是否用XOR进行简单加密数据。 客户端发送给服务端时，mask必须为1，否则断开连接。 服务端发送给客户端时，mask必须为0，否则断开连接。 payload length 表示帧的长度。它是另一种变长编码，最少 7 位，最多是 7+64 位，一个 WebSocket 帧最大是 2^64 Masking-key 0或32 bit掩码值(Mask为1时才有)，是一个4byte的随机数 Playload data 长度为Payload len的数据，如果有掩码，需要用Masking-Key来异或解密 ​</description></item><item><title>HashMap源码分析</title><link>/2021/03/12/hashmap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link><pubDate>Fri, 12 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/12/hashmap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid><description>为什么对象需要同时重写equals和hashcode Object对象有两个重要的方法: equals hashcode
public boolean equals(Object obj) { return this == obj; //默认直接比较是否是同一个引用 } @HotSpotIntrinsicCandidate public native int hashCode(); equals 默认是直接比较是否是同一个引用
hashCode 则不同机器实现不一样，一般是用变量的内存地址来进行计算hash值的
如果一个对象要放入 HashSet 或则 HashMap 的话，需要遵循下列原则，否则就会出现不可预期的错误(HashSet是用HashMap来实现的，所以只需要讨论HashMap即可):
如果一个类重写了equals()方法，则必须重写hashCode()方法。2个对象的equals()方法返回true的话，其hashCode()必须返回相同的值
为什么需要重写 hashCode() 方法呢?
这个很好理解，因为HashMap查找和放入一个 kv 必须计算出key的hash值，然后选择合适的位置放入value，其实就是直接调用key的hashCode()方法计算hash值，下次查找就是直接根据hash值来直接索引到value(这里还需要考虑Hash碰撞问题)，这样就实现了O(1)速度的查找，HashMap是典型的空间换时间的例子
如果我们不重写hashCode()方法，则会调用父类Object的hashCode方法，该方法是根据值得内存地址计算得出的，也就是说我们不重写的话，那么两个我们认为值相同的key对象计算出的hash值就会不一样，这样就会导致错误，比如HashSet无法进行去重等，下面的Student没有重写hashCode方法
public static void main(String[] args) { HashSet&amp;lt;Student&amp;gt; set = new HashSet&amp;lt;&amp;gt;(); Student s1 = new Student(&amp;#34;one&amp;#34;); Student s2 = new Student(&amp;#34;one&amp;#34;); set.add(s1); set.add(s2); System.out.println(set.size()); //2 【错误】这里应该为1 } 已经重写了hashCode()，为什么还需要重写equals()方法？
虽然我们重写了hashCode() 方法，但是还是无法得出正确的结果，因为hash值可能会发生 hash碰撞 ，也就是两个不同值得对象计算出的hash值一样，这个时候就会用 拉链法 等算法来解决碰撞，所以如果只比较hashCode就认为两个对象是相等的这显然是不合理的，所以 HashMap 在添加和取对象的时候不仅仅会比较hashCode，还会比较equals方法，如果两个都相等才判断为同一个对象</description></item><item><title>IP协议</title><link>/2021/03/11/%E7%BD%91%E7%BB%9C%E5%B1%82%E5%92%8Cip%E5%8D%8F%E8%AE%AE/</link><pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/11/%E7%BD%91%E7%BB%9C%E5%B1%82%E5%92%8Cip%E5%8D%8F%E8%AE%AE/</guid><description>TODO</description></item><item><title>TCP协议</title><link>/2021/03/11/tcp%E5%8D%8F%E8%AE%AE/</link><pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/11/tcp%E5%8D%8F%E8%AE%AE/</guid><description>TCP协议 面向连接、可靠的字节流传输协议 全双工 可相互传递字节流 只可用于 一对一通信 ，不能用于多播和组播 TCP 使用校验和，确认和重传机制来保证可靠传输 TCP 使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 TCP使用 (源地址，源端口，目的地址，目的端口)来标识一个连接 ​
TCP报文 源端口和目的端口 端口大小为16位，可见端口范围为:0~2^16 也就是[0~65536]
IP层则用ip地址来标识一台主机，TCP层用端口来标识一个应用，使用(源地址，源端口，目的地址，目的端口)唯一确定一个连接，所以对于IPV4的话单台主机最大的连接数为 2^(32+16+32+16) 个
序号 每个TCP包都有一个序号，编号是为了解决TCP包乱序问题，给每个包编上序号就知道了每个包的顺序，这样就可以完整的拼好所有的TCP包了而不造成乱序，TCP给个字节都有一个序号，序号是整个TCP包数据段的第一个字节的序号，比如现在一个包的起始序号为101，数据长度为500byte ，那么最后一个字节的序号就为600，这个TCP包的序号为第一个字节的序号101 ，所以下一个TCP包的第一个字节的序号应该为601，也就是下一个TCP包的序号为601
如果序号达到最大值2^32，则回卷到0
由于初始的seq号是随机生成的，所以TCP回绕到0之后怎么继续保持字节序呢?怎么判断字节序呢?
回绕之后遇到相同的seq号则可以根据TCP头部携带的时间戳来判断前后
确认号 设置TCP包的确认号是为了告诉对方上一个数据包已经确认收到了，你可以继续发送下一个TCP包了，这个确认号填的就是期望对方发送的下一个TCP包的 序号
比如B收到了A发的序号为101的TCP包，该包长度为500byte，B现在收到了A发的600byte之前的数据，期望A发送下一个序号为601的TCP包，所以确认号为601
A收到B的回复的确认号为601得知B已经收到了A发的600byte之前的数据，现在要发下一个序号为601的TCP包了
首部长度 长度为4位
指出TCP首部的大小，因为TCB首部中有可选择字段，所以每个TCB首部都是不定长的，所以需要指定首部长度，单位是4字节 ，最大为2^4 ，所以首部最大长度为16*4byte=60byte
保留位 6位，保留以后使用，目前全部置0
五大标志位 6位
标志 含义 URG 紧急位，为1的话则表示这是个紧急的TCP包，应该放到发送队列的最前面去立即发送 ACK ACK=1表示确认号有效，ACK=0表示确认号无效，TCP连接建立成功后所有的传输报文必须把ACK置为1 PSH 很少用到，一般为0 RST 复位 RST=1 表示TCP连接出错，必须释放连接重新建立 SYN 同步 SYN=1表示这是一个请求建立连接或接受建立连接请求报文 SYN=1 ACK=0表示这是一个建立连接请求，SYN=1 ACK=1表示这是一个应答建立连接请求的TCP报文，详情请参考TCP三次握手 FIN 用来释放连接， FIN=1 表示数据已经发送完毕并且请求释放TCP连接 窗口大小 TCP使用 滑动窗口 来实现拥塞控制和流量控制，详情请见下文，比如B响应给A的报文中窗口字段的大小为1000 ，确认号为101 目的就是为了告诉A可以发送101开始的数据包了，缓存空间大小为1000byte，也就是还可以接受101~1101字节范围的数据包</description></item><item><title>Go语法细节基础</title><link>/2021/03/08/go%E8%AF%AD%E6%B3%95%E7%BB%86%E8%8A%82%E5%9F%BA%E7%A1%80/</link><pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/08/go%E8%AF%AD%E6%B3%95%E7%BB%86%E8%8A%82%E5%9F%BA%E7%A1%80/</guid><description>基础 byte和rune byte是uint8的内置别名。 我们可以将byte和uint8看作是同一个类型 rune是int32的内置别名。 我们可以将rune和int32看作是同一个类型，代表一个Unicode字符，Unicode字符目前还没超过32位
uintptr、int、uint uintptr代表一个地址，所以必须要能寻找到计算机所能表示的最大地址，随意其大小随计算机的位数而确定，如果是64位则该类型的大小也是64位的
同理int、uint等也是相似的，随本机类型而定，64位机器则是int64
type自定义类型 type MyInt int64 //此类型是一个新的自定义类型 和int64类型不一样 type Int64=int64 //此类型和int64类型是一样的 类型0值 类型 默认值 bool false int、float64等数值类型 0 string &amp;quot;&amp;quot; 整数类型的表示 d1:=0x10F //16进制 int64 d2:=0b111 //二进制 int64 d3:=10_000_000 //可以用下划线分割方便观看 10000000 浮点数的表示 //[float64] d1:= .32 //0.32 d2:= 2. //2.0 d3:=2.3e3 //2300 d4:=2.3e-3 //0.0023 字符串的``反引号 s:=`1111 2222 3333` //反引号不会进行转义 常量const和itoa const定义的一组变量可以设置相同的值</description></item><item><title>HTTP协议</title><link>/2021/03/08/http%E5%8D%8F%E8%AE%AE/</link><pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/08/http%E5%8D%8F%E8%AE%AE/</guid><description>请求和响应报文 请求报文第一行必须指定 请求的方法、资源路径、HTTP协议版本
紧接着就是请求头信息
然后还需要一个空行
紧接着如果有请求体的话就是请求体，注意如果没有请求体也必须加一个空行
GET /note/ef1b6cee.html HTTP/1.1 Host: www.ru23.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) ....各个请求头 &amp;lt;空行&amp;gt; 响应报文第一行必须指定 HTTP协议版本、状态码、状态码的字符串简短描述
紧接着就是响应头信息
然后还需要一个空行
如果有响应体的化就需要一个响应体，没有的话空行也是必须的
HTTP/1.1 200 OK Server: nginx/1.16.1 Date: Sun, 04 Oct 2020 02:27:01 GMT Last-Modified: Sun, 30 Aug 2020 14:12:42 GMT Content-Type: text/html Content-Length: 40846 Accept-Ranges: bytes &amp;lt;!</description></item><item><title>网络分层和协议栈总览</title><link>/2021/03/05/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82%E5%92%8C%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%80%BB%E8%A7%88/</link><pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/05/%E7%BD%91%E7%BB%9C%E5%88%86%E5%B1%82%E5%92%8C%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%80%BB%E8%A7%88/</guid><description>OSI七层模型和TCP/IP五层模型 ​
为什么网络要分层 复杂的计算机程序都需要通过分层来设计，这是一种设计模式，通过分层每层各司其职，每层都可以独立升级和维护
​
TCP/IP协议栈 1、应用层 协议 全名 功能 基于/端口 HTTP Hypertext Transfer Protocol web TCP/80 HTTPS Hypertext Transfer Protocol Secure 加密的HTTP SSL/TSL/443 SSL/TSL Secure Socket Layer/Transport Layer Security 加密协议 FTP File Transfer Protocol 传输文件 TCP/21(控制)/20(数据传输) SSH Secure Shell 连接远程Linux主机 TCP/22 SFTP SSH File Transfer Protocol SSH加密的FTP SSH/22 DNS Domain Name System IP和域名的解析转化 UDP/TCP/53 SMTP Simple Mail Transfer Protocol 邮件收发 TCP/25 POP3 Post Office Protocol-Version 3 收邮件 TCP/110 RPC Remote Procedure Call 调用远程的函数 TCP/随机 DHCP Dynamic Host Configuration Protocol 在局域网中动态分配IP UDP/67(接收)/68(请求) 2、传输层 协议 全名 功能 TCP Transmission Control Protoco 可靠的传递网络数据包 QUIC Quick UDP Internet Connections Google研发的基于UDP的传输层协议，用于替换TCP 2、网络层 协议 全名 功能 IP Internet Protocol 广域网传递数据包 ARP Address Resolution Protocol 根据IP获取MAC ICMP Internet Control Message Protocol 传递网络控制信息，需要加上IP报头组成IP数据报发送 ​</description></item><item><title>数据链路层和以太网</title><link>/2021/03/04/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E5%92%8C%E4%BB%A5%E5%A4%AA%E7%BD%91/</link><pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/04/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%E5%92%8C%E4%BB%A5%E5%A4%AA%E7%BD%91/</guid><description>局域网和以太网的区别 局域网需要解决的就是网内多对多的通讯，局域网内所有的主机都可以进行通讯，一个简单粗暴的办法就是给每台PC都连接到网内任何一台PC的网线这不现实，每加入一台PC就需要给网内的每台PC加一条网线太不现实了，所以就需要一些 局域网拓扑结构 来解决这个问题
局域网拓扑结构有很多种，有星型、环形、总线型等，大多数的局域网都是 星型 局域网内的主机都连接到比如 集线器 的物理设备中进行通讯，所有信息都经过集线器然后再进行转发，这样局域网内的主机就可以和网内所有的主机进行通讯了，这种 星型 类型的局域网叫做 以太网
综上: 以太网是一种局域网
​
MAC地址 24:41:8c:28:e2:ea MAC地址由:分割，每个单元都由一个16进制表示，大小为8byte，MAC地址是全球唯一的
前 24 位是设备制造商的标识符，由IEEE组织分配，也就是组织唯一标识符，后24位由设备制造商自己内部分配，必须要保证唯一
​
数据链路层 数据链路层需要将上层 网络层 传递下来的 IP数据报 封装层帧（也就是加上一些报头和报尾）然后将数据帧在 局域网/以太网 中传播，在数据链路层/以太网中 MAC地址 唯一标识一台网络设备
为什么有了IP还需要MAC ? 为什么有了MAC还需要IP?
现在基本的局域网都是 以太网 ，所以最常见的链路层的数据帧是 Enthernet || 格式
的数据帧，也叫 MAC帧 (因为该帧的特点是通过MAC地址进行通讯)
链路层主要有两种类型的信道:
1对1信道，比如 PPP协议 广播信道，比如以太网 链路层主要解决下列3个问题:
封装成帧: 比如 Ehthernet || 数据帧 ，并且需要对一些特殊字符(比如报文信息中出现了和数据帧控制字符一样的字节)进行转义处理，并且需要加入一些头部控制信息，比如目标的MAC地址和源地址，以及数据帧内容的类型，是IP数据报还是ARP报文、ICMP报文等其他类型的数据帧 差错检测: 如果数据帧在传输过程被干扰出现错误，那么就需要丢弃这个数据帧，所以在接受到之前需要进行检测 透明传输: 因为之前插入了一些转义处理的字节，所以在接受到时需要去除这些冗余的字节，这些多余的字节必须不影响原来数据包的传播，看起来就像是透明的 ​
Ehthernet ||帧格式 没有VLAN的格式
有VLAN格式</description></item><item><title>ARP协议</title><link>/2021/03/03/arp%E5%8D%8F%E8%AE%AE/</link><pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/03/arp%E5%8D%8F%E8%AE%AE/</guid><description>什么是ARP协议 ARP协议 是一种位于 网络层 和 IP协议 同级的协议，用于 根据IP获取MAC地址
由于最终数据要到达目标主机，以太网/局域网中必须通过MAC地址来唯一识别一台主机，所以在链路层发送数据包必须知道目标主机的MAC地址以此封装一个个链路层的以太网格式的数据帧来传递，ARP在发送请求的时候也会被封装为以太网格式的数据链路帧，目的MAC地址为局域网的广播地址
也有RARP协议，根据MAC获取IP，用的不多
​
ARP协议过程 源主机要发送数据时会先检查本机的 ARP映射缓存(记录了IP地址和MAC地址的映射关系,方便快速查找,该缓存有一个失效时间,因为IP地址和目标主机的映射可能会变所以必须设置失效时间)
如果本地缓存有则直接获取到目标主机的MAC地址
如果本地缓存没有则需要广播发送一个局域网内的ARP请求包，所有的局域网内的主机都会收到，如果目标IP是自己则响应这个ARP请求，将自己的MAC地址响应回去，如果不是则丢弃ARP包 (这里会有一个ARP欺骗问题)
收到到ARP响应之后就获取了目标机器的MAC地址，则本机就会将映射关系缓存起来然后就可以将IP数据报封装为以太网中的 MAC数据帧(包含源MAC地址和目的MAC地址的数据帧) 然后再发送数据包给目标机器了
​
ARP数据包结构 op操作类型: 1表示是ARP请求，2表示是ARP响应 下面请看WireShark的抓包
ARP请求:
ARP响应
另外还需要注意在以太网MAC帧的Type字段需要设置为0x0806标识数据报是ARP数据报，同时MAC帧的目的的MAC地址是ff:ff:ff:ff:ff:ff，这是一个MAC广播地址
​
相关命令 arp命令
arp -a #获取本机的ARP缓存 cat /proc/net/arp #也可以获取本机ARP缓存 查看本机MAC地址的方法
cat /sys/class/net/eth0/address ifconfig ​</description></item><item><title>基金</title><link>/2021/03/03/%E5%9F%BA%E9%87%91/</link><pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/03/%E5%9F%BA%E9%87%91/</guid><description>基金分类 (分险依次降低)
股票型 混合型 债权型 货币型 A类基金：买入有手续费 长期投资 卖出需要手续费
C类基金：买入没有手续费 短期投资 卖出需要手续费
专业术语 https://zhuanlan.zhihu.com/p/348003436
​
基金交易时间 交易时间 净值确认日 交易确认日 盈亏查看日 周一15点前 周一 周二 周三 周一15点后—周二15点前 周二 周三 周四 周二15点后—周三15点前 周三 周四 周五 周三15点后—周四15点前 周四 周五 下周一 周四15点后—周五15点前 周五 下周一 下周二 周五15点、周六、周日 下周一 下周二 下周三 工作日时间: 9:30~11:30 13:00~15:00(建议交易在后面的时间段，这样最接近当然的价格) 周日晚上~周四15:00之前申购基金的最好时间 每次买卖一定要在当日下午15: 00前操作(最好是在14：00左右这样最接近当然的价格)，超过15:00就不要操作了，因为超过15:00就是次日的价格了 ​</description></item><item><title>Base64编码</title><link>/2021/03/02/base64%E7%BC%96%E7%A0%81/</link><pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/03/02/base64%E7%BC%96%E7%A0%81/</guid><description>什么是Base64编码 将二进制数据转化为64个可打印ASCII码的一种编码方式，这64个可打印字符分别为:
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/= 注意，最后一个=不算，=当做Base64编码的结尾标志
总结：基于 64 个可打印字符来表示二进制数据的表示方法
​
Base64编码原理 将待转换的字符串每3个字节分为一组，每个字节占 8 个二进制位，那么共有24个二进制位
将第（1）步得到的每 24 个二进制位分为每 6 个一组（因为2^6=64），则每 3 个字节可分为 4 组
在每组前面添加两个 0 ，补齐1字节，每组由 6 个二进制位变为 8 个二进制位，总共 32 个二进制位，即四个字节 （3字节变4字节，所以经过Base64编码的都会变大）
6个二进制位转化为十进制然后检索下表，根据 Base64编码对照表（见下表）获得对应的值
​
为什么么需要Base64编码 方便网络传输 Base64的那64个字符只包含最基础的字符，所以在各种环境进行传输的时候，极大地减少了出现莫名其妙的问题的概率 简单的隐藏可见内容 （Base64只是一种编码方式，不能用来加密信息） 将二进制数据转化为可打印字符 ​
Base64优缺点 缺点:
Base64会增加字节数 Base64编码不是加密算法 优点:
Base64能简单隐藏内容 Base64算法简单可逆，不会消耗太多CPU，不影响效率 Base64能将所有数据转化为可打印数据 减少网络传输出现的编解码错误 ​
Base64的使用场景 网上留言自己的联系方式等私密信息，可以使用Base64加密一下，这样就不会直接泄露自己的信息，只有真正需要的人才会拿去解密，可以过滤一部分人 包含一些特殊字符的字符串等可以先用Base64编码一下防止被转义 http请求，在解析参数时是根据?</description></item><item><title>DNS协议</title><link>/2021/02/26/dns%E5%8D%8F%E8%AE%AE/</link><pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/26/dns%E5%8D%8F%E8%AE%AE/</guid><description>DNS作用 解析域名为IP (网络上只能通过IP通讯) 负载均衡 (一个域名绑定多个IP,采用轮询方式访问多个IP) 灵活配置IP (当要更换IP时直接换IP,依旧不影响原来域名的访问) ​
DNS记录类型 下面列出常见的记录类型
类型 解释 A IP地址记录Address 记录域名对应的IP AAAA IPV6的地址记录 NS DNS服务器记录（Name Server），记录上一级DNS服务器地址，该记录只能设置为域名，不能设置为IP地址 CNAME 规范名称记录（Canonical Name），返回另一个域名，即当前查询的域名是另一个域名的跳转 SRV 用于服务发现和负载均衡 ​
DNS查询过程 ​
本地接受到DNS查询返回的报文之后就会调用操作系统的DNS报文解析程序glibc/musl来解析报文获取IP地址，其配置文件为/etc/resolv.conf
本地还有/etc/hosts文件也可以记录IP和域名的映射关系，查询DNS服务器之前会先查询这个文件以及本地DNS缓存
​
dig命令 该命令是dns查询工具，类似的工具还有nslookup
dig cname www.baidu.com #查询www.baidu.com的CNAME跳转到那个URL dig ns baidu.com #查询哪个DNS服务器记录了这个域名解析地址 dig baidu.com #查询baidu.com的IP地址(A记录) dig +shore baidu.com #返回简短信息 dig +trace +additional baidu.</description></item><item><title>Linux常用命令总结</title><link>/2021/02/23/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/23/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/</guid><description>持续跟新&amp;hellip;..
进程相关 进程的信息都在/proc下
ps ps 显示系统进程
ps -ef ps -aux ps -ef | grep sshd jobs fg bg &amp;amp; nohub &amp;amp; jobs fg bg nohub
./exe &amp;amp; #后台运行 ./exe &amp;gt; log.txt 2&amp;gt;&amp;amp;1 &amp;amp; #0:标准输入 1:标准输出 2:标准错误 2&amp;gt;&amp;amp;1是将标准出错重定向到标准输出 最终结果就是`标准输出`和`错误`都被重定向到`log.txt`中 etcd &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp; #后台运行 同时输出日志重定向到垃圾桶 nohup etcd &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp; #以守护进程方式运行 不会随着终端退出而退出 jobs #查看后台运行中的进程 #ctrl+z暂停任务 ctrl+c终止任务 fg 1 #将后台任务放到前台执行 bg 1 #将一个暂停的任务放在后台执行 kill kill killall
kill -9 1111 #强制终止 killall 1111 #杀死进程 以及所有子进程 pstree pstree 显示进程树</description></item><item><title>vim使用教程</title><link>/2021/02/21/vim%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</link><pubDate>Sun, 21 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/21/vim%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</guid><description>光标移动(命令模式)
n+空格 #在当前行中移动n个字符 n+Enter #移动到距离当前行后n行 H/M/L #移动到屏幕第一行/中间行/最后一行 gg/G/nG #移动到当前文件第一行/最后一行/第n行 w/nw #向前 移动1个单词/移动n个单词 b/nb #向后 移动1个单词/移动n个单词 文本编辑删除复制粘贴(命令模式)
a/A/i #在 光标后/行末/光标前 插入文本 o/O(字母O) #在光标下/上方新开一行 x/X #命令模式下删除光标后/前的单个字符 r/R #替换字符/复写模式,连续替换 d0/d$ #删除到 行首/行尾 dgg/dG #删除到 文件头/文件尾 dd/ndd #删除该行/删除该行下的n行 yy/nyy #复制该行/n行 p/P #当前行下/上面粘贴 u/ctrl+r #撤销上次操作/撤销反悔,重做上次撤销 文档检索
/search_text #在文档后面的部分搜索 ?search_text #在文档前面的部分搜索 n/N #往前/后移动检索到的关键字 :noh #取消检索的高亮 :%s/abc/aaa #检索第一个 “abc” 字符串并将其替换成“aaa” :%s/abc/aaa/g #检索并将所有的“abc”,替换为“aaa” :%s/original/replacement/gc #替换前先询问 可视模式
v #逐字可视模式 V #逐行可视模式 保存文件
:w new_file #另存为 不会退出 ZZ # :wq ZQ # :q!</description></item><item><title>MySql事务</title><link>/2021/02/19/mysql%E4%BA%8B%E5%8A%A1/</link><pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/19/mysql%E4%BA%8B%E5%8A%A1/</guid><description>更新中&amp;hellip;
事务四大特性ACID 原子性 Atomicity
事务是数据库的逻辑工作单位，不可分割，事务中包含的各操作要么都做，要么都不做
一致性 Consistency
同一个事务中所有操作要么全部成功，要么全部失败
隔离性 Isolation
每个事务都是隔离的，互相不影响，一共有4个隔离级别
持久性 Durability
事务一旦提交，它对数据库中的数据的改变就应该是永久性的，不能回滚
​
四大隔离级别 1、读未提交 Read Uncommitted
一个事务还没提交时，它做的变更对他事务可见
2、读已提交 Read Committed Oracle默认的隔离级别
一个事务只有提交时候它做的变化才对其他事务可见，该级别会造成 在事务中两次读取数据不一致的情况
3、可重复读 Repeatable Read MySql、Innodb默认的隔离级别
一个事务开始之后，其所看见的数据就是事务开始时候的数据，相当于给数据在事务开始时拍一个快照，在事务执行过程中看见的都是这个快照，即使是其他事务做了变更提交了对此事务也不可见，解决了不可重复读、幻读问题
4、串行化 事务必须串行化执行，一个事务只有等另外一个事务结束之后才可以开始，效率最低不支持并发，但是解决了事务隔离性的所有问题
​
事务并发读写问题 1、脏读 事务读取到了其他事务还没提交的修改
A事务执行过程中，B事务做出的变化还没提交修改就被A事务读取到了，但是B事务的修改发生了回滚，那么A事务就读取到了脏数据
时间线 存款事务 取款事务 1 开始事务 2 开始事务 3 查询余额500 4 取款400，余额更改为500-400=100 5 查询余额100（脏读） 6 取款操作发生错误，事务失败，执行回滚操作 rollback （使用commit或者rollback后，事务就结束了） 7 存入500，更改余额为500+100=600 8 提交事务 9 账户出错，按照正确的逻辑此时余额应该为 500+500=1000，而此时余额为600 2、不可重复读 事务读取到了其他事务已经提交的修改，导致同一个事务两次查询结果不一样</description></item><item><title>MySql约束</title><link>/2021/02/19/mysql%E7%BA%A6%E6%9D%9F/</link><pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/19/mysql%E7%BA%A6%E6%9D%9F/</guid><description>约束分类 约束就是给字段设置一定的规则，约束这个字段 主要有如下几类约束
主键约束 外键约束 非空约束 唯一约束 默认值约束 检查约束 ​
主键约束 主键约束是非空的，最好使用 AUTO_INCREMENT来自动增加防止重复，并且能用int就不要用 bigint ，因为这和索引有关系，主键数据越小越好 如果一张表没有设置主键，那么Mysql就会拿一个非空约束字段当做主键，如果都没有则会自己生成一个RowID的列作主键
CREATE TABLE tb( id int PRIMARY KEY AUTO_INCREMENT ) CREATE TABLE tb( id int AUTO_INCREMENT, name varchar(20), PRIMARY KEY pk(id) ) #添加主键约束 ALTER TABLE 表名 ADD CONSTRAINT 约束名 PRIMARY KEY(列名); #删除主键约束 ALTER TABLE 表名 DROP PRIMARY KEY 约束名; ​
外键约束 外键是指引用另一个表中的一列或多列，被引用的列应该具有主键约束或唯一约束
外键约束可以设置联级:
联级删除: 外键表中被引用的记录删除之后则连同所有拥有这个外键的记录都删除 联级更新: 外键表中被引用的记录更新之后则连同所有拥有这个外键的记录都更新 如果不设置则不允许删除还被引用的记录
CREATE TABLE IF NOT EXISTS category ( id INT PRIMARY KEY AUTO_INCREMENT, title VARCHAR(50) NOT NULL, UNIQUE uq_title (title) ); CREATE TABLE article ( id INT AUTO_INCREMENT, title VARCHAR(100) NOT NULL, created_at DATETIME NOT NULL, updated_at DATETIME NOT NULL, deleted_at DATETIME DEFAULT NULL, author VARCHAR(20) NOT NULL, status ENUM (&amp;#39;published&amp;#39;,&amp;#39;auditing&amp;#39;,&amp;#39;draft&amp;#39;,&amp;#39;deleted&amp;#39;) NOT NULL, cid INT NOT NULL, PRIMARY KEY pk_id (id), #联级删除 category记录删除了 所有引用该记录的article记录也一并删除 #如果没设置此联级策略则不允许删除还被引用的category记录 FOREIGN KEY fk_cid (cid) REFERENCES category (id) ON DELETE CASCADE, UNIQUE uq_title (title) COMMENT &amp;#39;会自动创建唯一索引&amp;#39; ); #添加外键 ALTER TABLE 表名 ADD CONSTRAINT 约束名 FOREIGN KEY (外键字段名) REFERENCES 外键表名(列名); #删除外键 ALTER TABLE 表名 DROP FOREIGN KEY 外键名; ​</description></item><item><title>快速排序</title><link>/2021/02/18/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</link><pubDate>Thu, 18 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/18/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</guid><description>快排思想 通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列
就是需要确定一个 pivot支点，然后将小于pivot的放到左边，大于pivot的放到右边，此时pivot就已经排好序了，然后再分别对两别进行递归排序
所以快排主要需要解决下面两个问题:
pivot的选择 如何把元素放到左边和右边，也就是如何确定pivot放置的位置 ​
复杂度分析 最优时间复杂度: O(nlogn) 最优空间复杂度: O(logn)
pivot每次都平分，计算时间复杂度过程和 归并排序一样计算
空间复杂度主要是递归栈的空间，看递归树的高度，比如50,10,90,30, 70,40,80,60,20 这个序列，递归深度如下，这是一颗平衡二叉树，高度是数组个数的 logn倍
最差时间复杂度: O(n^2) 最差空间复杂度: O(n)
pivot每次取最大最小值，退化为 冒泡排序 冒泡排序的时间复杂度：
T[n] = n * (n-1) = n^2 + n = O(n^2) 空间复杂度就是树的高度，单边树的高度就是元素的个数，所以空间复杂度为O(n)
​
pivot支点的选择 支点只要能将两边平均分就是最好的支点，主要有如下几个选法:
选第一个/最后一个 选中间一个 随机选一个 三数取中法: 选 开头、结尾、中间 的数中大小排中间的数 为了便于算法实现，需要取中间某个Pivot时，可以通过交换元素，转换成取第一个（或最后一个）来方便实现
//随机 pivot := rand.Intn(end+1-start) + start //三数取中 func getMiddle(arr []int, start, end int) int { mid := start + (end-start)/2 if arr[start] &amp;gt; arr[mid] { mid, start = start, mid } if arr[mid] &amp;gt; arr[end] { mid, end = end, mid } return mid } //取数组位置中间的数 pivot:=len(arr)/2 ​</description></item><item><title>十大排序算法</title><link>/2021/02/17/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link><pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/17/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid><description>更新中&amp;hellip;..
冒泡排序 稳定排序 最好时间复杂度: O(n) 基本有序状态，进行1次冒泡 最坏时间复杂度: O(n^2) 逆序状态，需要进行n次冒泡 平均时间复杂度: O(n^2) 空间复杂度: O(1) func BubbleSort(arr []int) { flag := true for i := 0; i &amp;lt; len(arr); i++ { for j := 0; j &amp;lt; len(arr)-i-1; j++ { if arr[j] &amp;gt; arr[j+1] { flag = false arr[j], arr[j+1] = arr[j+1], arr[j] } } if flag { break } } } ​
选择排序 不稳定排序 比如 5 8 5 2 9 两个相同的5会发生位置交换 最好时间复杂度: O(n^2) 最坏时间复杂度: O(n^2) 平均时间复杂度: O(n^2) 空间复杂度: O(1) 每次选择剩余排序区间中最小(大)的元素放入排序好的区间的最后一个位置中</description></item><item><title>装饰者模式</title><link>/2021/02/17/%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/</link><pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/17/%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F/</guid><description>跟新中&amp;hellip;.
为什么要使用装饰者模式 Decorator Pattern 装饰者模式，动态的透明的增加一些另外的功能而不需要改变原来的代码，拥有更好的灵活性和可扩展性
从名字中也可以看出，装饰者模式就是给一个对象加上一层装饰，穿上一件衣服，装饰者在我解除的技术里面在函数式语言中的应用比较广泛，就是在装饰函数里传入一个目标函数，装饰函数同样返回一个目标函数，但是返回的函数是进过装饰了的
使用装饰者模式可以不改变原来的代码而增加一些额外的功能，讲增加的功能和原来的功能代码解耦了，代码可移植性更强了，原来代码还可以用在其他地方其他项目或则增加另外的装饰来实现更多的功能
​
在Java中的应用和实现 实现案例 下面先来看一个 Shape 自己实现的案例:
Shape顶层接口:
public interface Shape { String display(); } Circle和Rectangle具体实现
public class Circle implements Shape{ private String name; public Circle(){ this.name = &amp;#34;Circle&amp;#34;; } public String display() { return this.name; } } ------------------------------------------------ public class Rectangle implements Shape { private String name; public Rectangle() { this.name = &amp;#34;Rectangle&amp;#34;; } public String display() { return this.name; } } 所有装饰器的顶层抽象对象，这里通过构造方法和set方法可以传入被装饰对象</description></item><item><title>MySql字符集</title><link>/2021/02/16/mysql%E5%AD%97%E7%AC%A6%E9%9B%86/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/16/mysql%E5%AD%97%E7%AC%A6%E9%9B%86/</guid><description>MySql字符集 MySql支持很多字符集，可以使用如下命令查看MySql支持的字符集:
SHOW CHARACTER SET SHOW CHARSET SHOW CHARACTER SET LIKE &amp;#39;utf8%&amp;#39; 其中Default collation 表示默认的 比较规则 MAXlen表示最大长度
下面是几个重要的字符集的最大长度:
字符集名称 Maxlen ascii 1 gbk 2 utf8 3 utf8mb4 4 ​
utf8和utf8mb4 utf8是utf8mb3的别名，只支持最大长度是3byte，属于 阉割版 的UTF8字符集
utf8mb4 是完整的UTF8字符集，最大支持4byte，包含所有UTF8字符集
所以如果文本里面有特殊符号或则表情符号，比如存博客等就需要修改表的字符集为utf8mb4
​
字符集比较规则 字符集比较规则用于字符集比较，比如a、A两个比较，是按照二进制大小来比较还是忽略大小写进行比较
可以使用如下命令显示支持的比较规则
SHOW COLLATION #显示所有比较规则 SHOW COLLATION LIKE &amp;#39;%utf8%&amp;#39; utf8默认的比较规则就是utf8_general_ci
utf8mb4默认是utf8mb4_0900_ai_ci
以ci结尾的比较规则都是忽略大小写的
​
字符集和比较规则应用范围 分别有3个应用范围:</description></item><item><title>MySql配置文件</title><link>/2021/02/16/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E7%B3%BB%E7%BB%9F%E5%8F%98%E9%87%8F/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/16/mysql%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E7%B3%BB%E7%BB%9F%E5%8F%98%E9%87%8F/</guid><description>更新中&amp;hellip;&amp;hellip;
配置文件 MySql配置文件的作用就是给mysqld服务器进程提供启动参数，设置一些变量，也可以通过命令行方式设置参数，但是这样太麻烦了而且不是永久的，所以一般都将这些参数写在配置文件中，mysqld进程启动的时候会按照如下方式去寻找配置文件:
$ mysql --help | grep my.cnf /etc/my.cnf /etc/mysql/my.cnf ~/.my.cnf /etc/my.cnf /etc/mysql/my.cnf $MYSQL_HOME/my.cnf ~/.my.cnf 可以指定配置文件路径:
$ mysqld --defaults-file=/etc/my.cnf #只读取这一个配置文件 $ mysqld --defaults-extra-file=/my.cnf #添加额外的配置文件路径加入默认的搜索路径，也就是说其他路径包括这个也会被搜索到 另外注意：命令行参数优先级高于配置文件，搜索路径前面的配置高于后面的，并且有些命令行参数是只属于命令行的，不属于配置文件，配置文件都可以用命令行替代
配置文件分为如下几组:
[server] ... [mysqld] ... [mysqld_safe] [client] [mysql] [mysqladmin] ​
[mysqld]配置 TODO
[server]配置 TODO
[client]配置 TODO
[mysql]配置 TODO
[mysqld_safe]配置 TODO
[mysqladmin]配置 TODO
系统变量 1、系统变量的查看 系统变量一般通过SHOW VARIABLES LIKE xxx来查看，下面展示常用的系统变量
SHOW VARIABLES LIKE &amp;#39;default_storage_engine&amp;#39; #默认使用的搜索引擎 在配置文件的变量可以用-线链接，而这些变量保存在数据库中则是以_链接
2、系统变量作用范围 系统变量有作用的范围之分，有下面几个范围:
GLOBAL 全局所有用户 SESSION 特指当前一个用户，一般客户端可以通过连接字符串添加参数来设置这些变量比如设置 时区、字符集 等，这属于单个连接的客户端 查询的时候可以指定范围，不指定则默认是SESSION</description></item><item><title>SQL总结</title><link>/2021/02/16/sql%E6%80%BB%E7%BB%93/</link><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/16/sql%E6%80%BB%E7%BB%93/</guid><description>更新中&amp;hellip;&amp;hellip;
表操作 CREATE TABLE test ( ) ENGINE = InnoDB #设置表的存储引擎 DEFAULT CHARSET = utf8 #设置表的字符集、 COLLATE=utf8_bin #设置字符集比较规则 DROP TABLE IF EXISTS category,article,tag,article_tag; #删除表 CREATE TABLE IF NOT EXISTS category ( id INT PRIMARY KEY AUTO_INCREMENT, title VARCHAR(50) NOT NULL, UNIQUE uq_title (title) ) ENGINE = InnoDB CHARACTER SET = utf8; CREATE TABLE article ( id INT AUTO_INCREMENT, title VARCHAR(100) NOT NULL, created_at DATETIME NOT NULL, updated_at DATETIME NOT NULL, deleted_at DATETIME DEFAULT NULL, author VARCHAR(20) NOT NULL, status ENUM (&amp;#39;published&amp;#39;,&amp;#39;auditing&amp;#39;,&amp;#39;draft&amp;#39;,&amp;#39;deleted&amp;#39;) NOT NULL, cid INT NOT NULL, PRIMARY KEY pk_id (id), FOREIGN KEY fk_cid (cid) REFERENCES category (id) ON DELETE CASCADE, UNIQUE uq_title (title) COMMENT &amp;#39;会自动创建唯一索引&amp;#39; ) ENGINE = InnoDB CHARACTER SET = utf8mb4; CREATE TABLE tag ( id INT PRIMARY KEY AUTO_INCREMENT, title varchar(20) NOT NULL, UNIQUE uq_title (title) ); CREATE TABLE article_tag ( id INT PRIMARY KEY AUTO_INCREMENT, tid INT NOT NULL, aid INT NOT NULL, FOREIGN KEY fk_tid (tid) REFERENCES tag (id), FOREIGN KEY fk_aid (aid) REFERENCES article (id), UNIQUE uq_tid_aid (tid, aid) ); #展示建表语句 SHOW CREATE TABLE test #展示test表的建表语句 DESC test #展示字段信息 #修改表 ALTER TABLE test ENGINE=MyISAM #修改存储引擎 ​</description></item><item><title>Go优雅的处理error</title><link>/2021/02/15/go%E4%BC%98%E9%9B%85%E7%9A%84%E5%A4%84%E7%90%86error/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/15/go%E4%BC%98%E9%9B%85%E7%9A%84%E5%A4%84%E7%90%86error/</guid><description>大道至简的error go的错误处理就只有一个errors包和一个error接口，这个接口只包哈一个Error方法，该方法返回一个string，这个包的代码很少，只有两个文件：
errors.go wrap.go go的error也就是通过创建一个 错误提示的字符串 的方式，然后通过返回值来返回这个错误，基本每个函数的返回值都标配一个error对象以及函数本身的返回值：
函数本身返回值 error对象 最简单的创建错误的方式就是通过errors.New来创建：
func f() error{ return errors.New(&amp;#34;error&amp;#34;) } 下面来看下errors.go的源码，不过10行左右
func New(text string) error { return &amp;amp;errorString{text} } // errorString is a trivial implementation of error. //实现了error接口 type errorString struct { s string } //获取错误字符串的方法 func (e *errorString) Error() string { return e.s } 综上来看，我们只需要实现error接口即可自定义错误（很多包都有自定义错误，可以参考他们的实现）：
type ZeroDivisionError struct { msg string code int } func (e ZeroDivisionError) Error() string { return fmt.</description></item><item><title>Go测试总结</title><link>/2021/02/15/go%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/15/go%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/</guid><description>go中的测试 go的测试是是以 xxx_test.go结尾的，前面的名字和对应的测试文件名字一样，后面加个test，运行测试命令之后就会扫描所有测试文件进行测试
xxx_test.go测试文件中主要有如下几个部分:
类型 格式 作用 单元测试 函数名前缀为Test 测试程序的一些逻辑行为是否正确 基准测试 函数名前缀为Benchmark 测试函数的性能 示例代码 函数名前缀为Example 为文档提供示例文档 ​
单元测试 $ go test -v #扫描当前包下所有的测试文件进行测试 并且输出详细信息 $ go test -v -test.run A #测试包含 A 字母的单元测试函数 [只能运行单元测试] 单元测试函数必须以 t *testing为参数，t主要用于报告测试结果是否正确以及日志记录，主要有如下几个方法:
Error Log 最常用
//标记失败 func (c *T) Fail() //标记失败，但继续执行当前测试函数 func (c *T) FailNow() //标记失败，停止下面的执行 func (c *T) Failed() bool //日志信息 go test如果测试成功的话，不会打印这部分内容，加上 -v则测试成功也会显示 func (c *T) Log(args .</description></item><item><title>Go随机数用法</title><link>/2021/02/15/go%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%A8%E6%B3%95/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/15/go%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%A8%E6%B3%95/</guid><description>基本用法 go随机数在math/rand包下，go的随机数需要先给他一个Seed，Seed如果一样的话或则不设置的话每次生成的都是 伪随机数 ，多次执行生成的都是一样的随机数序列，所以必须设定Seed而且还是以 时间戳 的方式来设置，如下生成 [0,10)之间的随机整数：
rand.Seed(time.Now().UnixNano()) r:=rand.Intn(10) //[0,10) 返回int类型 r=rand.Int63n(10) //返回int64 .... 如果要生成指定范围的随机整数，如下生成[min,max)之间的随机整数：
rand.Seed(time.Now().UnixNano()) max:=10;min:=-10 rand.Intn(max-min)+min) //[-10,10) ​
随机负载均衡实现 我们实战一下，实现一个 随机数负载均衡
type RandomBalance struct { curIndex int hosts []string } func (r *RandomBalance) Add(host string) { r.hosts = append(r.hosts, host) } func (r *RandomBalance) Next() (string, error) { if len(r.hosts) == 0 { return &amp;#34;&amp;#34;, errors.New(&amp;#34;no host&amp;#34;) } rand.Seed(time.Now().UnixNano()) r.curIndex = rand.Intn(len(r.hosts)) return r.hosts[r.curIndex], nil } func main() { rb := RandomBalance{} for i := 1; i &amp;lt; 10; i++ { rb.</description></item><item><title>vmware配置一台ubuntu-server</title><link>/2021/02/15/vmware%E9%85%8D%E7%BD%AE%E4%B8%80%E5%8F%B0ubuntu-server/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/15/vmware%E9%85%8D%E7%BD%AE%E4%B8%80%E5%8F%B0ubuntu-server/</guid><description>配置步骤 ubuntu阿里镜像站：http://mirrors.aliyun.com/ubuntu-releases/
ubuntu配置阿里云软件源：https://developer.aliyun.com/mirror/ubuntu?spm=a2c6h.13651102.0.0.3e221b11Zy3CPT
更新软件源头
$ apt update 重置root密码：
$ su passwd 设置允许以root身份ssh登入，设置PermitRootLogin yes：
$ vim /etc/ssh/sshd_config #设置PermitRootLogin yes $ service ssh restart #重启ssh服务 静态IP和网络相关的设置
$ vim /etc/netplan/00-installer-config.yaml ---------------------------------------------- # This is the network config written by &amp;#39;subiquity&amp;#39; network: ethernets: ens33: #网卡名字 addresses: - 192.168.1.10/24 #IP dhcp4: false #关闭DHCP gateway4: 192.168.1.1 #设置网关 4表示ipv4 nameservers: #设置DNS addresses: - 192.168.1.1 version: 2 ------------------------------------------------- $ netplan apply #应用配置 发送宿主机公钥给vmware虚拟机，允许宿主机免密登入虚拟机
ssh-copy-id -i ~/.ssh/id_rsa.pub root@u ​</description></item><item><title>在github上搭建个人网站</title><link>/2021/02/15/%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</link><pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/15/%E5%9C%A8github%E4%B8%8A%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</guid><description>使用github免费图床 github可以开一个仓库专门用于存放图片，然后图片就会产生一个链接，这样我们就可以使用这个图片了，这就是 github图床，并且不要钱呦！
我们这里使用的是： picgo+github 来实现命令行图片上传
1、安装picgo：https://github.com/PicGo/PicGo-Core
$ npm install picgo -g $ vim $HOME/.picgo/config.json #配置文件路径 2、配置config.json
{ picBed: { uploader: github, current: github, github: { repo: biningo/cdn, #github仓库地址 &amp;lt;username&amp;gt;/&amp;lt;repo&amp;gt; branch: master, #分支 token: dsadsadsada3231321321321, #访问token 需要github后台生成 path: img/, #仓库下的路径 } }, picgoPlugins: {} } 3、pic上传命令：
picgo u ~$PATH/aaaa.png #上传之后就会返回URL链接地址 ​
hugo静态博客 我采用的是 hugo+github page+github action 来实现自动化部署，我只需要在本地写完博客执行一下push发布上去即可实现部署，非常方便，具体可以参照我的仓库的action：https://github.com/biningo/biningo.github.io
因为push前需要先和github仓库rebase，命令比较多所以我写成一个脚本每次执行这个脚本即可，博客发布脚本：
#因为 hugo生成页面的actions会生成public页面，所以和本地不一样了，需要先rebase，然后再push才能push成功，每次push就会触发action生成页面 git fetch origin master git rebase origin/master git push</description></item><item><title>Go数组与slice</title><link>/2021/02/14/go%E6%95%B0%E7%BB%84%E4%B8%8Eslice/</link><pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/14/go%E6%95%B0%E7%BB%84%E4%B8%8Eslice/</guid><description>数组 值拷贝 a:=[...]int{1,2,3} a2:=a log.Println(a,a[0]) log.Println(a2,a2[0]) //也可以通过下标访问 a2[0] = 10 log.Println(a) //a[0]=1 指针传递 //通过指针访问数组 a:=[...]int{1,2,3} a2:=&amp;amp;a log.Println(a,a[0]) log.Println(a2,a2[0]) a2[0] = 10 log.Println(a) //a[0]=10 ​
切片与数组 数组 array := [3]int{1,2,3} array := [...]int{1,2,3} 切片 array := []int{1,2,3} //len=3 cap=3 array := make([]int,2) //len=2 cap=2 arr := [5]int{1,2,3,4,5} //底层数组可见 会修改原数组 相当于原数组1-3的子数组指针 array :=arr[1:3] //cap=5-1=4 len=3-1=2 array[0]=99 //arr[1]=99 被修改了 log.Println(arr) //[1 99 3 4 5] ​</description></item><item><title>优雅的写Go</title><link>/2021/02/14/%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99go/</link><pubDate>Sun, 14 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/14/%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99go/</guid><description>跟新中&amp;hellip;..
静态代码检查工具 1、goimports goimports 是 Go 语言官方提供的工具，主要有如下几个作用：
自动格式化 Go 语言代码 对所有引入的包进行管理，自动增删依赖的包引用、将依赖包按字母序排序并分类 goimports 就是等于 gofmt 加上依赖包管理
用法和go fmt差不多，这里不再赘述，另外，在CI/CD中不应该加入这些检查，因为这是开发者的本职工作，应该由开发者来规范代码
goimport -w . #格式化 并且修改原文件 2、go vet和golint 代码语法检查、代码风格检查，官方提供，没什么用
3、golangci-lint 强大的go开源静态代码分析，用于CI防止不规范代码合并，主要有几个用途：
代码规范 代码风格统一 语法错误、冗余语法等 golangci-lint run ./... golangci-lint run dir1 dir2/... dir3/file1.go 具体见官网：https://golangci-lint.run/usage/performance
​
go代码报告评分平台 https://goreportcard.com
​
参考 https://www.jianshu.com/p/ca38dcdaf6bb
https://supereagle.github.io/2019/10/03/golang-lint/</description></item><item><title>GoModules包管理</title><link>/2021/02/12/gomodules%E5%8C%85%E7%AE%A1%E7%90%86/</link><pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/12/gomodules%E5%8C%85%E7%AE%A1%E7%90%86/</guid><description>Go Modules环境变量 要开启Go Modules管理，需要设置一个环境变量：
GO111MODULE=&amp;#34;on&amp;#34; #默认是开启的 ​
go.mod文件 //1、每个模块都有一个名字 通常通过 go mod init 指定 module github.com/biningo/go-play //2、指定go版本 go 1.15 //3、指定依赖的库地址 &amp;lt;url&amp;gt; &amp;lt;version&amp;gt; 形式 require ( github.com/gin-gonic/gin v1.6.3 ) //4、replace 替换 require 中声明的依赖，使用另外的依赖及其版本号 不经常使用 replace github.com/gin-gonic/gin v1.6.3 =&amp;gt; github.com/gin-gonic/gin v1.6.3 //5、exclude 排除某些版本 exclude ithub.com/gin-gonic/gin v1.5.0 模块名字主要有如下几个作用：
作为模块的标识
作为模块的 import path
当其他项目引用这个模块下的 package 时都会以该 import path 作为共同的前缀，自己的项目引用自己项目的包也必须是这个前缀，代表了这个项目，然后前缀下就可以根据路径来引入包了
开启mod模式之后，所有的go get命令拉取的包都会放到$GOPATH/pkg/mod路径下，如果是在项目下面执行go get则也会同时将响应的依赖信息记录到go.mod文件
go mod的replace命令主要用来替换原来的包，使用场景有如下几个
单纯的替换包（用处不大）
替换无法下载的包</description></item><item><title>Go命令行和相关环境变量</title><link>/2021/02/12/go%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%92%8C%E7%9B%B8%E5%85%B3%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</link><pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/12/go%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%92%8C%E7%9B%B8%E5%85%B3%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</guid><description>go命令 go build 将代码编译为相关平台的可执行文件，只需要编译带有main的入口文件即可
go build #会寻找当前目录下main入口文件然后进行编译 会编译所有 go build -o main #指定生成可执行文件的名字 go build mymain.go #也可以编译指定的go文件 然后就会连一起依赖的代码都编译为一个二进制 go env 用于管理go的环境变量相关信息，go相关环境变量也可在.bashrc等文件里面设置，优先级高
go env #打印所有go的环境变量 go env GOPROXY #打印某个环境变量的值 go env -json #json格式输出 go env -w GOPROXY=https://goproxy.cn,direct #修改某个值 这里设置了中国代理，direct表示如果代理没有则直接走go官网，可以设置多个代理网站，用逗号分割 go fmt和gofmt go fmt是对gofmt的封装，直接使用gofmt即可，格式化如果不加-w是不会改变源代码的，所以最常用的就是：
gofmt -w ./ #格式化当前项目，并且会修改原文件而不是输出到控制台 还有一些其他命令，看看就行
gofmt test.go #格式化单个文件 gofmt ./viper/ #格式化整个目录文件 gofmt -l ./viper/ #列出哪些文件格式化前后会出现不同(只是列出 不进行格式化) gofmt -w ./viper/ #执行格式化 并且写入源代码 go get 拉取依赖并且编译安装代码的命令
go list 列出go.mod依赖了哪些库
go mod mod管理的相关命令</description></item><item><title>Go文档管理和规范</title><link>/2021/02/12/go%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86%E5%92%8C%E8%A7%84%E8%8C%83/</link><pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/12/go%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86%E5%92%8C%E8%A7%84%E8%8C%83/</guid><description>godoc godoc -http=:8000 #开启本地文档服务器 ​
Go文档注释规范 因为go的注释即文档，文档都是根据注释生成的，所以文档的详细性和合理性都必须要求注释必须符合一定的规范，这样才可以生成漂亮详细的文档
文档主要有如下几部分组成:
组成 作用 Overview 包含包的 import 语句和概要说明 Index 包含包中可见性为 public 的常量、类型、方法、函数的总目录及说明 Constants 项目所有的导出常量 Variables 显示所有全局变量 Functions 显示所有函数 Types 显示所有type Overview 用于整个项目的简单描述，是项目中一级目录下所有包头开始的注释内容的合并，一般将这些信息单独写在doc.go文件中，比如gin的doc.go下的内容为：
/* Package gin implements a HTTP web framework called gin. See https://gin-gonic.com/ for more information about gin. */ package gin // import &amp;#34;github.</description></item><item><title>Go的defer</title><link>/2021/02/12/go%E7%9A%84defer/</link><pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/12/go%E7%9A%84defer/</guid><description>1、defer执行时机 for i:=1;i&amp;lt;10;i++{ defer log.Println(i) } 上面那段简单的代码基本就可以说明多个defer时的执行顺序了
当代码中出现defer时，会将defer要执行的函数压人栈，然后等函数执行完毕再执行defer栈中的内容
go1.13以前用堆分配，加入到链表中，再尾递归调用，go1.13在栈上分配，如果defer过多则还是会在堆上用链表来管理
go1.14则做了进一步优化，defer的开销基本很小了
​
2、defer的估值时刻 defer分为进入阶段和退出阶段 ，defer延迟的只是函数体的执行，并不延迟函数的初始化
//defer初始化值和位置有关 推迟执行的仅仅是函数体 j:=10 defer func(jj int) { log.Printf(&amp;#34;j=%d jj=%d\n&amp;#34;,j,jj) //j=99 j=10 }(j) j=99 ​
3、防止defer内存泄漏 下面这段代码会严重占用内存栈，造成短暂内存泄漏，有大量的文件句柄没有被释放
//内存泄漏 func writeManyFiles(files []os.File) error { for _, file := range files { defer file.Close() } return nil } 用函数包裹之后每循环一个就关闭一个文件句柄
//防止内存泄漏 func writeManyFiles(files []os.File) error { for _, file := range files { if err:= func() error { f, err := os.</description></item><item><title>git总结</title><link>/2021/02/08/git%E6%80%BB%E7%BB%93/</link><pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/08/git%E6%80%BB%E7%BB%93/</guid><description>什么是git 版本控制工具 分布式 git在中心仓库保存所有的版本信息
同时也会在所有用户的本地也会保存所有版本
这样就做到了 分布式，git在中心仓库挂了之后依然可以在本地提交版本，等中心仓库恢复之后再一起push上去
使用git分布式版本管理工具的最重要的就是要解决多人协作的 版本冲突 问题
在使用git的时候，时刻需要保持一个理念：
你的每次commit都是一个版本
提交版本的时候就会标注上 user.name、user.email 指示出这是谁提交的版本
只要是一个版本，那么在以后就都可以回滚到这个版本中
​
三大区域 工作区： 直接写代码，修改文件的地方
暂存区： 将工作区的当前映象暂存起来以准备提交到版本库中，简单来说就是可以在提交最终的版本之前还可以继续修改反悔等，举个简单的例子：
我删除了a，并且add到暂存区 现在我添加了b，添加完之后就觉得还是a好，于是反悔了，将上次暂存区中的文件又覆盖了工作区，也就是说现在又回到了a 最终我觉得就a了，不再修改了，于是就add+commit将最终的版本提交了 版本库： 存放最终的版本
远程仓库： 供多人协作用，本地仓库的版本最终需要push到远程仓库，并且在push之前需要和远程仓库保持 同步 这要所有人才可以看到版本信息
​
三大区域变更 暂存区-&amp;gt;工作区
#1、将暂存区文件覆盖工作区 git restore &amp;lt;file&amp;gt; ... #2、取消暂存 git restore --staged &amp;lt;file&amp;gt;... #3、直接删除暂存区和本地文件 等同于:手动删除文件 + git add file git rm a #4、直接同时修改暂存区和本地文件名字 等同于:mv a b + git rm a + git add b git mv a b 版本库-&amp;gt;工作区</description></item><item><title>打造自己的终端环境</title><link>/2021/02/04/%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84linux%E7%BB%88%E7%AB%AF%E7%8E%AF%E5%A2%83/</link><pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/04/%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84linux%E7%BB%88%E7%AB%AF%E7%8E%AF%E5%A2%83/</guid><description>配置zsh 安装zsh apt install zsh 安装oh-my-zsh #https://github.com/ohmyzsh/ohmyzsh sh -c &amp;#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&amp;#34; 运行上面的sh之后，就会在家目录下配置.zshrc文件，当然也可以手动clone仓库代码到，然后按照oh-my-zsh模板文件进行配置.zshrc
配置.zshrc 该文件的作用和.bashrc作用一样，为了不让之前.bashrc的命令失效，可以在.zshrc中source进来，下面展示主要配置
#配置终端主题，不然会很丑 主题路径在.oh-my-zsh/themes 可以修改主题的样式 ZSH_THEME=&amp;#34;robbyrussell&amp;#34; #配置zsh插件 有些系统自带的插件则直接配置即可 #有些外部插件则需要下载(clone)到 .oh-my-zsh/custom/plugins路径下 然后需要在下面写上名字即可 plugins=( git zsh-syntax-highlighting #shell命令高亮插件 colored-man-pages #系统自带 zsh-autosuggestions #命令提示插件 ) 可以为zsh也配置wakatime来统计你在终端上的时间
https://github.com/sobolevn/wakatime-zsh-plugin pip install wakatime waketime的python cli程序也需要安装，其地址如下:
https://github.com/wakatime/wakatime ​
配置tmux 安装tmux apt install tmux 修改配置文件 tmux的配置文件在~/.tmux.conf
个人觉得tmux默认的快捷键不符合自己，那么可以修改，下面展示我的配置文件
#设置快捷键前缀 set -g prefix C-a #修改快捷键前缀 我习惯与ctrl+a unbind C-b # 解绑默认的 ctrl+b 前缀快捷键 bind C-a send-prefix # 绑定Ctrl+a为新的指令前缀 #绑定方向键 bind -r k select-pane -U # 绑定k为↑ bind -r j select-pane -D # 绑定j为↓ bind -r h select-pane -L # 绑定h为← bind -r l select-pane -R # 绑定l为→ #切换切割pane按键 分割窗口要用到 unbind &amp;#39;&amp;#34;&amp;#39; #解绑默认的键 # 垂直方向新增面板，默认进入当前目录 bind ] splitw -v -c &amp;#39;#{pane_current_path}&amp;#39; unbind % # 水平方向新增面板，默认进入当前目录 bind [ splitw -h -c &amp;#39;#{pane_current_path}&amp;#39; tmux的基本命令这里分享一个链接，可以速查一些相关的命令: https://gist.</description></item><item><title>信息的编码和表示</title><link>/2021/02/01/%E4%BF%A1%E6%81%AF%E7%9A%84%E7%BC%96%E7%A0%81%E5%92%8C%E8%A1%A8%E7%A4%BA/</link><pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/02/01/%E4%BF%A1%E6%81%AF%E7%9A%84%E7%BC%96%E7%A0%81%E5%92%8C%E8%A1%A8%E7%A4%BA/</guid><description>跟新中&amp;hellip;..
二进制算术运算 二进制的 加减乘除 运算和十进制相似，只不过二进制到2就需要进位，而十进制到10才需要进位而已，其他进制也都类似。
CPU逻辑运算：&amp;amp; | ^(异或) ~(取反) （由相应的与非门等电路组合而成）
CPU算术运算： 加法、位移 （通过上面的逻辑运算实现）
二进制的加减乘除都是通过 加法、位移 组合来实现的，CPU里面实现二进制的算术运算由相应的部件来实现：
加法器（全加器） 实现加法 除法器、乘法器 实现乘除 1、二进制加减 二进制加法：01+01=10 第一位1+1=0然后需要进位并且需要链式进位，这和十进制一样，加法器基本原理就是：
异或（不带进位的加法1+1=0 0+0=0） 与 （计算进位,只有1|1==1才会产生进位）如果有进位还必须保存进位参与下一次运算 二进制里面的减法是通过加法来运算的，减去一个数其实就是加上这个数的负数，计算机为了表示负数，会出现很多问题，原码、反码、补码就是为了解决负数问题的（稍后讨论）
二进制加法规则：0+0=0 1+0=1 1+1=1
二进制减法规则：0-0=0 1-0=1 0-1=1(需要向前借位) 1-1=0
可以看到和十进制一样，只不过十进制有10种状态0-9而二进制只有0-1两种状态
弄清楚二进制运算只需要转变以前10进制运算观念即可
2、二进制乘除 二进制乘法比十进制还简单，运算规则和十进制一样，下面截取**《编码》**里的一张图片说明：
第一排1101叫被被乘数，第二排1011叫乘数
为了更直观感受，将每次乘下来的结果空白部分都补0：
00001101 00011010 00000000 01101000 -------- 10001111 CPU乘法器：有3个寄存器组成：
A：保存被乘数 B：保存乘数 C：保存结果 下面展示完整流程（假设在8位机器上）：
A：00001101 B：00001011 C：00000000
1*00001101=00001101=&amp;gt; A：00011010 B：00000101 C：00001101 1*00011010=00011010=&amp;gt; A：00110100 B：00000010 C：00001101 0*00110100=00000000=&amp;gt; A：01101000 B：00000001 C：01101000 1*01101000=01101000=&amp;gt; A：11010000 B：00000000C：10001111 所以最终结果就是 10001111</description></item><item><title>Python并发和GIL锁</title><link>/2021/01/31/python%E5%B9%B6%E5%8F%91%E5%92%8Cgil%E9%94%81/</link><pubDate>Sun, 31 Jan 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/01/31/python%E5%B9%B6%E5%8F%91%E5%92%8Cgil%E9%94%81/</guid><description>更新中&amp;hellip;&amp;hellip;
GIL全局解释器锁 在单核时代，Python为了解决多个线程并发访问数据造成数据不安全问题，在语言层面就实现了一种机制，就是给一个进程中的多个并发线程设置一把锁，只有抢到锁的线程才可以在CPU上执行，没有锁的线程只能等待。这样就可以控制在同一时刻内对数据的访问只有一个线程（其实这也无法保证线程安全）所以这把锁就叫做 GIL锁
也就是说Python的多线程并发在单核时代可以有效控制线程安全问题，但是到了多核时代，即使有多个核，同一时刻也只能有一个线程在执行（因为同一个进程内的多个线程中只有一把GIL锁）
比如现在有 a、b、c、d三个线程和1、2、3、4号CPU核，如果是其他语言，则在同一个时刻四个线程可以同时并发的跑在4个核上运行，但是Python因为有了一把GIL锁 现在a抢到锁了，那么b、c、d只能干巴巴的等待a主动释放锁才可以继续抢锁才有机会执行，即使有4个核也无法充分利用，所以语言层面上创建了4个线程但最终也相当于串行执行
def my_task(): i = 0 for _ in range(10000000): i = i + 1 @metric def f1(): for t in range(2): t = threading.Thread(target=my_task) t.start() t.join() @metric def f2(): arr = [] for t in range(2): t = threading.Thread(target=my_task) t.start() arr.append(t) for t in arr: t.join() ​
GIL锁真的安全吗？ GIL锁其实并非安全，线程在下面三种情况下回主动释放锁：
不间断执行字节码&amp;gt;1000 执行时间&amp;gt;15ms IO操作 现在有一个全局变量count=0，假设t1线程拿到count准备count+=1的时候，t1的连续执行时间恰好&amp;gt;15ms了或则执行的字节码&amp;gt;1000了，此时t1就会主动释放锁，被t2抢到了，t2执行count+=1此时的count==1，后来t1再次执行的时候count=0，count+=1，count==1，正确的结果应该是count=2
也就是说GIL锁并不能百分之百保证线程安全，只有在循环比较短，执行代码比较少的情况下才可以百分之百保证线程安全
count=0 def add_cpu(max_num): global count for i in range(max_num): count+=1 def f5(max_num): arr = [] for t in range(10): t = threading.</description></item><item><title>SSL-TSL-HTTPS和CA证书</title><link>/2021/01/14/ssl-tsl-https%E5%92%8Cca%E8%AF%81%E4%B9%A6/</link><pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/01/14/ssl-tsl-https%E5%92%8Cca%E8%AF%81%E4%B9%A6/</guid><description>对称加密 对称加密就是在两端通信的时候使用同一个密钥进行加密解密，
特点：
不够安全，密钥如何传的问题（由非对称加密解决） 加解密的CPU消耗低 相关算法：DES、AES
本质就是将 密钥+数据 进过一个公式或则运算获得密文，对方也用 密钥+密文 进过一个公式或运算能还原回数据，下面展示最简单的 XOR对称加密:
现在有密钥: 1111 待加密的密文: 1010
第一次XOR: 1010^1111=0101 第二次XOR: 0101^1111=1010 可以看到进过两次XOR运算又回去了，因此就可以利用此特性进行对称加密 但是要加密的信息往往比密钥长，密钥一般很短，那么就需要将数据进行分组，每组长度就是密钥的长度，然后分别对每组进行XOR运算，最后拼接
比如现在A用密钥进行加密(XOR运算)了，B收到加密的密文之后还是用相同的密钥进行XOR运算，这样就可以解密了
​
非对称加密 非对称加密就是使用不同的密钥进行加密解密，比如使用 公钥 加密，使用 **私钥 **解密
特点：
安全，解决了 对称加密 密钥传输问题 加解密CPU消耗高，需要复杂的数学运算 所以一般使用非对称加密进行传输对称加密密钥，之后用对称加密进行通信
相关算法：RSA、ECC
非对称加密就是将 公钥+数据 进过一个公式进行处理就变成一个密文，然后对方用 私钥+密文 也进过一个公式处理就变成了原始数据，反之同理
​
​
信息摘要 摘要主要是为了 防止信息被篡改 ，又称为 信息指纹 ，并且通过摘要算法之后可以讲不同长度的数据都变为固定长度的hash字符串
字符串、文件等内容经过 摘要算法(hash算法) 进行hash散列之后得到的一串固定长度的 hash字符串 这就是 信息摘要
摘要算法其实是一种 单向的加密算法 ，只能加密而不能解密，也就是说不能通过hash字符串推出原来的数据
常见的hash算法有：MD5、SHA256
​
​
数字签名 数字签名是一个非对称加密的方式，私钥签名，公钥解密</description></item><item><title>docker的volumes踩坑</title><link>/2021/01/07/docker%E7%9A%84volumes%E8%B8%A9%E5%9D%91/</link><pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2021/01/07/docker%E7%9A%84volumes%E8%B8%A9%E5%9D%91/</guid><description>挂载volume的行为 volume的挂载是 以宿主机为主 ，主要有如下几个行为可能：
host container mount result 文件夹不存在，文件夹存在但为空 不管容器内文件夹是否存在 container中文件被覆盖（清空） 文件夹存在且不为空 不管容器内的文件夹是否存在 container中文件夹内容被覆盖（原内容清空， 覆盖为host上文件夹内容） 综上，应该避免挂载宿主机上一个空的或未创建的目录，这样可能会清空容器中原来存在的文件，避免将容器原来已经存在的文件覆盖(除非你的目的就是要覆盖容器内的文件)
​
将容器已经存在的文件挂载到宿主机 由上面可知，容器中原本存在的文件一旦进过挂载，就一定会被宿主机覆盖，但是有如下几个方法，可以曲线救国：
docker cp命令先将容器内的数据copy到宿主机然后再进行挂载 在docker-entrypoint.sh等脚本中执行创建文件和文件夹等相关命令，因为挂载行为先与脚本的执行行为，所以在脚本执行的时候已经挂载volume，当脚本创建相关文件的时候就可以反映到宿主机上了 ​
volume相关命令 docker volume ls #查看所有命名和匿名volume docker inspect &amp;lt;volume-name&amp;gt; #查看volume相关信息 docker volume create &amp;lt;volume-name&amp;gt; #创建volume docker volume rm &amp;lt;volume-name&amp;gt; #删除 docker volume preun #清空没有容器挂载中的volume stop中的容器的volume不会清空 #控制volume的读写权限 -v &amp;lt;xxx&amp;gt;:容器内路径:ro #只读 在容器内只能读挂载的文件 -v &amp;lt;xxx&amp;gt;:容器内路径:rw #读写 在容器内能读写挂载文件 默认 ​</description></item><item><title>HTML总结</title><link>/2019/05/25/html%E6%80%BB%E7%BB%93/</link><pubDate>Sat, 25 May 2019 00:00:00 +0000</pubDate><author>icepan@aliyun.com (lyer)</author><guid>/2019/05/25/html%E6%80%BB%E7%BB%93/</guid><description>head标签 head标签用于HTML文档头部，主要用于存放元数据、引入外部样式脚本等标签的容器，还可定义一些页面信息相关的内容，主要的子标签如下：
&amp;lt;meta&amp;gt;：设置网页的元数据,比如网页的字符集&amp;hellip;..
&amp;lt;link&amp;gt;：引入外部资源，指定ref定义当前文档与被链接文档之间的关系
指定type定义被链接的文档类型
&amp;lt;title&amp;gt;：设置网页标题
&amp;lt;style&amp;gt;：放置内嵌的样式表
&amp;lt;script&amp;gt;：引入外部js脚本
&amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;title&amp;gt;这是网页标题&amp;lt;/title&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; type=&amp;#34;text/css&amp;#34; href=&amp;#34;theme.css&amp;#34;&amp;gt; &amp;lt;link rel=&amp;#34;stylesheet&amp;#34; type=&amp;#34;text/css&amp;#34; href=&amp;#34;http://www.x.cn/a.css&amp;#34;&amp;gt; &amp;lt;style&amp;gt; a{color: red;} &amp;lt;/style&amp;gt; &amp;lt;script src=&amp;#34;https://static.sick.cn/respond.min.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; //下面脚本会执行 &amp;lt;script&amp;gt; alert(&amp;#34;hello,world&amp;#34;) &amp;lt;/script&amp;gt; //定义了这行则所有绝对地址的url则都会以这个为基础 &amp;lt;base href=&amp;#34;https://www.google.com&amp;#34;&amp;gt; &amp;lt;/head&amp;gt; ​
meta元数据 meta标签用于设置一些元数据，并且可以定义一些浏览器的缓存策略，还可以定义网页关键字用于搜索引擎爬虫的爬取
&amp;lt;!-- 定义网页文档的字符集 --&amp;gt; &amp;lt;meta charset=&amp;#34;utf-8&amp;#34; /&amp;gt; &amp;lt;!-- 网页作者 --&amp;gt; &amp;lt;meta name=&amp;#34;author&amp;#34; content=&amp;#34;开源技术团队&amp;#34;/&amp;gt; &amp;lt;!-- 网页地址 --&amp;gt; &amp;lt;meta name=&amp;#34;website&amp;#34; content=&amp;#34;https://www.baidu.com&amp;#34;/&amp;gt; &amp;lt;!-- 网页版权信息 --&amp;gt; &amp;lt;meta name=&amp;#34;copyright&amp;#34; content=&amp;#34;2020-2021 demo.</description></item></channel></rss>